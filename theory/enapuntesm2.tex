% Principios de elaboración:
% 1. Son apuntes, no un libro.
% 2. Esquemáticos: la estructura es muy importante.
% 3. Concisos: no añadir comentarios excesivos ni demasiados ejemplos que entorpezcan el estudio.
% 4. La paginación debe resaltar la estructura y facilitar el estudio.
\documentclass[spanish]{book}

\usepackage{mypack}

\graphicspath{{./img/}}

\setcounter{topnumber}{4}
\setcounter{bottomnumber}{4}
\setcounter{totalnumber}{10}

\begin{document}

\title{\scshape Matemáticas II\\Apuntes} \author{} \date{Septiembre de 2016}
\maketitle

\tableofcontents

\part{Algebra Lineal}

\chapter{Matrices}

\newpage\section{Definición de matriz}

\begin{definition}
  [Matrix]A \textbf{matrix} of dimension (or size) $m \times n$ is any set of scalars arranged in $m$ rows and $n$ columns.
\end{definition}

\begin{example}
  A matrix is a table, or a set of data which depends on two indices. For example, the profit made by four restaurants in the first three months of a year might be represented as a $4\times3$ matrix, in which every row shows the data from a restaurant, and every column shows the data of a month:

  \begin{center}
  \begin{tabular}{|l|l|l|l|}
    \hline
    & 1 (January) & 2 (February) & 3 (March)\\
    \hline
    1 (London) & 5.6 & 12.3 & 15.6\\
    \hline
    2 (Manchester) & 3.5 & 7.6 & 21.8\\
    \hline
    3 (Oxford) & 5.8 & 14.5 & 16.7\\
    \hline
    4 (Liverpool) & 7.8 & 13.3 & 15.2\\
    \hline
  \end{tabular}
  \end{center}

  Using matrix language, we get:
$$B = \left(\begin{array}{ccc}
    5.6 & 12.3 & 15.6\\
    3.5 & 7.6 & 21.8\\
    5.8 & 14.5 & 16.7\\
    7.8 & 13.3 & 15.2
  \end{array}\right)$$
\end{example}

\begin{remark} In this notes,  the word \textit{scalar} might be taken as a synonimous of \textit{real number}. Actually, an \texit{scalar} is any element of a \textit{body}. A \texit{body} is an algebraic structure which consists of a set and two operations with a series of properties (associative, commutative, null element, symmetric element, distributive). The set $\mathbb{R}$ of the real numbers with the operations \texit{addition} and \textit{product} form a \textit{body}. The set $\mathbb{C}$ of compllex numbers is also a body. A matrix whose elements are real numbers is called a \textit{real matrix}, while a matrix whose elements are complex numbers is called a \texit{complex matrix}.

\begin{remark}Las matrices suelen representarse con letras mayúsculas, y los escalares con letras minúsculas.\end{remark}

\begin{remark}Al escalar que está en fila $i$ y en la columna $j$, se le llama \textit{elemento de lugar (i,j)} o \textit{elemento ij}. Cuando se utilizan letras para representar los elementos de una matriz es frecuente utilizar la misma letra para todos ellos distinguiéndolos mediante un subíndice en el que se indican la fila y la columna, en ese orden, de cada elemento: $a_{i, j}$ representa al elemento de lugar $(i,j)$. Si no hay posible confusión, se suele omitir la coma que separa la fila y la columna: $a_{ij}$. Cuando las matrices son pequeñas se puede utilizar una letra distinta para cada elemento:

$$M = \left(\begin{array}{ccccc}
  m_{11} & m_{12} & m_{13} & m_{14} & m_{15}\\
  m_{21} & m_{22} & m_{23} & m_{24} & m_{25}\\
  m_{31} & m_{32} & m_{33} & m_{34} & m_{35}
\end{array}\right)$$

$$A = \matriz{cc}{a&b\\c&d}$$
\end{remark}

\begin{remark}Cuando se quiera señalar expresamente que la matriz $A$ tiene tamaño $m \times n$, se la denotará por $A_{m \times n}$.\end{remark}

\begin{remark}En toda la notación utilizada para las matrices, el primer número se refiere siempre a las filas y el segundo a las columnas (así, $a_{23}$ es el elemento de la fila 2 y columna 3, y $a_{32}$ es el elemento de la fila 3 y la columna 2, $A_{4 \times 3}$ es una matriz de 4 filas y 3 columnas, mientras que $B_{3 \times 4}$ es una matriz de 3 filas y 4 columnas).\end{remark}

\begin{remark}Las filas se escriben en horizontal y las columnas en vertical.\end{remark}

\begin{remark} Cuando el número de elementos es muy grande o indeterminado, pueden escribirse solo algunos elementos e indicar que se han omitido elementos utilizando puntos suspensivos, siempre que los elementos omitidos puedan inducirse a partir de los que se han escrito. Por ejemplo:

\[A_{m \times n} =
\left(\begin{array}{cccc}
  a_{11} & a_{12} & \ldots & a_{1 n}\\
  a_{21} & a_{22} & \ldots & a_{2 n}\\
  \vdots & \vdots & \ddots & \vdots\\
  a_{m 1} & a_{m 2} & \ldots & a_{m n}
\end{array}\right)\]

\[B_{30\times30} = \matriz{ccccc}{-1&1&1&\ldots&1\\0&-1&1&\ldots&1\\0&0&-1&\ldots&1\\\vdots&\vdots&\vdots&\ddots&\vdots\\0&0&0&\ldots&-1}\]
\end{remark}

\begin{example}Sea la matriz

\[A_{3 \times 4} = \left(\begin{array}{cccc}
  1 & 3 & 2 & - 1\\
  2 & 4 & 2 & 1\\
  4 & 6 & 2 & 5
\end{array}\right)\]

La matriz tiene 3 filas, que son:
\[F_1 = \left(\begin{array}{cccc}
  1 & 3 & 2 & - 1
\end{array}\right),\ F_2 = \left(\begin{array}{cccc}
  2 & 4 & 2 & 1
\end{array}\right), \text{ y } F_3 = \left(\begin{array}{cccc}
  4 & 6 & 2 & 5
\end{array}\right).\]
La matriz $A$ tiene 4 columnas:
\[C_1 =
\left(\begin{array}{c}
  1\\
  2\\
  4
\end{array}\right),\; C_2 = \left(\begin{array}{c}
  3\\
  4\\
  6
\end{array}\right),\; C_3 = \left(\begin{array}{c}
  2\\
  2\\
  2
\end{array}\right)\text{ y }C_4 = \left(\begin{array}{c}
  - 1\\
  1\\
  5
\end{array}\right).\]

Algunos elementos de $A$ son: $a_{11} = 1 ; a_{21} = 2 ; a_{31} = 4 ; a_{24} =
1$.

La posición del único 6 que contiene la matriz es $( 3, 2 )$, lo cual
significa que está en la 3ª fila y en la 2ª
columna.\end{example}
\begin{definition}[Igualdad de matrices]Dos matrices son iguales si tienen igual
tamaño y tienen respectivamente iguales los elementos que ocupan los mismos
lugares.\end{definition}



\newpage\section{Tipos de matrices}

\begin{definition}[Matriz fila]Matriz de una sola fila.\end{definition}
\begin{example}
  $$A_{1 \times 5} = \left(\begin{array}{ccccc}  1 & 4 & - 3 & 0 & 0\end{array}\right)$$
\end{example}

\begin{definition}[Matriz columna]Matriz con una sola columna.\end{definition}
\begin{example}
  $$B_{3 \times 1} = \left(\begin{array}{c}  x\\  y\\  z\end{array}\right)$$
\end{example}

\begin{definition}[Matriz cuadrada]Matriz con igual número de filas que columnas. Al tamaño de una matriz cuadrada se le llama también orden: una matriz cuadrada de orden n es una matriz de tamaño $n \times n$.\end{definition}
\begin{example}
  $$C = \left(\begin{array}{ccc}  1 & 2 & 3\\  4 & 5 & 6\\  7 & 8 & 9\end{array}\right)$$
\end{example}

\begin{definition}[Diagonal principal]En una matriz cuadrada de dimensión n$\times$n, es el conjunto de elementos de la matriz cuyo número de fila es igual a su número de columna: $\left\{ a_{i i} \right\}_{i=1}^n$.\end{definition}
\begin{example}
  Diagonal principal de la matriz anterior $C$: $\{ 1, 5, 9 \}$. Está formada por los elementos $c_{11}$, $c_{22}$ y $c_{33}$.
\end{example}

\begin{definition}[Diagonal secundaria]En una matriz cuadrada de dimensión $n\times n$, es el conjunto de elementos de la matriz $\left\{ a_{i, n - i + 1} \right\}_{i=1}^n$.\end{definition}
\begin{example}
  Diagonal secundaria de $C$: $\{ 3, 5, 7 \}$. Está formada por los elementos $c_{13}$, $c_{22}$ y $c_{31}$.
\end{example}

\begin{definition}[Traza]En una matriz cuadrada de dimensión n$\times$n, es la suma de los elementos de la diagonal principal: $\tmop{Tr} ( A_n ) = \overset{n}{\underset{i = 1}{\sum}} a_{i i}$.\end{definition}
\begin{example}
  Traza de $C$: $\tmop{Tr} ( C ) = c_{11} + c_{22} + c_{33} = 1 + 5 + 9 = 15$.
\end{example}

\begin{definition}[Matriz rectangular]Matriz que no es cuadrada.\end{definition}
\begin{example}
  $$D = \left(\begin{array}{ccc}  0 & 0 & 1\\  1 & 1 & 0\end{array}\right)$$  
\end{example}

\begin{definition}[Matriz simétrica]Es una matriz cuadrada tal que $a_{i j} = a_{ji}, \forall i, j$.\end{definition}
\begin{example}
$$S = \left(\begin{array}{ccc}  1 & 0 & 7\\  0 & 5 & 3\\  7 & 3 & 9 \end{array}\right)$$
\end{example}

\begin{definition}[Matriz antisimétrica]Es una matriz cuadrada tal que $a_{i j} = - a_{j i}, \forall i, j$.\end{definition}
\begin{example}
Obsérvese que la diagonal principal ha de ser nula.
$$A = \left(\begin{array}{ccc}  0 & 6 & - 2\\  - 6 & 0 & 1\\  2 & - 1 & 0\end{array}\right)$$
\end{example}

\begin{definition}[Matriz triangular superior]Es una matriz cuadrada tal que $a_{ij} = 0, \forall i > j$ (es decir, tiene nulos todos sus elementos por debajo de la diagonal principal).\end{definition}
\begin{example}
$$E = \left(\begin{array}{cccc} - 1 & 3 & 0 & 2\\  0 & 2 & 1 & 1\\  0 & 0 & 0 & - 1\\  0 & 0 & 0 & 5\end{array}\right)$$
\end{example}

\begin{definition}[Matriz triangular inferior]Es una matriz cuadrada tal que $a_{ij} = 0, \forall i < j$ (es decir, tiene nulos todos sus elementos por encima de la diagonal principal).\end{definition}
\begin{example}
  $$F =\left(\begin{array}{cccc}  1 & 0 & 0 & 0\\  1 & 1 & 0 & 0\\  1 & 1 & 1 & 0\\  1 & 1 & 1 & 1\end{array}\right)$$
\end{example}

\begin{definition}[Matriz diagonal]Es una matriz cuadrada tal que $a_{i j} = 0,\forall i \neq j$ (es decir, que tiene nulos todos sus elementos excepto los
de la diagonal principal).\end{definition}
\begin{example}
  $$G = \left(\begin{array}{ccc}  - 1 & 0 & 0\\  0 & 7 & 0\\  0 & 0 & 1\end{array}\right)$$
\end{example}

\begin{definition}[Matriz escalar]Es una matriz diagonal que tiene iguales todos sus elementos de la diagonal principal.\end{definition}
\begin{example}
  $$H = \left(\begin{array}{ccc}  2 & 0 & 0\\  0 & 2 & 0\\  0 & 0 & 2\end{array}\right)$$
\end{example}

\begin{definition}[Matriz identidad o unidad de orden $n$]Es una matriz escalar de tamaño n$\times$n que tiene todos los elementos de la diagonal principal iguales a 1. Se representa por $I_n$.\end{definition}
\begin{example}
  $$I_3 = \left(\begin{array}{ccc}  1 & 0 & 0\\  0 & 1 & 0\\  0 & 0 & 1\end{array}\right)$$
\end{example}

\begin{remark}
  \textbf{Cuidado:} la matriz identidad o unidad no es la que tiene todos sus elementos iguales a
  1. Cuando estudiemos el producto de matrices veremos por qué.
\end{remark}

\begin{definition}[Matriz nula]Es una matriz cuyos elementos son todos cero. Se representa por $O_{m \times n}$.\end{definition}
\begin{example}
  $$O_{2 \times 3} = \left(\begin{array}{ccc}  0 & 0 & 0\\  0 & 0 & 0\end{array}\right)_{}$$
\end{example}

{}

\newpage\section{Suma de matrices}

\begin{definition}[Suma de matrices]Dadas dos matrices de igual tamaño, $A_{m\times n}$ y $B_{m \times n}$, se llama suma de $A$ y $B$, y se representa por
$A + B$, a otra matriz del mismo tamaño cuyo elemento de lugar $( i, j )$ es la suma del elemento $i j$ de $A$ más el elemento $i j$ de $B$. Es decir:
\begin{center}
  $\left(\begin{array}{cccc}
    a_{11} & a_{12} & \ldots & a_{1 n}\\
    a_{21} & a_{22} & \ldots & a_{2 n}\\
    \ldots & \ldots & \ldots & \ldots\\
    a_{m 1} & a_{m 2} & \ldots & a_{m n}
  \end{array}\right) + \left(\begin{array}{cccc}
    b_{11} & b_{12} & \ldots & b_{1 n}\\
    b_{21} & b_{22} & \ldots & b_{2 n}\\
    \ldots & \ldots & \ldots & \ldots\\
    b_{m 1} & b_{m 2} & \ldots & b_{m n}
  \end{array}\right) = \left(\begin{array}{cccc}
    a_{11} + b_{11} & a_{12} + b_{12} & \ldots & a_{1 n} + b_{1 n}\\
    a_{21} + b_{21} & a_{22} + b_{22} & \ldots & a_{2 n} + b_{2 n}\\
    \ldots & \ldots & \ldots & \ldots\\
    a_{m 1} + b_{m 1} & a_{m 2} + b_{m 2} & \ldots & a_{m n} + b_{m n}
  \end{array}\right)$
\end{center}
\end{definition}

\begin{theorem}
  [Propiedades de la suma de matrices]Dadas tres matrices cualesquiera, $A$, $B$ y $C$ del mismo tamaño $m \times n$, se cumple:
  \begin{enumerate}
    \item Propiedad asociativa: $( A + B ) + C = A + ( B + C )$.
    
    \item Propiedad conmutativa: $A + B = B + A$.
    
    \item Elemento neutro: existe una matriz $O$ tal que $\forall\ A, A + O = O + A = A$.
    
    \item Elemento simétrico: $\forall\ A \ \exists\ - A / A + ( - A ) = O$.
  \end{enumerate}
\end{theorem}

\begin{remark}El elemento neutro de la suma es la matriz nula (todos sus elementos son 0).\end{remark}

\begin{remark}El elemento simétrico de una matriz $A = ( a_{i j} )$ respecto a la suma se llama \textit{matriz opuesta}, y es la matriz formada por los opuestos de los elementos de $A$: $- A = ( - a_{i j} )$.\end{remark}

\begin{remark}No se debe confundir la matriz nula, $O$, con un cero, $0$.\end{remark}

\begin{remark}La suma de matrices utiliza el mismo símbolo que la suma de escalares, $+$, pero son operaciones diferentes. No se pueden sumar números con matrices: una expresión como $5 + A_{3 \times 4}$ no tiene sentido.\end{remark}

\begin{remark}Sólo pueden sumarse matrices del mismo tamaño. Por tanto, la expresión
$$\left(\begin{array}{ccc}
  1 & 2 & 3\\
  4 & 5 & 6
\end{array}\right) + \left(\begin{array}{cc}
  1 & 2\\
  3 & 4\\
  5 & 6
\end{array}\right)$$
no tiene sentido (no está definido su significado).
\end{remark}

\begin{example}Sean las matrices: $A = \left(\begin{array}{ccc}
  3 / 2 & 1 & 0\\
  2 & 1 / 2 & 5
\end{array}\right)$ y $B = \left(\begin{array}{ccc}
  3 / 2 & 2 & 1\\
  1 & 1 / 2 & 4
\end{array}\right)$, calcular su suma.

\[A + B = \left(\begin{array}{ccc}
  3 / 2 & 1 & 0\\
  2 & 1 / 2 & 5
\end{array}\right) + \left(\begin{array}{ccc}
  3 / 2 & 2 & 1\\
  1 & 1 / 2 & 4
\end{array}\right) = \left(\begin{array}{ccc}
  3 / 2 + 3 / 2 & 1 + 2 & 0 + 1\\
  2 + 1 & 1 / 2 + 1 / 2 & 5 + 4
\end{array}\right) = \left(\begin{array}{ccc}
  3 & 3 & 1\\
  3 & 1 & 9
\end{array}\right).\]
\end{example}

{}

\newpage\section{Producto por un escalar}

\begin{definition}[Producto de una matriz por un escalar]Dada una matriz $A$ y un escalar $\lambda$, se llama producto de $A$ por $\lambda$, y se representa por $\lambda A$, a la matriz del mismo tamaño que $A$ que se obtiene al multiplicar todos los elementos de $A$ por dicho escalar. Es decir:
\begin{center}
  $\lambda \left(\begin{array}{cccc}
    a_{11} & a_{12} & \ldots & a_{1 n}\\
    a_{21} & a_{22} & \ldots & a_{2 n}\\
    \ldots & \ldots & \ldots & \ldots\\
    a_{m 1} & a_{m 2} & \ldots & a_{m n}
  \end{array}\right) = \left(\begin{array}{cccc}
    \lambda a_{11} & \lambda a_{12} & \ldots & \lambda a_{1 n}\\
    \lambda a_{21} & \lambda a_{22} & \ldots & \lambda a_{2 n}\\
    \ldots & \ldots & \ldots & \ldots\\
    \lambda a_{m 1} & \lambda a_{m 2} & \ldots & \lambda a_{m n}
  \end{array}\right)$
\end{center}
\end{definition}

\begin{theorem}
  [Propiedades del producto por un escalar]Dadas dos matrices cualesquiera del mismo tamaño, $A$ y $B$, y dos escalares cualesquiera, $\lambda$ y $\mu$, se cumple:
  
  \begin{enumerate}
    \item Propiedad distributiva respecto de la suma de escalares: $( \lambda + \mu ) A = \lambda A + \mu A$.
    
    \item Propiedad distributiva respecto de la suma de matrices: $\lambda ( A + B ) = \lambda A + \lambda  B$.
    
    \item Propiedad asociativa: $\lambda ( \mu A ) = ( \lambda \mu ) A$.
    
    \item Elemento neutro: $1 A = A$.
  \end{enumerate}
\end{theorem}

\begin{example}Calcular $- 2 A$, siendo $A = \left(\begin{array}{ccc}
  1 & - 1 & 0\\
  0 & 2 & - 2\\
  1 & - 1 & - 3
\end{array}\right)$.

$$- 2 A = - 2 \left(\begin{array}{ccc}
  1 & - 1 & 0\\
  0 & 2 & - 2\\
  1 & - 1 & - 3
\end{array}\right) = \left(\begin{array}{ccc}
  - 2 \cdot 1 & - 2 \cdot ( - 1 ) & - 2 \cdot 0\\
  - 2 \cdot 0 & - 2 \cdot 2 & - 2 \cdot ( - 2 )\\
  - 2 \cdot 1 & - 2 \cdot ( - 1 ) & - 2 \cdot ( - 3 )
\end{array}\right) = \left(\begin{array}{ccc}
  - 2 & 2 & 0\\
  0 & - 4 & 4\\
  - 2 & 2 & 6
\end{array}\right)$$
\end{example}

\begin{example}
  Gracias a que las propiedades de la suma de matrices y del producto de un escalar por una matriz
  son las mismas que las de la suma y producto de números reales,
  podemos resolver sistemas de ecuaciones matriciales en que aparezcan solo estas dos operaciones
  utilizando los mismos métodos que para sistemas numéricos. Por ejemplo, siendo $A=\matriz{cc}{-1&3\\2&2}$, $B=\matriz{cc}{4&3\\-2&1}$,
  \begin{eqnarray*}
    \left\{\begin{array}{l}2X+Y=A\\X-Y=B\end{array}\right. & \sim & \left\{\begin{array}{l}2X+Y=A\\3X=B+A\end{array}\right. \\
    & \sim & \left\{\begin{array}{l}Y=A-2X\\X=\dfrac{1}{3}(A+B)=\dfrac{1}{3}\matriz{cc}{3&6\\0&3}=\matriz{cc}{1&2\\0&1}\end{array}\right. \\
    & \sim & \left\{\begin{array}{l}Y=\matriz{cc}{-1&3\\2&2}-2\matriz{cc}{1&2\\0&1}=\matriz{cc}{-3&-1\\2&0}\\X=\matriz{cc}{1&2\\0&1}\end{array}\right.
  \end{eqnarray*}
        
\end{example}

{}

\newpage\section{Producto de matrices}

\begin{definition}[Producto de matrices]Dadas las matrices $A = ( a_{i j} )$ de tamaño $m \times p$ y $B = ( b_{i j} )$ de tamaño $p \times n$, se llama
producto de $A$ por $B$, y se representa por $A B$ o $A \cdot B$, a la matriz $C = ( c_{i j} )$ de tamaño $m \times n$ cuyo elemento $i j$ viene dado por:
\begin{center}
  $c_{i j} = a_{i 1} b_{1 j} + a_{i 2} b_{2 j} + \ldots + a_{i p} b_{p j} = \overset{p}{\underset{k = 1}{\sum}} a_{i k} b_{k j}$
\end{center}
\end{definition}

\begin{remark}El producto de $A$ por $B$ se calcula multiplicando cada fila de $A$ por cada columna de $B$. Una fila se multiplica por una columna, multiplicando elemento a elemento y sumando. El elemento $i j$ del producto $A B$ será el resultado de multiplicar la fila $i$ de $A$ por la columna $j$ de $B$.\end{remark}

\begin{remark}Sólo está definido el producto $A \cdot B$ si el número de columnas de $A$ es igual al número de filas de $B$.\end{remark}

\begin{remark}La matriz producto $A B$ tiene tantas filas como $A$ y tantas columnas como $B$:
\begin{center}
  $A_{m \times p} \cdot B_{p \times n} = C_{m \times n}$
\end{center}
\end{remark}

\begin{example}Calcular el producto $A B$, siendo $A = \left(\begin{array}{cccc}
  2 & - 1 & 5 & - 3\\
  4 & 2 & - 3 & - 5\\
  3 & - 1 & - 1 & 5
\end{array}\right)$ y $B = \left(\begin{array}{cc}
  1 & - 2\\
  3 & 6\\
  2 & 7\\
  4 & 1
\end{array}\right)$.

Observemos en primer lugar que el producto existe porque $A$ tiene tantas columnas, 4, como filas tiene $B$. El resultado será una matriz con tantas
filas como $A$, 3, y tantas columnas como $B$, 2:

$$A_{3 \times 4} \cdot B_{4 \times 2} = C_{3 \times 2}$$

\begin{align*}
A B &= \left(\begin{array}{cccc}
  2 & - 1 & 5 & - 3\\
  4 & 2 & - 3 & - 5\\
  3 & - 1 & - 1 & 5
\end{array}\right) \left(\begin{array}{cc}
  1 & - 2\\
  3 & 6\\
  2 & 7\\
  4 & 1
\end{array}\right)\\
& = \left(\begin{array}{cccc}
  2 \cdot 1 - 1 \cdot 3 + 5 \cdot 2 - 3 \cdot 4 &  &  & 2 \cdot ( - 2 ) - 1
  \cdot 6 + 5 \cdot 7 - 3 \cdot 1\\
  4 \cdot 1 + 2 \cdot 3 - 3 \cdot 2 - 5 \cdot 4 &  &  & 4 \cdot ( - 2 ) + 2
  \cdot 6 - 3 \cdot 7 - 5 \cdot 1\\
  3 \cdot 1 - 1 \cdot 3 - 1 \cdot 2 + 5 \cdot 4 &  &  & 3 \cdot ( - 2 ) - 1
  \cdot 6 - 1 \cdot 7 + 5 \cdot 1
\end{array}\right)\\
& = \left(\begin{array}{cc}
  - 3 & 22\\
  - 16 & - 22\\
  18 & - 14
\end{array}\right)
\end{align*}
\end{example}

\begin{theorem}
  [Propiedades del producto]Para cualesquiera matrices $A, A'$, $B, B'$ y $C$, (siempre que existan los productos) se cumple:
  
  \begin{enumerate}
    \item Propiedad asociativa: $( A B ) C = A ( B C )$.
    
    \item Propiedad distributiva: $\left\{\begin{array}{l}
      A ( B + B' ) = A B + A B'\\
      ( A + A' ) B = A B + A' B
    \end{array}\right.$.
    
    \item Elemento neutro: $A I = A$, $I B = B$, siendo $I$ la matriz identidad.
  \end{enumerate}
\end{theorem}

\begin{remark}El producto de matrices no es conmutativo: en general, $A B \neq B A$. Cuando dos matrices cumplen $M N = N M$, se dice que $M$ y $N$
\textit{conmutan}.\end{remark}
\begin{example}
  El producto de matrices no es conmutativo:
$$\left(\begin{array}{cc}
  1 & 0\\
  1 & 1
\end{array}\right) \left(\begin{array}{cc}
  4 & - 1\\
  0 & 2
\end{array}\right) = \left(\begin{array}{cc}
  4 & - 1\\
  4 & 1
\end{array}\right)$$

$$\left(\begin{array}{cc}
  4 & - 1\\
  0 & 2
\end{array}\right) \left(\begin{array}{cc}
  1 & 0\\
  1 & 1
\end{array}\right) = \left(\begin{array}{cc}
  3 & - 1\\
  2 & 2
\end{array}\right)$$
\end{example}

\begin{remark}
  Como consecuencia de la no conmutatividad, las \emph{identidades notables} no son válidas, en
  general, para las matrices:
  $$(A+B)^2=A^2+B^2+AB+BA\neq A^2+B^2+2AB$$
  $$(A+B)(A-B)=A^2-B^2+BA-AB\neq A^2-B^2$$
\end{remark}

\begin{remark}En el producto de matrices, existen \textit{divisores de cero}, que son matrices tales que $A B = O$, siendo $A \neq O$ y $B \neq O$ (el producto de dos matrices no nulas puede ser la matriz nula).\end{remark}

\begin{example}

Existen divisores de cero:

$$\left(\begin{array}{cc}
  2 & 6\\
  - 1 & - 3
\end{array}\right) \left(\begin{array}{cc}
  3 & - 15\\
  - 1 & 5
\end{array}\right) = \left(\begin{array}{cc}
  0 & 0\\
  0 & 0
\end{array}\right) = O_2$$

$$\left(\begin{array}{cc}
  2 & 6\\
  - 1 & - 3
\end{array}\right) \left(\begin{array}{cc}
  6 & 3\\
  - 2 & - 1
\end{array}\right) = \left(\begin{array}{cc}
  0 & 0\\
  0 & 0
\end{array}\right) = O_2$$
\end{example}

\begin{remark}De la observación anterior se deduce también que el producto de matrices no es \textit{simplificable}, es decir, en general, $A B = A C$ y $A \neq O \nRightarrow B = C$. Dicho de otro modo: dos matrices distintas pueden tener el mismo producto con una tercera matriz, aunque esta no sea nula.\end{remark}

\newpage\section{Matriz traspuesta}

\begin{definition}[Matriz traspuesta]Dada una matriz $A$ de dimensión $m \times n$, se llama matriz traspuesta de $A$, y se representa por $A^t$, a la matriz de tamaño $n \times m$, cuyo elemento $i j$ es el elemento $j i$ de $A$.\end{definition}

\begin{remark}La matriz traspuesta es la que se obtiene cambiando filas por columnas (la primera
  fila se convierte en primera columna, la segunda fila en segunda columna, y así
  sucesivamente).\end{remark}

\begin{remark}
  Otro símbolo utilizado frecuentemente para representar a la matriz traspuesta es $A^T$.
\end{remark}

\begin{example}Dada $A = \left(\begin{array}{ccc}
  1 & 0 & 7\\
  - 2 & 3 & 0
\end{array}\right)$, la traspuesta de $A$ es $A^t = \left(\begin{array}{cc}
  1 & - 2\\
  0 & 3\\
  7 & 0
\end{array}\right)$.
\end{example}

\begin{theorem}
  [Propiedades de la matriz traspuesta]Para cualesquiera matrices $A$ y B se verifica:
  
  \begin{enumerate}
    \item $( A^t )^t = A$.
    
    \item $( A + B )^t = A^t + B^t$.
    
    \item $( \lambda A )^t = \lambda A^t$.
    
    \item $( A B )^t = B^t A^t$.
  \end{enumerate}
\end{theorem}

\begin{remark}Una matriz cuadrada $A$ es simétrica si y solo si $A^t = A^{}$. Una matriz cuadrada $A$ es antisimétrica si y solo si $A^t = - A$.\end{remark}

\newpage\section{Potencias de matrices}

\begin{definition} Dada una matriz cuadrada $A$, se define $A^n$ para todo número natural $n$, del siguiente modo: 
$$A^n = \left\{\begin{array}{ll}
  A , & n = 1\\
  A \cdot A^{n - 1}, & n > 1
\end{array}\right.$$
\end{definition}

\begin{remark}
  La potencia de matrices se define solo para matrices cuadradas, porque son las únicas que pueden multiplicarse por sí mismas.
\end{remark}

\begin{definition} [Matriz periódica] Una matriz cuadrada $A$ es periódica si existe $p\in\mathbb{N}$ tal que $A^{p+1}=A$. Si $p$ es el menor número natural que cumple la relación anterior, se dice que $A$ es periódica con periodo $p$.
\end{definition}

\begin{remark}
  Si $A$ es periódica de periodo $p$, entonces $A^{p+k}=A^k$. Es decir, una matriz periódica de periodo $p$ tiene solo $p$ potencias distintas, $A, A^2, \hdots, A^p$, que se repiten periódicamente.
\end{remark}

\begin{definition} [Matriz idempotente] Una matriz cuadrada $A$ es idempotente si $A^2=A$.
\end{definition}

\begin{remark}
  Si $A$ es idempotente, entonces $A^n=A$, para todo $n$. Es decir, una matriz idempotente es una matriz periódica de periodo 1: todas sus potencias son iguales a ella misma.
\end{remark}

\begin{definition} [Matriz nilpotente] Una matriz cuadrada $A$ es nilpotente si existe $p\in\mathbb{N}$ tal que $A^p=O$.
\end{definition}

\begin{remark}
  Si $A$ es nilpotente, con $A^p=O$, entonces, $A^m=O$ para todo $m>p$ (a partir de $p$ todas sus potencias son nulas).
\end{remark}

\begin{definition} [Matriz unipotente o involutiva] Una matriz cuadrada $A$ es unipotente o involutiva si $A^2=I$.
\end{definition}

\begin{remark}
  Si $A$ es unipotente, entonces las potencias de exponente par de $A$ son iguales a la matriz identidad, mientras que las potencias de exponente impar son iguales a la propia matriz $A$. Es decir, una matriz unipotente es una matriz de periodo 2.
\end{remark}

\begin{example}
  Sea
  $$A=\matriz{ccc}{-1&-1&-1\\1&1&1\\-1&-1&0}$$
  Comprobar que la matriz $A$ es nilpotente.

  $$A^2=AA=\matriz{ccc}{-1&-1&-1\\1&1&1\\-1&-1&0}\matriz{ccc}{-1&-1&-1\\1&1&1\\-1&-1&0}=\matriz{ccc}{1&1&0\\-1&-1&0\\0&0&0}$$

  $$A^3=AA^2=\matriz{ccc}{-1&-1&-1\\1&1&1\\-1&-1&0}\matriz{ccc}{1&1&0\\-1&-1&0\\0&0&0}=\matriz{ccc}{0&0&0\\0&0&0\\0&0&0}$$

  Luego, $A^n=O$ para $n\geq3$.
\end{example}

\begin{remark}
  La manera habitual de calcular una potencia de una matriz es simplemente calculando los productos correspondientes ($A^3=A\cdot A\cdot A$). Sin embargo, cuando se identifica que la matriz es periódica, idempotente, nilpotente o unipotente, esa información puede facilitar los cálculos. Existen otros métodos más sofisticados para calcular potencias, que no estudiaremos.
\end{remark}

\begin{remark}
  Se llama \emph{potencia enésima} de una matriz a su potencia de exponente $n$. Pero, normalmente, cuando hablamos de la potencia enésima de una matriz nos referiremos a una expresión que permita calcular $A^n$ para cualquier $n$ sin necesidad de efectuar los productos de matrices correspondientes. Por ejemplo,

\[A = \matriz{cc}{1&1\\0&1} \Rightarrow A^n = \matriz{cc}{1&n\\0&1}\]

La expresión anterior nos permitiría calcular cualquier potencia de $A$ sin ningún producto de matrices. Por ejemplo,

\[A^{2013} = \matriz{cc}{1&2013\\0&1}\]

El método más sencillo (que no funciona siempre) para hallar una potencia enésima, o $A^n$, consiste en calcular algunas potencias sencillas, como $A^2$, $A^3$, etc., y a partir de ellas tratar de inducir una fórmula válida para cualquier exponente. En el ejemplo anterior, si calculamos las primeras potencias resulta obvio cuál es la potencia enésima:

\[A^2 = AA = \matriz{cc}{1&1\\0&1} \matriz{cc}{1&1\\0&1} = \matriz{cc}{1&2\\0&1}\]
\[A^3 = AA^2 = \matriz{cc}{1&1\\0&1} \matriz{cc}{1&2\\0&1} = \matriz{cc}{1&3\\0&1}\]
\[A^4 = AA^3 = \matriz{cc}{1&1\\0&1} \matriz{cc}{1&3\\0&1} = \matriz{cc}{1&4\\0&1}\]

Seguro que el lector es capaz de adivinar cuánto vale $A^5$ sin necesidad de calcularlo. No siempre es tan sencillo inducir la fórmula general (pero no tendremos que enfrentarnos a casos complicados en este curso).

En algunos casos, la fórmula para la potencia enésima no se escribe en función de sus elementos, sino que es una expresión en la que interviene la matriz original, y quizá alguna otra (típicamente, la identidad). Por ejemplo, supongamos que nos dicen de una matriz $A$ que verifica:

\[A^2 = 2A - I\]

Podemos hallar la potencia enésima de $A$ sin conocer sus elementos. Ni siquiera necesitamos saber su tamaño. El procedimiento es análogo al anterior: calculamos algunas potencias, y tratamos de inducir una fórmula general. La única diferencia es que las potencias las calculamos ``en función de $A$ e $I$'', y, para ello, será necesario sustituir $A^2$, cada vez que aparezca, por $2A - I$:

\[A^3 = AA^2 = A(2A - I) = 2A^2 - A = 2(2A - I) - A = 4A - 2I - A = 3A - 2I\]
\[A^4 = AA^3 = A(3A - 2I) = 3A^2 -2A = 3(2A - I) - 2A = 6A - 3I - 2A = 4A - 3I\]

El lector ya habrá adivinado (quizá con algo más de dificultad) que $A^5 = 5A - 4I$. Y no se habrá equivocado. Así, pues, podemos conjeturar que:

\[A^n = nA - (n-1)I\]

Obsérvese que en este caso hemos calificado la expresión anterior de ``conjetura''. La verdad es que el procedimiento seguido para hallarla no nos garantiza que la fórmula sea correcta más allá de $A^4$ (o la que sea la última potencia calculada). Si quisiéramos estar seguros de que la fórmula ``funcionará'' para cualquier valor de $n$ (esa es nuestra pretensión), tendríamos que demostrarla de algún modo. En la siguiente observación se explica cómo hacer esta demostración.
\end{remark}

\begin{remark}
  \emph{Demostración por inducción}. El método de demostración por inducción se basa en el \emph{principio de inducción}, que permite probar que una determinada propiedad la cumplen todos los números naturales. El método tiene dos partes:
  \begin{enumerate}
  \item En primer lugar, se demuestra que la propiedad se cumple para el primer número natural que interese (habitualmente, en potencias, será $n=2$).
  \item En segundo lugar, se ha de demostrar el llamado \emph{paso de inducción}. Se trata de probar que si la propiedad se cumple para un número $n$, entonces también se ha de cumplir para el siguiente, $n+1$, y que esta implicación se cumple para cualquier $n$.
  \end{enumerate}

Así, por ejemplo, las potencias calculadas antes se demostrarían del siguiente modo.

En el primer ejemplo se encontró que:

\[A = \matriz{cc}{1&1\\0&1} \Rightarrow A^n = \matriz{cc}{1&n\\0&1}\]

En primer lugar, demostraremos que la fórmula se cumple para $n=2$:

\[n=2 \Rightarrow A^n = A^2 = AA = \matriz{cc}{1&1\\0&1} \matriz{cc}{1&1\\0&1} = \matriz{cc}{1&2\\0&1}\]
\[n=2 \Rightarrow \matriz{cc}{1&n\\0&1} = \matriz{cc}{1&2\\0&1}\]

Luego,

\[n=2 \Rightarrow A^n = \matriz{cc}{1&n\\0&1}\] 

En segundo lugar, demostraremos el paso de inducción. Supondremos que la fórmula es verdadera para $n$, y demostraremos que entonces también lo es para $n+1$:

\[A^{n+1} = AA^n = \matriz{cc}{1&1\\0&1}\matriz{cc}{1&n\\0&1} = \matriz{cc}{1&n+1\\0&1}\]

La expresión obtenida ``calculando'' $A^{n+1}$ ``sin usar la fórmula'' (en realidad, la hemos usado para $A^n$, pero porque estamos suponiendo que para $A^n$ la fórmula es válida), es igual que la que obtendríamos utilizando la fórmula (es decir, sustituyendo $n$ por $n+1$ en la fórmula). Por tanto, si la fórmula es válida para $n$, también lo es para $n+1$. Con esto queda demostrado el paso de inducción.

El segundo ejemplo se demuestra de forma análoga. No volveremos a escribir el primer paso de la demostración, porque es evidente que la fórmula se cumple para $n=2$, ya que la obtuvimos a partir de esa potencia (y de alguna más). La demostración del paso de inducción sería la siguiente:

\[A^n = nA-(n-1)I \Rightarrow A^{n+1} = AA^n = A(nA-(n-1)I) = nA^2-(n-1)A = n(2A-I)-(n-1)A = (n+1)A-nI\]

La expresión obtenida es la misma que obtendríamos sustituyendo $n$ por $n+1$ en la fórmula.
\end{remark}

\section{Grafos}


\begin{definition} [Grafo] Un grafo es un conjunto de puntos (llamados también nodos o vértices), y un conjunto de líneas de unión entre ellos (también llamadas aristas).
\end{definition}

\begin{remark}
  Vamos a hacer solo una breve introducción a este concepto matemático para ilustrar una posible aplicación de la herramienta algebraica que acabamos de presentar, las matrices. Como veremos pronto, la principal aplicación de las matrices es directamente algebraica: el estudio de los sistemas de ecuaciones.
\end{remark}

\begin{figure}
\centering
\subfloat[Grafo no dirigido]{\label{fig:grafos1:a}
\includegraphics[width=4cm]{ejgrafo1_cropped.pdf}}
\hspace{1cm}
\subfloat[Digrafo]{\label{fig:grafos1:b}
\includegraphics[width=4cm]{ejgrafo2_cropped.pdf}}
\hspace{1cm}
\subfloat[Grafo valuado]{\label{fig:grafos1:c}
\includegraphics[width=4cm]{ejgrafo3_cropped.pdf}}
\caption{Grafos}
\label{fig:grafos1}
\end{figure}

\begin{definition} [Tipos de grafos] Los grafos pueden ser
  \begin{itemize}
  \item Dirigidos: cada arista tiene un sentido (solo se puede recorrer en un sentido determinado), de modo que uno de los nodos que une es el origen y el otro el destino. También se llaman \emph{digrafos}.
  \item No dirigidos: las aristas no tienen un sentido determinado (se pueden recorrer en cualquier sentido), de modo que los nodos son indistintamente origen y destino de la arista.
  \item Simples: cada par de nodos está unido por una arista como máximo.
  \item Conexos: para todo par de nodos existe una sucesión de aristas que los conecta.
  \item Valuados (ponderados o etiquetados): cada arista tiene asignado un número (valor, peso o etiqueta).
  \end{itemize}
\end{definition}

\begin{definition} [Matriz de adyacencia] Dado un grafo simple con $n$ nodos, $\{v_1,v_2,\hdots,v_n\}$, se llama matriz de adyacencia de dicho grafo a una matriz cuadrada de orden $n$ cuyo elemento de lugar $(i,j)$ vale $1$ si existe una arista que une el nodo $v_i$ con el nodo $V_j$ en el sentido indicado, y $0$ si no existe dicha arista.
\end{definition}

\begin{example}
  Las matrices de adyacencia de los grafos de la figura~\ref{fig:grafos1} son las siguientes:
  \begin{enumeratealpha}
    \item $M_1=\matriz{ccccc}{0&1&0&0&1\\1&0&0&1&1\\0&1&0&1&0\\0&1&1&0&0\\1&1&0&0&0}$
    \item $M_2=\matriz{ccc}{0&1&1\\0&0&0\\1&1&0}$
    \item $M_3=\matriz{cccc}{0&1&1&0\\1&0&1&1\\1&1&0&1\\0&1&1&0}$
  \end{enumeratealpha}
\end{example}

\begin{example}
  El grafo correspondiente a la matriz de adyacencia

  \[\matriz{ccc}{1&1&1\\0&0&1\\1&1&0}\]

  sería el siguiente:

  \begin{center}\includegraphics[width=5cm]{ejgrafo4_cropped.pdf}\end{center}
\end{example}

\begin{remark}
  La matriz de adyacencia de un grafo simple no dirigido es siempre una matriz simétrica.
\end{remark}

\begin{remark}
  Si llamamos \emph{camino} entre dos nodos $v_i$ y $v_j$ a cualquier sucesión de aristas que tenga su origen en $v_i$ y que termine en $v_j$, y llamamos \emph{longitud} de dicho camino al número de aristas que lo forman, entonces resulta que la matriz $M^k$ indica el número de caminos de longitud $k$ que existen entre los distintos nodos. Además, la matriz $M+M^2+M^3+\cdots+M^{n-1}$, donde $n$ es el número de nodos, indica si existen o no caminos entre los distintos nodos.
\end{remark}

\begin{example}
  Hallar cuántos caminos de longitud 2 y 3 conectan cada par de nodos del grafo siguiente:

  \begin{center}\includegraphics[width=5cm]{ejgrafo5_cropped.pdf}\end{center}

  Se trata de un grafo simple no dirigido. La matriz de adyacencia del grafo es:

  \[M=\matriz{cccc}{0&1&0&1\\1&0&1&1\\0&1&0&1\\1&1&1&0}\]

  La matriz indica los caminos de longitud 1 (aristas del grafo) entre cada par de nodos. La matriz $M^2$ indicará los caminos de longitud 2:

  \[M^2=MM=\matriz{cccc}{0&1&0&1\\1&0&1&1\\0&1&0&1\\1&1&1&0}\matriz{cccc}{0&1&0&1\\1&0&1&1\\0&1&0&1\\1&1&1&0} = \matriz{cccc}{2&1&2&1\\1&3&1&2\\2&1&2&1\\1&2&1&3}\]

  Por ejemplo, la matriz anterior nos indica que hay dos caminos de longitud 2 que conectan el nodo A con el nodo C, en ese sentido (y otros dos en el sentido de C hacia A), ya que el elemento de posición $(1,3)$ vale $2$.

  La matriz $M^3$ indicará el número de caminos de longitud 3 entre cada par de nodos:

  \[M^3=MM^3=\matriz{cccc}{0&1&0&1\\1&0&1&1\\0&1&0&1\\1&1&1&0}\matriz{cccc}{2&1&2&1\\1&3&1&2\\2&1&2&1\\1&2&1&3} = \matriz{cccc}{2&5&2&5\\5&4&5&5\\2&5&2&5\\5&5&5&4}\]

  Obsérvese que la matriz de adyacencia es simétrica (porque el grafo es no dirigido), y también lo son, por tanto, las matrices $M^2$ y $M^3$, lo cual significa que el número de caminos que conectan el nodo $i$ con el nodo $j$ es igual que el número de caminos que conectan el nodo $j$ con el $i$.
\end{example}

\chapter{Determinantes}

\newpage\section{Determinantes de segundo orden}

\begin{definition}
  [Determinante de segundo orden] Dada una matriz cuadrada de dimensión $2 \times 2$, $A = \left(\begin{array}{cc} a_{11} & a_{12}\\ a_{21} & a_{22} \end{array}\right)$, se llama {\tmstrong{determinante}} de $A$ al escalar que resulta de la operación $a_{11} \cdot a_{22} - a_{21} \cdot a_{12}$. Se representa por $\det ( A )$, $\left|\begin{array}{c}  A \end{array}\right|$ o $\left|\begin{array}{cc} a_{11} & a_{12}\\ a_{21} & a_{22} \end{array}\right|$.
  \begin{center}
    $\det ( A ) = \left|\begin{array}{c}
      A
    \end{array}\right| = \left|\begin{array}{cc}
      a_{11} & a_{12}\\
      a_{21} & a_{22}
    \end{array}\right| = a_{11} \cdot a_{22} - a_{21} \cdot a_{12}$
  \end{center}
\end{definition}

  \begin{example}
    Sea la matriz $A = \left(\begin{array}{cc}
      1 & 2\\
      3 & 4
    \end{array}\right)$. El determinante de $A$ es $- 2$, ya que:
    
    \[\det ( A ) = \left|\begin{array}{cc}
      1 & 2\\
      3 & 4
    \end{array}\right| = 1 \cdot 4 - 3 \cdot 2 = - 2\]
  \end{example}


\section{Determinantes de tercer orden}

\begin{definition}
  [Determinante de tercer orden] Dada una matriz cuadrada de dimensión $3 \times 3$, $A =
  \left(\begin{array}{ccc}
    a_{11} & a_{12} & a_{13}\\
    a_{21} & a_{22} & a_{23}\\
    a_{31} & a_{32} & a_{33}
  \end{array}\right)$, se llama {\tmstrong{determinante}} de $A$ al escalar que se obtiene como resultado de la siguiente operación ({\tmstrong{Regla de
  Sarrus}}):
  \begin{center}
    $\left|\begin{array}{ccc}
      a_{11} & a_{12} & a_{13}\\
      a_{21} & a_{22} & a_{23}\\
      a_{31} & a_{32} & a_{33}
    \end{array}\right| = a_{11} \cdot a_{22} \cdot a_{33} + a_{12} \cdot
    a_{23} \cdot a_{31} + a_{13} \cdot a_{21} \cdot a_{32} - a_{13} \cdot
    a_{22} \cdot a_{31} - a_{12} \cdot a_{21} \cdot a_{33} - a_{11} \cdot
    a_{23} \cdot a_{32}$
  \end{center}
  Se representa por $\det ( A )$ o bien $\left|\begin{array}{c}
    A
  \end{array}\right|$.
\end{definition}


  \begin{example}
    Sea la matriz $A = \left(\begin{array}{ccc}
      1 & - 2 & 4\\
      5 & 3 & 2\\
      - 1 & 0 & 2
    \end{array}\right)$. Su determinante es $42$, ya que:
    
    \[\det ( A ) = \left|\begin{array}{ccc}
      1 & - 2 & 4\\
      5 & 3 & 2\\
      - 1 & 0 & 2
    \end{array}\right| = 1 \cdot 3 \cdot 2 + ( - 2 ) \cdot 2 \cdot ( - 1 ) + 4
    \cdot 5 \cdot 0 - 4 \cdot 3 \cdot ( - 1 ) - ( - 2 ) \cdot 5 \cdot 2 - 1
    \cdot 2 \cdot 0 = 6 + 4 + 0 + 12 + 20 - 0 = 42\]
  \end{example}

\newpage\section{Determinantes de cualquier orden}

\begin{definition}
  [Submatriz complementaria] Dada una matriz cuadrada $A$ y un elemento de $A$, $a_{i j}$, se llama {\tmstrong{submatriz complementaria}} de $a_{i j}$ a la matriz que se obtiene al quitar de $A$ la fila y la columna en las que se encuentra dicho elemento. Se representa por $A_{i j}$.
\end{definition}

  \begin{example}
    Escribe la submatriz complementaria de $a_{21}$ en la matriz $A = \left(\begin{array}{ccc}
      1 & 2 & - 1\\
      3 & 1 & 0\\
      - 4 & 1 & 2
    \end{array}\right)$:
    
    $$A_{21} = \left(\begin{array}{cc}
      2 & - 1\\
      1 & 2
    \end{array}\right).$$
  \end{example}


\begin{definition}
  [Adjunto] Dada una matriz cuadrada $A$, se llama {\tmstrong{adjunto}} (o cofactor) del elemento $a_{i j}$ al determinante de su submatriz complementaria,
  multiplicado por $+ 1$ o $- 1$ según la suma $i + j$ sea par o impar, respectivamente. Se representa por $\alpha_{i j}$.
  
      $$\alpha_{i j} = ( - 1 )^{i + j} |A_{i j} |$$
  
\end{definition}

  \begin{example}
    Calcula el adjunto de $a_{32}$ en la matriz $A = \left(\begin{array}{cccc}
      2 & 1 & - 1 & 4\\
      1 & 3 & 2 & 1\\
      3 & 2 & - 1 & 6\\
      5 & - 4 & 2 & - 1
    \end{array}\right)$.
    
    Calculamos la submatriz complementaria de $a_{32}$ eliminando la fila 3 y la columna 2 de la matriz $A$, que son la fila y la columna de $a_{32}$.

    Se obtiene: $A_{32} = \left(\begin{array}{ccc}
      2 & - 1 & 4\\
      1 & 2 & 1\\
      5 & 2 & - 1
    \end{array}\right)$.
    
    El determinante de $A_{32}$ lo calculamos aplicando la regla de Sarrus:
    
   $$|A_{32} | = \left|\begin{array}{ccc}
      2 & - 1 & 4\\
      1 & 2 & 1\\
      5 & 2 & - 1
    \end{array}\right| = 2 \cdot 2 \cdot ( - 1 ) + ( - 1 ) \cdot 1 \cdot 5 + 4
    \cdot 1 \cdot 2 - 2 \cdot 1 \cdot 2 - ( - 1 ) \cdot 1 \cdot ( - 1 ) - 4
    \cdot 2 \cdot 5 = - 46$$
    
    Finalmente, para calcular el adjunto de $a_{32}$, multiplicamos $|A_{32} |$ por $- 1$ ya que la posición de $a_{32}$ es impar, pues $3 + 2 = 5$. Es decir:
    
    $$\alpha_{32} = ( - 1 )^{3 + 2} \cdot |A_{32} | = ( - 1 ) \cdot ( - 46 ) =  46$$
  \end{example}

\begin{definition}
  [Determinante de una matriz cuadrada] Dada una matriz cuadrada $A$ de dimensión $n \times n$ cualquiera, se llama {\tmstrong{determinante}} de $A$ al escalar que se obtiene por el procedimiento siguiente:
  \begin{itemize}
    \item se elige una fila o columna cualquiera de $A$ (el resultado será el mismo);
    
    \item se calculan los adjuntos de los elementos de dicha fila o columna;
    
    \item se multiplica cada elemento de dicha fila o columna por su adjunto;
    
    \item se suman todos los productos anteriores.
  \end{itemize}

    $$\det ( A ) = |a_{i j} | = a_{k 1} \cdot \alpha_{k 1} + a_{k 2} \cdot \alpha_{k 2} + \ldots + a_{k n} \cdot \alpha_{k n}$$

  El determinante de una matriz de dimensión $n \times n$ se dice que es {\tmstrong{de orden n}}.
\end{definition}

  \begin{example}
    Calcular el determinante siguiente desarrollándolo por los adjuntos de la primera fila:

    $$\deter{ccc}{2&-1&3\\4&1&5\\3&3&-2}$$

    \begin{align*}
      \deter{ccc}{2&-1&3\\4&1&5\\3&3&-2} & = 2\alpha_{11}-\alpha_{12}+3\alpha_{13} \\
      & = 2\deter{cc}{1&5\\3&-2}-(-1)\deter{cc}{4&5\\3&-2}+3\deter{cc}{4&1\\3&3} \\
      & = 2(-2-15)+(-8-15)+3(12-3) \\
      & = -30
    \end{align*}
  \end{example}

  \begin{example}
    Calcular el determinante siguiente: $|A| = \left|\begin{array}{cccc}
      1 & - 1 & 1 & - 1\\
      0 & 0 & 1 & 2\\
      - 2 & - 1 & 2 & - 3\\
      2 & 5 & 1 & 3
    \end{array}\right|$.
    
    Vamos a desarrollarlo por la 4ª fila (habría sido más inteligente elegir la fila 2, que tiene 2 ceros).
    
    Calculamos los adjuntos de los elementos de dicha fila (sin olvidarnos de multiplicar por +1 o $- 1$, dependiendo de la posición):
    
    \[\alpha_{41} = ( - 1 )^{4 + 1} \left|\begin{array}{ccc}
      - 1 & 1 & - 1\\
      0 & 1 & 2\\
      - 1 & 2 & - 3
    \end{array}\right| = - 1 \cdot 4 = - 4\]
    
    \[\alpha_{42} = ( - 1 )^{4 + 2} \left|\begin{array}{ccc}
      1 & 1 & - 1\\
      0 & 1 & 2\\
      - 2 & 2 & - 3
    \end{array}\right| = + 1 \cdot ( - 13 ) = - 13\]
    
    \[\alpha_{43} = ( - 1 )^{4 + 3} \left|\begin{array}{ccc}
      1 & - 1 & - 1\\
      0 & 0 & 2\\
      - 2 & - 1 & - 3
    \end{array}\right| = - 1 \cdot 6 = - 6\]
    
    \[\alpha_{44} = ( - 1 )^{4 + 4} \left|\begin{array}{ccc}
      1 & - 1 & 1\\
      0 & 0 & 1\\
      - 2 & - 1 & 2
    \end{array}\right| = 1 \cdot 3 = 3\]
    
    Multiplicamos cada elemento de la fila 4 por su adjunto, y sumamos:
    
    \[\det ( A ) = a_{41} \cdot \alpha_{41} + a_{42} \cdot \alpha_{42} + a_{43} \cdot \alpha_{43} + a_{44} \cdot \alpha_{44} = 2 \cdot ( - 4 ) + 5 \cdot ( - 13 ) + 1 \cdot ( - 6 ) + 3 \cdot 3 = - 70\]
  \end{example}


{}

\newpage\section{Propiedades de los determinantes}

\begin{theorem}
  Todo determinante de orden cualquiera cumple las propiedades siguientes (para mayor claridad, las propiedades se expresan con determinantes de tercer orden, pero todas ellas son válidas para determinantes de cualquier orden; igualmente, se expresan las propiedades referidas a las filas, pero todas ellas son válidas también para las columnas):
  
  \begin{enumerate}
    \item Multilinealidad (suma): $\left|\begin{array}{ccc}
      a + a' & b + b' & c + c'\\
      d & e & f\\
      g & h & i
    \end{array}\right| = \left|\begin{array}{ccc}
      a & b & c\\
      d & e & f\\
      g & h & i
    \end{array}\right| + \left|\begin{array}{ccc}
      a' & b' & c'\\
      d & e & f\\
      g & h & i
    \end{array}\right|$.
    
    \item Multilinealidad (producto por escalar): $\left|\begin{array}{ccc}
      \lambda a & \lambda b & \lambda c\\
      d & e & f\\
      g & h & i
    \end{array}\right| = \lambda \left|\begin{array}{ccc}
      a & b & c\\
      d & e & f\\
      g & h & i
    \end{array}\right|$.
    
    \item Si dos filas o dos columnas son iguales, el determinante es cero:
    $\left|\begin{array}{ccc}
      a & b & c\\
      d & e & f\\
      d & e & f
    \end{array}\right| = 0$.
    
    \item El determinante de la matriz identidad es 1: $\det ( I ) = 1$.
    
    \item Si se intercambian una fila con otra fila, o una columna con otra
    columna, el determinante cambia de signo:
    
    $\left|\begin{array}{ccc}
      a & b & c\\
      d & e & f\\
      g & h & i
    \end{array}\right| = - \left|\begin{array}{ccc}
      g & h & i\\
      d & e & f\\
      a & b & c
    \end{array}\right|$
    
    \item Si una fila o columna tiene todos los elementos nulos, el
    determinante es 0: $\left|\begin{array}{ccc}
      a & b & c\\
      0 & 0 & 0\\
      g & h & i
    \end{array}\right| = 0$
    
    \item Si dos filas o dos columnas son proporcionales, el determinante es
    cero: $\left|\begin{array}{ccc}
      a & b & c\\
      d & e & f\\
      \lambda a & \lambda b & \lambda c
    \end{array}\right| = 0$.
    
    \item Si a una fila o columna se le suma otra fila o columna, el
    determinante no varía:
    
    $\left|\begin{array}{ccc}
      a & b & c\\
      d & e & f\\
      g & h & i
    \end{array}\right| = \left|\begin{array}{ccc}
      a & b & c\\
      d + a & e + b & f + c\\
      g & h & i
    \end{array}\right|$
    
    \item Si a una fila o columna se le suma otra fila o columna multiplicada
    por un escalar, el determinante no varía:
    
    $\left|\begin{array}{ccc}
      a & b & c\\
      d & e & f\\
      g & h & i
    \end{array}\right| = \left|\begin{array}{ccc}
      a & b & c\\
      d + \lambda a & e + \lambda b & f + \lambda c\\
      g & h & i
    \end{array}\right|$
    
    \item El determinante del producto es igual al producto de los
    determinantes:
    
    $\det ( A \cdot B ) = \det ( A ) \cdot \det ( B )$
    
    \item El determinante de una matriz es igual al de su traspuesta: $\det (
    A ) = \det ( A^t )$.
  \end{enumerate}
\end{theorem}

\begin{remark}
  El determinante de una matriz es un escalar (un número).
\end{remark}

\begin{remark}
  El símbolo que se usa para representar un determinante es el mismo que el de valor absoluto de un número. El significado se distingue por el contenido:
  $|A|$ representa al determinante de $A$ si $A$ es una matriz (en este caso no puede significar valor absoluto porque una matriz no tiene valor
  absoluto); $|A|$ representa valor absoluto de $A$ si $A$ es un número real (en este caso no puede significar determinante de $A$ porque los números
  reales no tienen determinante).
\end{remark}

\begin{remark}
  Las barras verticales del símbolo del determinante sustituyen a los paréntesis de la matriz, que no se suelen escribir:
  
  $$\left|\begin{array}{ccc}
    1 & 2 & 3\\
    4 & 5 & 6\\
    7 & 8 & 9
  \end{array}\right| = \left|\begin{array}{c}
    \left(\begin{array}{ccc}
      1 & 2 & 3\\
      4 & 5 & 6\\
      7 & 8 & 9
    \end{array}\right)
  \end{array}\right| = \det \left(\begin{array}{ccc}
    1 & 2 & 3\\
    4 & 5 & 6\\
    7 & 8 & 9
  \end{array}\right)$$
\end{remark}

\begin{remark}
  Sólo tienen determinante las matrices cuadradas. La expresión
 $\left|\begin{array}{ccc}
    1 & 2 & 3\\
    4 & 5 & 6
  \end{array}\right|$ no tiene sentido.
\end{remark}

\begin{remark}
  El determinante de una matriz de un elemento es dicho elemento.
\end{remark}

\begin{remark}
  Cualquier determinante se puede desarrollar por los adjuntos de una fila o columna (también los de orden 2 y orden 3), aunque sólo suelen calcularse
  así los de orden mayor que 3.
\end{remark}

\begin{remark}
  El determinante de una matriz triangular es igual al producto de los elementos de su diagonal (basta desarrollar por la primera columna para
  comprobarlo):
  
  $$\left|\begin{array}{cccc}
    a_{11} & a_{12} & a_{13} & a_{14}\\
    0 & a_{22} & a_{23} & a_{24}\\
    0 & 0 & a_{33} & a_{34}\\
    0 & 0 & 0 & a_{44}
  \end{array}\right| = a_{11} \cdot a_{22} \cdot a_{33} \cdot a_{44}$$
\end{remark}

\begin{remark}
  El siguiente determinante se llama {\tmem{determinante de Vandermonde}}. Se calcula restando a cada fila la anterior multiplicada por $a$:
  
  $$\left|\begin{array}{cccc}
    1 & 1 & 1 & 1\\
    a & b & c & d\\
    a^2 & b^2 & c^2 & d^2\\
    a^3 & b^3 & c^3 & d^3
  \end{array}\right| = ( b - a ) ( c - a ) ( d - a ) ( c - b ) ( d - b ) ( d - c )$$
\end{remark}

\begin{remark}
  El determinante de la suma NO es igual a la suma de los determinantes.
\end{remark}

\begin{remark}
  De la propiedad 2 se deduce que: $\det ( \lambda A_n ) = \lambda^n \det ( A_n )$, siendo $A_n$ una matriz cuadrada de dimensión $n \times n$. Por ejemplo, si $A$ es $2\times2$, entonces $\det(3A)=3^2\det(A)=9\det(A)$.
\end{remark}

\begin{remark}
  Para calcular determinantes de orden superior a tres se puede seguir el
  procedimiento siguiente ({\tmstrong{reducción de orden}}):
  \begin{enumerate}
    \item Elegir una fila o columna (con el mayor número posible de ceros).
    
    \item Aplicar las propiedades de los determinantes para anular todos los
    elementos de dicha fila o columna excepto uno (siempre es posible!).
    
    \item Desarrollar por los adjuntos de esa fila o columna: como todos los
    elementos de dicha fila o columna son cero excepto uno, sólo habrá que
    calcular un adjunto (el del elemento no nulo) y multiplicarlo por ese
    elemento.
  \end{enumerate}
\end{remark}


  \begin{example}
    Calcular el siguiente determinante: $\left|\begin{array}{cccc}
      1 & 3 & 2 & 1\\
      2 & 1 & - 1 & 4\\
      0 & 2 & - 1 & 6\\
      5 & - 4 & 2 & - 1
    \end{array}\right|$.
    
    Elegimos la primera columna porque tiene un cero.
    
    A la fila 2 le sumamos la primera multiplicada por $- 2$ (según la
    propiedad 9, el determinante no varía):
    
    $$\left|\begin{array}{cccc}
      1 & 3 & 2 & 1\\
      2 & 1 & - 1 & 4\\
      0 & 2 & - 1 & 6\\
      5 & - 4 & 2 & - 1
    \end{array}\right| = \left|\begin{array}{cccc}
      1 & 3 & 2 & 1\\
      2 - 2 \cdot 1 & 1 - 2 \cdot 3 & - 1 - 2 \cdot 2 & 4 - 2 \cdot 1\\
      0 & 2 & - 1 & 6\\
      5 & - 4 & 2 & - 1
    \end{array}\right| = \left|\begin{array}{cccc}
      1 & 3 & 2 & 1\\
      0 & - 5 & - 5 & 2\\
      0 & 2 & - 1 & 6\\
      5 & - 4 & 2 & - 1
    \end{array}\right| =$$
    
    (a la fila 4 le sumamos la fila 1 multiplicada por $- 5$)
    
    $$= \left|\begin{array}{cccc}
      1 & 3 & 2 & 1\\
      0 & - 5 & - 5 & 2\\
      0 & 2 & - 1 & 6\\
      5 - 5 \cdot 1 & - 4 - 5 \cdot 3 & 2 - 5 \cdot 2 & - 1 - 5 \cdot 1
    \end{array}\right| = \left|\begin{array}{cccc}
      1 & 3 & 2 & 1\\
      0 & - 5 & - 5 & 2\\
      0 & 2 & - 1 & 6\\
      0 & - 19 & - 8 & - 6
    \end{array}\right| =$$
    
    (desarrollamos el determinante por los aduntos de la primera columna)
    
    $$= a_{11} \cdot \alpha_{11} + a_{21} \cdot \alpha_{21} + a_{31} \cdot
    \alpha_{31} + a_{41} \cdot \alpha_{41} = 1 \cdot \left|\begin{array}{ccc}
      - 5 & - 5 & 2\\
      2 & - 1 & 6\\
      - 19 & - 8 & - 6
    \end{array}\right| + 0 \cdot \alpha_{21} + 0 \cdot \alpha_{31} + 0 \cdot
    \alpha_{41} = 170$$
  \end{example}


\chapter{Rango de matrices}

\newpage\section{Combinaciones lineales}

\begin{definition}[Combinación lineal]Dado un conjunto de escalares $\{\lambda_1,\cdots,\lambda_k\}$ y un conjunto de matrices del mismo tamaño $\{F_1,F_2,\cdots,F_k\}$, se llama {\tmstrong{combinación lineal}} de dichas matrices a cualquier operación de la forma:
\begin{center}
  $F_i = \lambda_1 F_1 + \lambda_2 F_2 + \ldots + \lambda_k F_k$
\end{center}
Los escalares $\lambda_1$, $\lambda_2$, ... $\lambda_k$ reciben el nombre de {\tmstrong{coeficientes}} de la combinación lineal.
\end{definition}


\begin{remark}Una fila de una matriz $m \times n$ es una matriz de dimensión $1 \times n$. Igualmente, una columna se puede interpretar como una matriz columna. Por tanto, las operaciones con filas o columnas se han de interpretar como operaciones con matrices. En este tema estudiaremos de manera particular las combinaciones lineales entre las filas o las columnas de una matriz.
\end{remark}

\begin{remark}
Si una fila es una combinación lineal de un conjunto de filas, también se dice que {\tmem{depende linealmente}} de ellas.\end{remark} 

\begin{remark}Una fila nula es siempre combinación lineal de cualquier conjunto de filas, ya que, para cualquier conjunto de filas $\{ F_1, F_2, \ldots, F_k \}$ siempre se verifica que: $\left(\begin{array}{cccc}
  0 & 0 & \ldots & 0
\end{array}\right) = 0 \cdot F_1 + 0 \cdot F_2 + \ldots + 0 \cdot F_k$.\end{remark}

\begin{example}Sean $F_1$, $F_2$ y $F_3$ las filas de la matriz $A =
\left(\begin{array}{ccc}
  - 2 & - 11 & 5\\
  0 & - 2 & 1\\
  2 & - 3 & - 12
\end{array}\right)$:

La fila $F_3$ es una combinación lineal de las filas $F_1$ y $F_2$ ya que
$$F_3= - F_1 - 7 F_2$$
En este caso, los coeficientes de la combinación lineal que
relaciona $F_3$ con $F_1$ y $F_2$ son $\lambda_1 = - 1$ y $\lambda_2 = - 7$.\end{example}

\newpage\section{Dependencia lineal}

\begin{definition}[Dependencia lineal]Se dice que un conjunto de filas (o columnas) es {\tmstrong{linealmente dependiente}} (o ligado) si al menos una de las filas (o columnas) de dicho conjunto se puede escribir como combinación lineal de las demás.

Se dice que un conjunto de filas (o columnas) es {\tmstrong{linealmente independiente}} (o libre), si ninguna fila (o columna) de dicho conjunto se puede escribir como combinación lineal de las demás.
\end{definition}

\begin{remark}Sea un conjunto de filas $\{ F_1, F_2, \ldots F_k \}$, y sea $O$ una fila nula. Se puede demostrar que:

$$\text{$\{ F_1, F_2, \ldots F_k \}$} \text{ es linealmente independiente } \Leftrightarrow \left( \overset{k}{\underset{i = 1}{\sum}} \lambda_i F_i = O \Rightarrow \lambda_i = 0, \forall i = 1 \ldots k \right)$$

Es decir, que un conjunto de filas es linealmente independiente si y solo si la única combinación lineal de filas de dicho conjunto que da como resultado
una fila nula es aquella cuyos coeficientes son todos nulos. Por tanto un conjunto de filas es linealmente dependiente si y solo existe alguna
combinación lineal que da como resultado la fila nula y tiene algún coeficiente distinto de cero. Otro tanto podría decirse de las columnas.
\end{remark}

\begin{remark}Un conjunto de filas que incluya una fila nula siempre es ligado, ya que, según se vio, la fila nula se puede escribir siempre como combinación lineal de cualquier conjunto de filas.
\end{remark}

\begin{remark}
  En realidad, el concepto de dependencia lineal es aplicable a matrices de cualquier tamaño. Sin embargo, nos interesa ahora estudiar la dependencia lineal de las filas y columnas de una matriz.
\end{remark}

\begin{example}Demostrar que las filas de la matriz $A = \left(\begin{array}{ccc}
  1 & 1 & 0\\
  1 & 1 & 1\\
  0 & 1 & - 1
\end{array}\right)$ son linealmente independientes.

Demostraremos que la relación $\alpha F_1 + \beta F_2 + \gamma F_3 =
\left(\begin{array}{ccc}
  0 & 0 & 0
\end{array}\right)$ solo se cumple si $\alpha = \beta = \gamma = 0$.

\begin{eqnarray*}\alpha F_1 + \beta F_2 + \gamma F_3 = \left(\begin{array}{ccc}
  0 & 0 & 0
\end{array}\right) & \Leftrightarrow & \alpha \left(\begin{array}{ccc}
  1 & 1 & 0
\end{array}\right) + \beta \left(\begin{array}{ccc}
  1 & 1 & 1
\end{array}\right) + \gamma \left(\begin{array}{ccc}
  0 & 1 & - 1
\end{array}\right) = \left(\begin{array}{ccc}
  0 & 0 & 0
\end{array}\right)\\
& \Leftrightarrow &
\left(\begin{array}{c}
  \alpha + \beta, \alpha + \beta + \gamma, \beta - \gamma
\end{array}\right) = \left(\begin{array}{ccc}
  0 & 0 & 0
\end{array}\right) \\
& \Leftrightarrow & \left\{\begin{array}{l}
  \alpha + \beta = 0\\
  \alpha + \beta + \gamma = 0\\
  \beta - \gamma = 0
\end{array}\right. \\
& \Leftrightarrow & \left\{\begin{array}{l}
  \alpha = - \beta\\
  - \beta + \beta + \gamma = 0\\
  \beta = \gamma
\end{array}\right. \\
& \Leftrightarrow & \left\{\begin{array}{l}
  \alpha = 0\\
  \beta = 0\\
  \gamma = 0
\end{array}\right.
\end{eqnarray*}

Para que la combinación lineal sea nula, han de ser 0 todos los coeficientes,
luego son independientes.
\end{example}

\newpage\section{Rango}

\begin{definition}El {\tmstrong{rango de filas}} de una matriz $A$ es $m$ si y solo si se cumplen las dos condiciones siguientes:
\begin{enumerate}
  \item Existe al menos un conjunto formado por $m$ filas de $A$ que es linealmente independiente;
  
  \item Cualquier conjunto formado por más de $m$ filas de $A$ es linealmente dependiente.
\end{enumerate}
El {\tmstrong{rango de columnas}} de una matriz $A$ es $n$ si y solo si se cumplen las condiciones siguientes:
\begin{enumerate}
  \item Existe al menos un conjunto formado por $n$ columnas de $A$ linealmente independiente;
  
  \item Cualquier conjunto formado por más de $n$ columnas de $A$ es linealmente dependiente.
\end{enumerate}
\end{definition}

\begin{theorem}[Teorema del Rango] El rango de filas de cualquier matriz es igual a su rango de columnas, y se denomina simplemente {\tmstrong{rango de $A$}}.
\end{theorem}

\begin{remark}El rango de una matriz es el mayor número de filas linealmente independientes que se pueden tomar de la misma, y también el mayor número de
columnas linealmente indendientes.
\end{remark}

\begin{remark}Si $A$ es una matriz de dimensión $m \times n$, y $r = \tmop{rango} ( A )$, entonces $r \leqslant \min ( m, n )$.
\end{remark}

\begin{remark}Si en una matriz de rango $r$ tomamos $r$ filas linealmente independientes (se puede, por ser el rango $r$), las demás filas de la matriz
dependen linealmente de esas $r$ filas (es decir, se pueden escribir como combinaciones lineales de ellas).
\end{remark}

\begin{example}
Sea la matriz $A = \left(\begin{array}{cccc}
  1 & 0 & 3 & 1\\
  0 & 2 & 0 & 2\\
  0 & 0 & 3 & 3\\
  0 & 2 & 0 & 2\\
  1 & 0 & 3 & 1
\end{array}\right)$.

Las columnas $C_1$, $C_2$ y $C_3$ forman un conjunto linealmente
independiente, ya que la relación $\lambda_1 C_1 + \lambda_2 C_2 + \lambda_3
C_3 = O$ equivale al sistema $\lambda_1 + 3 \lambda_3 = 0 ; 2 \lambda_2 = 0 ;
3 \lambda_3 = 0$, cuyas únicas soluciones son, evidentemente, $\lambda_1 =
\lambda_2 = \lambda_3 = 0$. Por tanto, $\tmop{rango} ( A ) \geqslant 3$.

Por otra parte, la columna $C_4$ es una combinación lineal de las tres
primeras, ya que, se cumple que $C_4 = - 2 C_1 + C_2 + C_3$. Por tanto,
$\tmop{rango} ( A ) = 3$.
\end{example}

\newpage\section{Propiedad fundamental del rango}

\begin{definition}[Operaciones elementales sobre las filas (o sobre las columnas)]Se llaman {\tmstrong{operaciones
elementales sonre las filas (o sobre las columnas)}} a las siguientes manipulaciones aplicadas a las filas (o columnas)
de una matriz:

\begin{enumerate}
  \item Cambiar el orden en el que aparecen las filas (o columnas).
  
  \item Multiplicar una fila (o columna) por un escalar no nulo.
  
  \item Sumar a una fila (o columna) otra fila (o columna) cualquiera.
  
  \item Aplicar, reiteradamente, cualesquiera de las operaciones anteriores (en particular, sumar a una fila -o columna-, una combinación lineal de las
  demás filas -o columnas-).
\end{enumerate}
\end{definition}

\begin{theorem}[Propiedad fundamental del rango]El rango de una matriz no varía si se realizan en ella cualesquiera operaciones elementales.
\end{theorem}

\begin{remark}
  La propiedad fundamental del rango se refiere tanto a las operaciones elementales sobre las filas,
  como sobre las columnas, y a cualquier secuencia de las mismas (en que pueden combinarse ambos
  tipos de operaciones elementales). Sin embargo, nosotros utilizaremos casi exclusivamente las
  operaciones elementales sobre las filas, ya que la distinción es importante en algunas de sus
  aplicaciones (cálculo de la matriz inversa y resolución de sistemas).
\end{remark}

\begin{definition}[Matrices equivalentes]Dos matrices de la misma dimensión se
dice que son {\tmstrong{matrices equivalentes}} si tienen el mismo rango.
\end{definition}

\begin{remark}
  La propiedad fundamental del rango podría, por tanto, enunciarse diciendo que las operaciones
  elementales transforman siempre una matriz en otra matriz equivalente.
\end{remark}

\begin{remark}
  Se dice que dos matrices son \emph{equivalentes por filas} si una de ellas se ha obtenido
  aplicando a la otra una secuencia de operaciones elementales sobre las filas. Obviamente, dos
  matrices equivalentes por filas son también equivalentes (tienen el mismo rango).
\end{remark}

\begin{definition}[Matriz canónica de equivalencia]Se llama matriz canónica de
equivalencia de dimensión $m \times n$ y rango $r$ a la matriz que tiene nulos
todos sus elementos excepto los primeros $r$ elementos de su ``diagonal
principal'', que son iguales a 1. Se representa por $C_r$.
\end{definition}

\begin{theorem}
  Cualquier matriz de rango $r$ se puede transformar mediante adecuadas
  operaciones elementales en la matriz canónica de equivalencia.
\end{theorem}

\begin{example}
La matriz canónica de equivalencia de rango 3 y dimensión $4 \times 5$
es:

$$C_3 = \left(\begin{array}{ccccc}
  1 & 0 & 0 & 0 & 0\\
  0 & 1 & 0 & 0 & 0\\
  0 & 0 & 1 & 0 & 0\\
  0 & 0 & 0 & 0 & 0
\end{array}\right)$$

Cualquier matriz $4 \times 5$ y rango 3 se puede transformar en $C_3$ mediante
operaciones elementales.
\end{example}

\newpage\section{Cálculo del rango por el método de Gauss}

\begin{definition}[Matriz escalonada por filas]Es una matriz en la que todas las filas a partir de
la 2ª comienzan con una sucesión de ceros que contiene al menos un cero más que la sucesión inicial
de la fila anterior, o los mismos si la fila anterior es nula.\end{definition}
\begin{example}
  $$M = \left(\begin{array}{ccccc}  1 & 2 & 3 & 0 & 4\\  0 & 5 & 6 & 7 & 0\\  0 & 0 & 0 & 8 & 9\\  0 & 0 & 0 & 0 & 0\end{array}\right)$$
\end{example}

\begin{theorem}
  El rango de una matriz escalonada por filas es igual al número de filas no nulas que
  tiene.
\end{theorem}

\begin{remark}Basándose en el resultado anterior, es posible calcular el rango de
cualquier matriz transformándola mediante operaciones elementales en una
matriz escalonada por filas equivalente (esta transformación siempre es posible utilizando solo
operaciones elementales sobre las filas).\end{remark}

\begin{remark}
  Existe un caso concreto de matriz escalonada por filas que se llama \emph{matriz reducida
    escalonada por filas}. Es una matriz escalonada por filas en la que el primer elemento no nulo
  de cada fila vale siempre 1, y es el único elemento no nulo de su columna. Para cada matriz existe
  una única matriz reducida escalonada por filas. No es necesario, para conocer el rango, obtener
  este caso tan simplificado de matriz escalonada por filas equivalente.
\end{remark}

\begin{remark}Para transformar una matriz en otra equivalente (igual rango) que sea
escalonada por filas se sigue el procedimiento siguiente ({\tmstrong{Método de Gauss}}).
Realizando las operaciones elementales adecuadas se coloca un 1
en la posición (1, 1). A continuación, a cada fila se le resta la primera
multiplicada por el primer elemento de cada fila (i.e. a la 3ª
fila se le resta la 1ª multiplicada por $a_{31}$). De esta
manera, todos los números que hay por debajo del primer elemento de la
1ª columna serán 0. Pasando a la 2ª fila, si el
segundo elemento es nulo y tiene debajo algún elemento no nulo, se cambia el
orden de las filas, de modo que dicho elemento no nulo quede en la segunda
fila, y se toma como ``pivote''. Por el mismo procedimiento anterior, se
convierten en 0 todos los elementos que haya debajo de dicho``pivote''. El
procedimiento continúa cogiendo como ``pivote'' el primer elemento no nulo de la
3ª fila, y realizando el mismo proceso. Terminamos cuando
lleguemos a una matriz escalonada por filas.\end{remark}

\begin{example}Calcular el rango de la siguiente matriz:

$$A = \left(\begin{array}{ccccc}
  1 & 3 & - 2 & 1 & 2\\
  2 & 5 & 1 & - 3 & 5\\
  - 1 & 3 & 2 & - 3 & - 3\\
  3 & - 4 & - 1 & 2 & 9
\end{array}\right)$$

Tomando el 1 de la posición (1,1) como pivote, anulamos todos los demás
elementos de su columna:

$$\left\{\begin{array}{l}
  F_1' = F_1\\
  F_2' = F_2 - 2 \cdot F_1\\
  F_3' = F_3 + F_1\\
  F_4' = F_4 - 3 \cdot F_1
\end{array}\right. \Rightarrow A' = \left(\begin{array}{ccccc}
  1 & 3 & - 2 & 1 & 2\\
  0 & - 1 & 5 & - 5 & 1\\
  0 & 6 & 0 & - 2 & - 1\\
  0 & - 13 & 5 & - 1 & 3
\end{array}\right)$$

A continuación, tomamos el $- 1$ de la segunda fila como pivote, y anulamos
todos los elementos que tiene por debajo en su columna:

$$\left\{\begin{array}{l}
  F_1'' = F_1'\\
  F_2'' = F_2'\\
  F_3'' = F_3' + 6 \cdot F_2'\\
  F_4'' = F_4' - 13 \cdot F_2'
\end{array}\right. \Rightarrow A'' = \left(\begin{array}{ccccc}
  1 & 3 & - 2 & 1 & 2\\
  0 & - 1 & 5 & - 5 & 1\\
  0 & 0 & 30 & - 32 & 5\\
  0 & 0 & - 60 & 64 & - 10
\end{array}\right)$$

Finalmente, tomamos como pivote el 30 de la tercera columna y anulamos el
número que tiene debajo:

$$\left\{\begin{array}{l}
  F_1''' = F_1''\\
  F_2''' = F_2''\\
  F_3''' = F_3''\\
  F_4''' = F_4'' + 2 \cdot F_3''
\end{array}\right. \Rightarrow A''' = \left(\begin{array}{ccccc}
  1 & 3 & - 2 & 1 & 2\\
  0 & - 1 & 5 & - 5 & 1\\
  0 & 0 & 30 & - 32 & 5\\
  0 & 0 & 0 & 0 & 0
\end{array}\right)$$

Hemos obtenido una matriz escalonada por filas con 3 filas no nulas, cuyo rango es, por
tanto, 3. Las matrices $A$, $A'$, $A''$ y $A'''$ tienen todas el mismo rango,
pues se han obtenido mediante operaciones elementales. Por tanto,
$$\tmop{rango} ( A ) = 3.$$
\end{example}

\begin{remark}
  Existe una relación importante entre las operaciones elementales y el producto de matrices.

  El producto de una matriz por una matriz columna equivale a una combinación lineal de las columnas de la matriz:
  \[\matriz{ccc}{7&8&-9\\1&2&1\\-3&0&1}\matriz{c}{1\\5\\3} = \matriz{ccc}{1\cdot7+5\cdot8+3\cdot(-9)\\1\cdot1+5\cdot2+3\cdot1\\1\cdot(-3)+5\cdot0+3\cdot1} = 1\matriz{c}{7\\1\\-3}+5\matriz{c}{8\\2\\0}+3\matriz{c}{-9\\1\\1}=\matriz{c}{20\\14\\0}\]

  Por lo tanto, el producto de dos matrices equivale a una combinación lineal de las columnas de la primera por cada columna de la segunda:
  \[\matriz{ccc}{7&8&-9\\1&2&1\\-3&0&1}\matriz{ccc}{1&2&3\\5&-1&4\\3&0&3} =\]
  \[= \matriz{ccc}{1\matriz{c}{7\\1\\-3}+5\matriz{c}{8\\2\\0}+3\matriz{c}{-9\\1\\1} & 2\matriz{c}{7\\1\\-3}-1\matriz{c}{8\\2\\0}+0\matriz{c}{-9\\1\\1} & 3\matriz{c}{7\\1\\-3}+4\matriz{c}{8\\2\\0}+3\matriz{c}{-9\\1\\1}}\]
  \[ = \matriz{ccc}{20&6&26\\14&0&14\\0&-6&-6}\]

  De modo análogo, el producto de una matriz fila por una matriz, equivale a una combinación lineal de las filas de la matriz:
  \[\matriz{ccc}{7&8&-9}\matriz{ccc}{1&2&3\\5&-1&4\\3&0&3} = 7\matriz{ccc}{1&2&3}+8\matriz{ccc}{5&-1&4}-9\matriz{ccc}{3&0&3} = \matriz{ccc}{20&6&26}\]

  Finalmente, el producto de una matriz por otra equivale a realizar una combinación lineal de las filas de la segunda por cada fila de la primera:
  \[\matriz{ccc}{7&8&-9\\1&2&1\\-3&0&1}\matriz{ccc}{1&2&3\\5&-1&4\\3&0&3} = \matriz{c}{7\matriz{ccc}{1&2&3}+8\matriz{ccc}{5&-1&4}-9\matriz{ccc}{3&0&3}\\1\matriz{ccc}{1&2&3}+2\matriz{ccc}{5&-1&4}+1\matriz{ccc}{3&0&3}\\-3\matriz{ccc}{1&2&3}+0\matriz{ccc}{5&-1&4}+1\matriz{ccc}{3&0&3}} = \matriz{ccc}{20&6&17\\14&0&15\\26&14&-6}\]

  Dado que las operaciones elementales, excepto los cambios de orden, consisten en sustituir una fila o columna por una combinación lineal de esa fila o columna con otras filas o columnas de la matriz, resulta que podemos expresarlas como productos de matrices. Por ejemplo, si, en la matriz $A$,  queremos sumar a la segunda fila la primera multiplicada por $-5$, podríamos hacerlo así:
  \[A=\matriz{ccc}{1&2&3\\5&-1&4\\3&0&3} \sim E_{21}A=\matriz{ccc}{1&0&0\\-5&1&0\\0&0&1}\matriz{ccc}{1&2&3\\5&-1&4\\3&0&3}=\matriz{ccc}{1&2&3\\0&-11&-11\\3&0&3}\]

  Estas matrices que realizan operaciones elementales, se llaman \emph{matrices elementales}. También podemos realizar un cambio de orden de filas multiplicando por una matriz elemental:
  \[A=\matriz{ccc}{1&2&3\\5&-1&4\\3&0&3} \sim PA=\matriz{ccc}{0&0&1\\1&0&0\\0&1&0}\matriz{ccc}{1&2&3\\5&-1&4\\3&0&3} = \matriz{ccc}{3&0&3\\1&2&3\\5&-1&4}\]

  El método de eliminación de Gauss se puede expresar mediante una secuencia de productos de matrices elementales.
  
\end{remark}

\newpage\section{Cálculo del rango por determinantes}

\begin{definition}[Submatriz]Dada una matriz $A$, se llama submatriz de $A$ a cualquier matriz obtenida al quitar de $A$ algunas filas y/o columnas.
\end{definition}

\begin{definition}[Menor]Dada una matriz $A$, se llama menor de orden p de A al determinante de una submatriz de A de dimensión $p \times p$.
\end{definition}

\begin{definition}[Rango de menores]Dada una matriz $A$, se dice que su rango de menores es p si $A$ tiene algún menor de orden p que no sea nulo, y todos los menores de $A$ de orden mayor que p son nulos.\end{definition}

\begin{theorem}
  El rango de menores de una matriz es igual a su rango.
\end{theorem}

\begin{remark}De todo lo anterior se deriva el método de cálculo del rango por determinantes. Para calcular el rango de una matriz por determinantes, habría que calcular todos sus menores: el rango sería el orden del menor no nulo de mayor orden (se recomienda al alumno que vuelva a leer esta frase y la analice hasta comprenderla: ``\textit{el rango es el orden del menor no nulo de mayor orden}'').

Una matriz tiene muchos menores, por lo que para determinar el menor no nulo de mayor orden conviene proceder metódicamente. En primer lugar se escoge un
menor de orden 2 no nulo (esto es sencillo, basta con que el menor no tenga las filas proporcionales). Si no existiese ninguno, el rango de la matriz
sería 1. Si existe alguno, ya tenemos rango $\geqslant$ 2.

A continuación se ``orla'' el menor escogido con una fila (es decir, se le añade debajo alguna fila de la matriz, pero no completa, sino sólo los elementos correspondientes a las columnas que hay en el menor). A ese menor ``orlado'' con una fila, se le va ``orlando'' con cada columna de la matriz, calculando los menores resultantes, que son de orden 3. Si no se encuentra ningún menor no nulo, se repite el proceso ``orlando'' con las demás filas, hasta encontrar un menor no nulo. Si no se encuentra ninguno con ninguna fila, el rango de la matriz es 2. Si en el proceso de ``orlado'' se encuentra algún menor no nulo, ya sabemos que el rango es mayor o igual que 3.

A partir de ese menor de orden 3 no nulo, repetimos el proceso de ``orlado'', para buscar algún menor de orden 4 no nulo. Así se procede sucesivamente hasta que no se puedan formar menores de mayor orden.\end{remark}

\begin{example}
Calcula el rango de la matriz:
\begin{center}
  $A = \left(\begin{array}{cccccc}
    1 & 2 & 0 & - 5 & - 3 & - 2\\
    3 & 1 & - 1 & 3 & 2 & 4\\
    - 2 & 0 & 2 & 1 & - 1 & 5\\
    2 & - 3 & 1 & 3 & 2 & - 1\\
    1 & - 1 & 3 & - 1 & - 2 & 2\\
    4 & 3 & - 1 & - 2 & - 1 & 2
  \end{array}\right)$
\end{center}
$\left|\begin{array}{cc}
  1 & 2\\
  3 & 1
\end{array}\right| = 1 - 6 = - 5 \neq 0$. Tenemos un menor de orden 2 no nulo,
luego $\tmop{rango} ( A ) \geqslant 2$.

Lo ``orlamos'' con la fila 3 y la columna 3:

$\left|\begin{array}{ccc}
  1 & 2 & 0\\
  3 & 1 & - 1\\
  - 2 & 0 & 2
\end{array}\right| = - 6 \neq 0$. Tenemos un menor de orden 3 no nulo, luego
$\tmop{rango} ( A ) \geqslant 3$.

Lo ``orlamos'' con la fila 4 y la columna 4:

$\left|\begin{array}{cccc}
  1 & 2 & 0 & - 5\\
  3 & 1 & - 1 & 3\\
  - 2 & 0 & 2 & 1\\
  2 & - 3 & 1 & 3
\end{array}\right| = 138 \neq 0$. Tenemos un menor de orden 4 no nulo, luego
$\tmop{rango} ( A ) \geqslant 4$.

Lo ``orlamos'' con la fila 5 y la columna 5:

$\left|\begin{array}{ccccc}
  1 & 2 & 0 & - 5 & - 3\\
  3 & 1 & - 1 & 3 & 2\\
  - 2 & 0 & 2 & 1 & - 1\\
  2 & - 3 & 1 & 3 & 2\\
  1 & - 1 & 3 & - 1 & - 2
\end{array}\right| = 0$. Es nulo, luego tenemos que buscar otro menor de orden
5.

Volvemos al menor de orden 4 no nulo que teníamos y lo ``orlamos'' con la fila 5
y la columna 6:

$\left|\begin{array}{ccccc}
  1 & 2 & 0 & - 5 & - 2\\
  3 & 1 & - 1 & 3 & 4\\
  - 2 & 0 & 2 & 1 & 5\\
  2 & - 3 & 1 & 3 & - 1\\
  1 & - 1 & 3 & - 1 & 2
\end{array}\right| = 0$. Es nulo, luego tenemos que buscar otro menor de orden
5.

Volvemos al menor de orden 4 no nulo, y lo ``orlamos'' con la fila 6 y la
columna 5:

$\left|\begin{array}{ccccc}
  1 & 2 & 0 & - 5 & - 3\\
  3 & 1 & - 1 & 3 & 2\\
  - 2 & 0 & 2 & 1 & - 1\\
  2 & - 3 & 1 & 3 & 2\\
  4 & 3 & - 1 & - 2 & - 1
\end{array}\right| = 0$. También es nulo, luego seguimos probando con orden 5.

``Orlamos'' el menor de orden 4 no nulo con la misma fila (6), y la siguiente
columna (6):

$\left|\begin{array}{ccccc}
  1 & 2 & 0 & - 5 & - 2\\
  3 & 1 & - 1 & 3 & 4\\
  - 2 & 0 & 2 & 1 & 5\\
  2 & - 3 & 1 & 3 & - 1\\
  4 & 3 & - 1 & - 2 & 2
\end{array}\right| = 0$. También nulo.

Como ya no quedan filas para seguir ``orlando'', podemos asegurar que no hay ningún menor de orden 5 no nulo. Pero teníamos uno de orden 4 no nulo, por
tanto, $\tmop{rango} ( A ) = 4$.
\end{example}
 \begin{remark}
  En el caso de una matriz $3\times 4$, que serán las que con más frecuencia utilicemos en este tema, el método anterior es muy sencillo, y se reduce al cálculo de unos pocos determinantes. Lo veremos con un ejemplo, calculando el rango de la siguiente matriz:

  \[A=\matriz{cccc}{-4&-2&0&2\\3&-1&-1&-1\\1&3&1&1}\]

  Empezamos por encontrar un menor de orden 2 no nulo, que nos asegura dos columnas independientes. Tomando las dos primeras columnas, vemos que:

  \[\deter{cc}{-4&-2\\3&-1}=4+6=10\neq0\]

  Luego las dos primeras columnas son independientes, luego $\rank(A)\geq2$.

  Orlamos el menor anterior con una fila (la única que queda) y con la tercera columna:

  \[\deter{ccc}{-4&-2&0\\3&-1&-1\\1&3&1}=4+2+6-12=0\]

  Esto significa que la tercera columna es combinación lineal de las dos primeras (depende linealmente de ellas). Pero todavía tenemos que estudiar la cuarta columna para averiguar el rango. Orlamos de nuevo el menor de orden 2 inicial con la tercera fila y con la cuarta columna:

  \[\deter{ccc}{-4&-2&2\\3&-1&-1\\1&3&1}=4+2+18+2+6-12=20\neq0\]

  Por lo tanto, la cuarta columna es independiente de las dos primeras. La matriz tiene tres columnas linealmente independientes, y, por tanto, su rango es 3:

  \[\rank(A)=3\]
\end{remark}

\begin{remark}Sea $A$ una matriz cuadrada de orden $n$, entonces $\tmop{rango} ( A ) = n \Leftrightarrow \det ( A ) \neq 0$, o lo que es lo mismo, $\tmop{rango} ( A ) < n \Leftrightarrow \det ( A ) = 0$. En matrices pequeñas, en lugar del método anterior, se aplica este resultado por un método que podríamos llamar {\tmem{reducción del rango}}, y que se dirige en sentido contrario, empezando por los menores ``mayores`'', y ``reduciendo el rango'': calculamos los determinantes de mayor orden que podamos; si todos son nulos, el rango ``se reduce en 1'' eliminando de la matriz una fila o columna que se a combinación lineal de las demás. Luego volvemos a calcular los determinantes de mayor orden que podamos con la matriz reducida, y aplicamos el mismo método hasta encontrar algún menor no nulo.\end{remark}

\begin{example}
Calcular el rango de la matriz:

$$A = \left(\begin{array}{cccc}
  1 & 1 & 1 & - 1\\
  4 & - 5 & - 2 & 7\\
  2 & 5 & 4 & - 8\\
  3 & - 3 & - 1 & 4
\end{array}\right)$$

Como es cuadrada, el menor de mayor orden que podemos calcular es el
determinante de la matriz:

$$\det ( A ) = \left|\begin{array}{cccc}
  1 & 1 & 1 & - 1\\
  4 & - 5 & - 2 & 7\\
  2 & 5 & 4 & - 8\\
  3 & - 3 & - 1 & 4
\end{array}\right| = 0 \Rightarrow \tmop{rango} ( A ) < 4.$$

Podemos asegurar que el rango no es 4 porque todos los menores de orden 4 (hay
uno solo) son nulos. Ahora calculamos todos los menores de orden 3 hasta
encontrar uno que no sea nulo:

$$\left|\begin{array}{ccc}
  1 & 1 & 1\\
  4 & - 5 & - 2\\
  2 & 5 & 4
\end{array}\right| = 0 ; \left|\begin{array}{ccc}
  1 & 1 & - 1\\
  4 & - 5 & 7\\
  2 & 5 & - 8
\end{array}\right| = 21 \neq 0.$$

Hemos tenido suerte, porque el segundo menor
de orden 3 que hemos probado no era nulo (hay 16 menores de orden 3).

Como hay un menor de orden 3 no nulo, y todos los de orden 4 son nulos,
$$\tmop{rango} ( A ) = 3.$$
\end{example}

\begin{example}
  Estudiar el rango de la siguiente matriz para los distintos valores del parámetro real $k$:
\[A=\matriz{cccc}{1&k&-7&4k-1\\1&1+k&-(k+6)&3k+1\\0&k&-6&3k-2}\]

Estudiaremos el rango por menores. Procederemos de mayor a menor orden. La matriz es de tamaño $3\times4$, por lo que sus menores de mayor orden son los de orden 3, que se obtienen eliminando una columna.

El primer menor que calcularemos será el que se obtiene al eliminar la cuarta columna:

\[\Delta=\deter{ccc}{1&k&-1\\1&1+k&-(k+6)\\0&k&-6}=-6(1+k)-7k+6k+k(k+6)=k^2-k-6=(k+2)(k-3)\]

Antes de seguir calculando menores vamos a estudiar para qué valores de $k$ vale 0 el menor anterior:

\[\Delta=0 \iff (k+2)(k-3)=0 \iff k\in\{-2,3\}\]

Por tanto, siempre que $k$ sea distinto de $-2$ y distinto de $3$, la matriz tendrá un menor de orden 3 no nulo (el que hemos llamado $\Delta$), por lo que su rango será 3. Con esto hemos hallado el rango de $A$ para todos los valores de $k$ excepto $-2$ y $3$.

Para $k=-2$, calcularemos el rango de $A$ por el método de Gauss, sustituyendo previamente $k$ por su valor:

\begin{eqnarray*}
  \rank(A) & = & \rank(\matriz{cccc}{1&-2&-7&-9\\1&-1&-4&-5\\0&-2&-6&-8})\\
  & \stackrel{F_2'=F_2-F_1}{=} & \rank(\matriz{cccc}{1&-2&-7&-9\\0&1&3&4\\0&-2&-6&-8})\\
  & \stackrel{F_3'=F_3+2F_2'}{=} & \rank(\matriz{cccc}{1&-2&-7&-9\\0&1&3&4\\0&0&0&0})\\
  & = & 2
\end{eqnarray*}

El rango de la última matriz obtenida (y, por tanto, el de todas las anteriores) es 2 porque es una matriz escalonada por filas con 2 filas no nulas.

Para $k=3$ seguiremos el mismo procedimiento:

\begin{eqnarray*}
  \rank(A) & = & \rank(\matriz{cccc}{1&3&-7&11\\1&4&-9&10\\0&3&-6&7})\\
  & \stackrel{F_2'=F_2-F_1}{=} & \rank(\matriz{cccc}{1&3&-7&11\\0&1&-2&-1\\0&3&-6&7})\\
  & \stackrel{F_3'=F_3-3F_2'}{=} & \rank(\matriz{cccc}{1&3&-7&11\\0&1&-2&-1\\0&0&0&10})\\
  & = & 3
\end{eqnarray*}

El rango de la última matriz obtenida (y, por tanto, el de todas las anteriores) es 3 porque es una matriz escalonada por filas con 3 filas no nulas.

Para comparar métodos, hallaremos también este último rango por determinantes.

Partimos del hecho de que las dos primeras columnas son independientes, ya que:

\[\deter{cc}{1&3\\1&4}=1\neq0\]

Pasamos a estudiar las otras dos columnas. Ya sabemos que la tercera columna depende linealmente de las dos primeras, puesto que:

\[\Delta = \deter{ccc}{1&3&-7\\1&4&-9\\0&3&-6} = 0\]

De hecho estamos estudiando el rango para $k=3$ porque al principio obtuvimos que para $k=3$, $\Delta=0$. Nos queda por estudiar si la cuarta columna depende linealmente de las dos primeras:

\[\deter{ccc}{1&3&11\\1&4&10\\0&3&7} = 28 + 0 + 33 - 0 - 21 - 33 = 7 \neq 0\]

Por lo tanto, la cuarta columna es independiente de las dos primeras, y, por lo tanto, el rango de $A$ es $3$.

Obsérvese que si el último determinante hubiese sido nulo podríamos haber afirmado que el rango es 2 habiendo calculado solo dos de los cuatro menores de orden 3 de la matriz. Esto se basa en el hecho de que las dos primeras columnas eran independientes. Si hay algún conjunto de 3 columnas independientes en la matriz, necesariamente tiene que haber uno que contenga a esas 2 (la afirmación no es del todo trivial, pero basta pensarla un poco para convencerse de que es así).

En resumen, hemos obtenido lo siguiente:
\begin{itemize}
\item Si $k\in\mathbb{R}-\{-2\}$, el rango de $A$ es 3.
\item Si $k=-2$, el rango de $A$ es 2.
\end{itemize}

\end{example}

\chapter{Matriz inversa}

\newpage\section{Definición de matriz inversa}

\begin{definition}[Matriz invertible]Se dice que una matriz cuadrada $A$ es {\tmstrong{invertible}} (o {\tmstrong{regular}}) si y sólo si existe otra matriz $B$ que verifica $A B = B A = I$, siendo $I$ la matriz identidad. Si dicha matriz $B$ existe, se dice que es la {\tmstrong{matriz inversa}} de $A$, y se representa por $A^{- 1}$. Si una matriz no es invertible, se dice también que es {\tmstrong{singular}}.
\end{definition}

\begin{remark}
  La matriz inversa de una matriz dada, si existe, es única. Supongamos que existen dos matrices $B$ y $C$ que verifican la definición de matriz inversa de $A$, es decir, tales que $A B = B A = I ; A C = C A = I$. En ese caso, $B = B I = B ( A C ) = ( B A ) C = I C = C.$ Es decir, esas dos matrices $B$ y $C$ tendrían que ser necesariamente iguales; o, lo que es lo mismo, la matriz inversa de $A$ es única. 
\end{remark}

\begin{remark}
  Según se desprende de la definición, de manera obvia, si $B$ es la matriz inversa de $A$, entonces $A$ es la matriz inversa de $B$; es decir, $(A^{-1})^{- 1} = A$.
\end{remark}

\begin{remark}
  En realidad, la definición es redundante: bastaría con exigirle a la inversa que $A A^{- 1} = I$, o bien que $A^{- 1} A = I$, ya que cada una de estas dos condiciones implica necesariamente la otra.
\end{remark}

\begin{remark}
  Toda matriz unipotente (tal que $A^2=I$) es invertible, y su inversa es ella misma, ya que $AA=I$.
\end{remark}

\begin{example}
La matriz inversa de $A = \left(\begin{array}{ccc}
  1 & 4 & 2\\
  3 & 7 & 9\\
  1 & 5 & 1
\end{array}\right)$ es  $B = \left(\begin{array}{ccc}
  - 19 & 3 & 11\\
  3 & - \frac{1}{2} & - \frac{3}{2}\\
  4 & - \frac{1}{2} & - \frac{5}{2}
\end{array}\right)$, ya que:

\[A B = \left(\begin{array}{ccc}
  1 & 4 & 2\\
  3 & 7 & 9\\
  1 & 5 & 1
\end{array}\right) \left(\begin{array}{ccc}
  - 19 & 3 & 11\\
  3 & - \frac{1}{2} & - \frac{3}{2}\\
  4 & - \frac{1}{2} & - \frac{5}{2}
\end{array}\right) = \left(\begin{array}{ccc}
  1 & 0 & 0\\
  0 & 1 & 0\\
  0 & 0 & 1
\end{array}\right)=I\]
\end{example}

\section{Propiedades de la matriz inversa}

\begin{theorem}
  Las matrices invertibles cumplen las propiedades siguientes:
  
  \begin{enumerate}
    \item Si dos matrices $A$ y $B$ son invertibles, entonces su producto $A
    B$ también es invertible, y su inversa viene dada por:

    \[( A B )^{- 1} = B^{- 1} A^{- 1}.\]
    
    \item Si una matriz $A$ es invertible, entonces su traspuesta $A^t$
    también es invertible, y su inversa viene dada por:
    
    \[( A^t )^{- 1} = ( A^{- 1} )^t.\]
    
    \item Una matriz $A$ es invertible si y sólo si su determinante es
    distinto de cero.
    
    \item Si $A$ es invertible, entonces

      \[\det ( A^{- 1} ) = \dfrac{1}{\det ( A )}.\]

    \end{enumerate}
\end{theorem}

\begin{example}
Determínese si las matrices $A = \left(\begin{array}{ccc}
  4 & - 3 & - 3\\
  5 & - 4 & - 4\\
  - 1 & 1 & 0
\end{array}\right)$ y $B = \left(\begin{array}{ccc}
  3 & 2 & - 1\\
  1 & 1 & 1\\
  1 & 0 & - 3
\end{array}\right)$ son invertibles.

Aplicaremos la propiedad 3: $A$ es invertible $\Leftrightarrow \det ( A ) \neq
0$.

\[\det ( A ) = \left|\begin{array}{ccc}
  4 & - 3 & - 3\\
  5 & - 4 & - 4\\
  - 1 & 1 & 0
\end{array}\right| = 0 - 12 - 15 + 12 - 0 + 16 = 1 \neq 0 \Rightarrow A
\tmop{es} \tmop{invertible}.\]

\[\det ( B ) = \left|\begin{array}{ccc}
  3 & 2 & - 1\\
  1 & 1 & 1\\
  1 & 0 & - 3
\end{array}\right| = - 9 + 2 + 0 + 1 + 6 - 0 = 0 \Rightarrow B \tmop{no}
\tmop{es} \tmop{invertible}.\]
\end{example}


{}

\newpage\section{Cálculo de la matriz inversa: método de Gauss-Jordan}

\begin{theorem}
  Toda matriz invertible puede transformarse mediante operaciones elementales sobre sus filas en la matriz identidad.
\end{theorem}

\begin{theorem}
  Si $A$ una matriz invertible, entonces el mismo conjunto de operaciones elementales sobre las filas de $A$ que transforman la matriz $A$ en la matriz identidad, transforma la matriz identidad en la matriz inversa de $A$.
\end{theorem}

\begin{remark}
  Cualquier conjunto de operaciones elementales sobre las filas de una matriz $A$ se puede
  representar mediante una matriz $E$ de modo que la matriz resultante de dicho conjunto de
  operaciones sea la matriz producto $EA$. El teorema anterior podría entonces enunciarse diciendo
  que si $EA = I$ entonces $EI=A^{-1}$. En realidad, cada operación elemental sobre filas se puede representar
  mediante una matriz $E_k$ (llamada \emph{matriz elemental}) que es el resultado de aplicar dicha
  operación a la matriz identidad. Para cualquier matriz $M$, el producto $E_kM$ será el resultado
  de aplicar a la matriz $M$ dicha operación elemental sobre filas. Lo mismo podría decirse de las
  operaciones elementales sobre las columnas, solo que entonces, para aplicar la operación a una
  matriz, habría que multiplicar por la derecha: $ME_j$.
\end{remark}

\begin{remark}
  De las anteriores proposiciones se deriva el {\tmstrong{método de Gauss-Jordan}} para el cálculo de la matriz inversa. Colocamos la matriz $I$ a la derecha de la matriz $A$, formando la ``matriz'': $( A|I )$. A continuación, aplicamos a las filas de esa ``matriz'' las operaciones elementales necesarias para que $A$ se transforme en la matriz identidad, pero las operaciones se aplican a las filas completas, es decir, incluyendo la parte correspondiente a $I$. Cuando $A$ se haya transformado en $I$, $I$ se habrá transformado en $A^{-1}$: $( A|I ) \sim ( I|A^{- 1} )$.

  Las operaciones elementales que hay que hacer para transformar $A$ en $I$ son las siguientes. Comenzamos, como siempre, situando un 1 en la posición (1,1). A continuación, anulamos los números que hay por debajo de él, restando a cada fila la primera multiplicada por el número que sea necesario. Después debemos conseguir un 1 en la posición (2,2), y anular todos los números que hay por debajo de él, restando a cada fila la segunda multiplicada por el número que sea necesario. Proseguimos hasta llegar a la última fila. Después repetimos el proceso de derecha a izquierda, anulando los números que haya por encima de los 1 de la diagonal principal. El esquema es el siguiente (los * representan números cualesquiera):
  
  $( A|I ) \sim \left(\begin{array}{cccccccc}
    \ast & \ast & \ast & \ast & 1 & 0 & 0 & 0\\
    \ast & \ast & \ast & \ast & 0 & 1 & 0 & 0\\
    \ast & \ast & \ast & \ast & 0 & 0 & 1 & 0\\
    \ast & \ast & \ast & \ast & 0 & 0 & 0 & 1
  \end{array}\right) \sim \left(\begin{array}{cccccccc}
    1 & \ast & \ast & \ast & \ast & \ast & \ast & \ast\\
    0 & \ast & \ast & \ast & \ast & \ast & \ast & \ast\\
    0 & \ast & \ast & \ast & \ast & \ast & \ast & \ast\\
    0 & \ast & \ast & \ast & \ast & \ast & \ast & \ast
  \end{array}\right) \sim \left(\begin{array}{cccccccc}
    1 & \ast & \ast & \ast & \ast & \ast & \ast & \ast\\
    0 & 1 & \ast & \ast & \ast & \ast & \ast & \ast\\
    0 & 0 & \ast & \ast & \ast & \ast & \ast & \ast\\
    0 & 0 & \ast & \ast & \ast & \ast & \ast & \ast
  \end{array}\right) \sim$
  
  $\left(\begin{array}{cccccccc}
    1 & \ast & \ast & \ast & \ast & \ast & \ast & \ast\\
    0 & 1 & \ast & \ast & \ast & \ast & \ast & \ast\\
    0 & 0 & 1 & \ast & \ast & \ast & \ast & \ast\\
    0 & 0 & 0 & \ast & \ast & \ast & \ast & \ast
  \end{array}\right) \sim \left(\begin{array}{cccccccc}
    1 & \ast & \ast & \ast & \ast & \ast & \ast & \ast\\
    0 & 1 & \ast & \ast & \ast & \ast & \ast & \ast\\
    0 & 0 & 1 & \ast & \ast & \ast & \ast & \ast\\
    0 & 0 & 0 & 1 & \ast & \ast & \ast & \ast
  \end{array}\right) \sim \left(\begin{array}{cccccccc}
    1 & \ast & \ast & 0 & \ast & \ast & \ast & \ast\\
    0 & 1 & \ast & 0 & \ast & \ast & \ast & \ast\\
    0 & 0 & 1 & 0 & \ast & \ast & \ast & \ast\\
    0 & 0 & 0 & 1 & \ast & \ast & \ast & \ast
  \end{array}\right) \sim$
  
  $\left(\begin{array}{cccccccc}
    1 & \ast & 0 & 0 & \ast & \ast & \ast & \ast\\
    0 & 1 & 0 & 0 & \ast & \ast & \ast & \ast\\
    0 & 0 & 1 & 0 & \ast & \ast & \ast & \ast\\
    0 & 0 & 0 & 1 & \ast & \ast & \ast & \ast
  \end{array}\right) \sim \left(\begin{array}{cccccccc}
    1 & 0 & 0 & 0 & \ast & \ast & \ast & \ast\\
    0 & 1 & 0 & 0 & \ast & \ast & \ast & \ast\\
    0 & 0 & 1 & 0 & \ast & \ast & \ast & \ast\\
    0 & 0 & 0 & 1 & \ast & \ast & \ast & \ast
  \end{array}\right) \sim ( I|A^{- 1} )$
\end{remark}

\begin{remark}
Si la matriz no fuese invertible, no podríamos transformarla mediante operaciones elementales en la matriz identidad. En el método de Gauss-Jordan esto se detecta en cuanto se obtenga una fila nula en la parte correspondiente a $A$.
\end{remark}

\begin{remark}
El método se puede igualmente aplicar por columnas, pero entonces habría que colocar la matriz
identidad debajo de la matriz $A$ y hacer todas las operaciones elementales por columnas. \textbf{No
  es posible mezclar operaciones elementales sobre filas y operaciones elementales sobre columnas},
para la obtención de la matriz inversa. 
\end{remark}

\begin{example}
Hallar la matriz inversa de $A = \left(\begin{array}{cccc}
  - 2 & - 9 & - 8 & 5\\
  - 3 & - 12 & 10 & 6\\
  0 & - 2 & 2 & 1\\
  - 2 & - 6 & 5 & 3
\end{array}\right)$.

\begin{eqnarray*}( A|I ) & = & \left(\begin{array}{cccccccc}
  - 2 & - 9 & - 8 & 5 & 1 & 0 & 0 & 0\\
  - 3 & - 12 & 10 & 6 & 0 & 1 & 0 & 0\\
  0 & - 2 & 2 & 1 & 0 & 0 & 1 & 0\\
  - 2 & - 6 & 5 & 3 & 0 & 0 & 0 & 1
\end{array}\right) ; \\
  F_1' = F_1 - F_2 & \rightarrow & \left(\begin{array}{cccccccc}
    1 & 3 & - 18 & - 1 & 1 & - 1 & 0 & 0\\
    - 3 & - 12 & 10 & 6 & 0 & 1 & 0 & 0\\
    0 & - 2 & 2 & 1 & 0 & 0 & 1 & 0\\
    - 2 & - 6 & 5 & 3 & 0 & 0 & 0 & 1
  \end{array}\right) ;\\
\left. \begin{array}{l} 
  F_2'' = F_2' + 3 F_1'\\
  F_4'' = F_4' + 2 F_1'
\end{array} \right\} & \rightarrow & \left(\begin{array}{cccccccc}
  1 & 3 & - 18 & - 1 & 1 & - 1 & 0 & 0\\
  0 & - 3 & - 44 & 3 & 3 & - 2 & 0 & 0\\
  0 & - 2 & 2 & 1 & 0 & 0 & 1 & 0\\
  0 & 0 & - 31 & 1 & 2 & - 2 & 0 & 1
\end{array}\right) ;\\
  F_2''' = - F_2'' & \rightarrow &
\left(\begin{array}{cccccccc}
  1 & 3 & - 18 & - 1 & 1 & - 1 & 0 & 0\\
  0 & 3 & 44 & - 3 & - 3 & 2 & 0 & 0\\
  0 & - 2 & 2 & 1 & 0 & 0 & 1 & 0\\
  0 & 0 & - 31 & 1 & 2 & - 2 & 0 & 1
\end{array}\right) ;\\   
F_2^{\tmop{IV}} = F_2^{'''} + F_3''' & \rightarrow & \left(\begin{array}{cccccccc}
  1 & 3 & - 18 & - 1 & 1 & - 1 & 0 & 0\\
  0 & 1 & 46 & - 2 & - 3 & 2 & 1 & 0\\
  0 & - 2 & 2 & 1 & 0 & 0 & 1 & 0\\
  0 & 0 & - 31 & 1 & 2 & - 2 & 0 & 1
\end{array}\right) \\
F_3^V = F_3^{\tmop{IV}} + 2 F_1^{\tmop{IV}} & \rightarrow &
\left(\begin{array}{cccccccc}
  1 & 3 & - 18 & - 1 & 1 & - 1 & 0 & 0\\
  0 & 1 & 46 & - 2 & - 3 & 2 & 1 & 0\\
  0 & 0 & 94 & - 3 & - 6 & 4 & 3 & 0\\
  0 & 0 & - 31 & 1 & 2 & - 2 & 0 & 1
\end{array}\right) ;\\
F_3^{\tmop{VI}} = F_3^V + 3 F_4^V & \rightarrow &
\left(\begin{array}{cccccccc}
  1 & 3 & - 18 & - 1 & 1 & - 1 & 0 & 0\\
  0 & 1 & 46 & - 2 & - 3 & 2 & 1 & 0\\
  0 & 0 & 1 & 0 & 0 & - 2 & 3 & 3\\
  0 & 0 & - 31 & 1 & 2 & - 2 & 0 & 1
\end{array}\right) ;\\
F_4^{\tmop{VII}} = F_4^{\tmop{VI}} + 31 F_3^{\tmop{VI}} & \rightarrow &
\left(\begin{array}{cccccccc}
  1 & 3 & - 18 & - 1 & 1 & - 1 & 0 & 0\\
  0 & 1 & 46 & - 2 & - 3 & 2 & 1 & 0\\
  0 & 0 & 1 & 0 & 0 & - 2 & 3 & 3\\
  0 & 0 & 0 & 1 & 2 & - 64 & 93 & 94
\end{array}\right) ;\\ 
\left. \begin{array}{l}
  F_1^{\tmop{VIII}} = F_1^{\tmop{VII}} + F_4^{\tmop{VII}}\\
  F_2^{\tmop{VIII}} = F_2^{\tmop{VII}} + 2 F_4^{\tmop{VII}}
\end{array} \right\} & \rightarrow &
\left(\begin{array}{cccccccc}
  1 & 3 & - 18 & 0 & 3 & - 65 & 93 & 94\\
  0 & 1 & 46 & 0 & 1 & - 126 & 187 & 188\\
  0 & 0 & 1 & 0 & 0 & - 2 & 3 & 3\\
  0 & 0 & 0 & 1 & 2 & - 64 & 93 & 94
\end{array}\right) ;\\
\left.\begin{array}{l}
  F_1^{\tmop{IX}} = F_1^{\tmop{VIII}} + 18 F_3^{\tmop{VIII}}\\
  F_2^{\tmop{IX}} = F_2^{\tmop{VIII}} - 46 F_3^{\tmop{VIII}}
\end{array} \right\} & \rightarrow &
\left(\begin{array}{cccccccc}
  1 & 3 & 0 & 0 & 3 & - 101 & 147 & 148\\
  0 & 1 & 0 & 0 & 1 & - 34 & 49 & 50\\
  0 & 0 & 1 & 0 & 0 & - 2 & 3 & 3\\
  0 & 0 & 0 & 1 & 2 & - 64 & 93 & 94
\end{array}\right) ;\\
F_1^X = F_1^{\tmop{IX}} - 3 F_2^{\tmop{IX}} & \rightarrow &
\left(\begin{array}{cccccccc}
  1 & 0 & 0 & 0 & 0 & 1 & 0 & - 2\\
  0 & 1 & 0 & 0 & 1 & - 34 & 49 & 50\\
  0 & 0 & 1 & 0 & 0 & - 2 & 3 & 3\\
  0 & 0 & 0 & 1 & 2 & - 64 & 93 & 94
\end{array}\right)\\
& = & ( I|A^{- 1} ) \Rightarrow A^{- 1} =
\left(\begin{array}{cccc}
  0 & 1 & 0 & - 2\\
  1 & - 34 & 49 & 50\\
  0 & - 2 & 3 & 3\\
  2 & - 64 & 93 & 94
\end{array}\right)
\end{eqnarray*}

\end{example}

\newpage\section{Cálculo de la matriz inversa por determinantes}

\begin{definition}
  [Matriz adjunta] Dada una matriz cuadrada $A$, se llama {\tmstrong{matriz adjunta}} de $A$ (o matriz de cofactores de $A$) a la matriz cuyo elemento $( i, j )$ es el adjunto (o cofactor) del elemento $( i, j )$ de $A$. Se representa por $\tmop{Adj} A$.
\end{definition}

\begin{theorem}
  Si $A$ es invertible, entonces su inversa $A^{- 1}$ viene dada por:
  
  \[A^{- 1} = \dfrac{1}{\det ( A )} ( \tmop{Adj} A )^t.\]
\end{theorem}

\begin{remark}
  La traspuesta de la adjunta es igual a la adjunta de la traspuesta: $A^{-1} = \frac{1}{\det (A)}\tmop{Adj} (A^t)$.
\end{remark}

\begin{remark}
  Algunos autores llaman matriz de cofactores a la que nosotros hemos llamado adjunta, y llaman matriz adjunta a la traspuesta de la matriz de cofactores. Según esta nomenclatura, la trasposición está incluida en la adjunta, y no aparece en la fórmula de la inversa.
\end{remark}

\begin{example}
Hallar la matriz inversa de $A = \left(\begin{array}{ccc}
  0 & 2 & 1\\
  - 1 & 3 & 1\\
  4 & - 5 & - 1
\end{array}\right)$.

En primer lugar, calculamos por Sarrus el determinante de $A$, para saber si
$A$ es invertible:

$$\det ( A ) = \left|\begin{array}{ccc}
  0 & 2 & 1\\
  - 1 & 3 & 1\\
  4 & - 5 & - 1
\end{array}\right| = 0 + 8 + 5 - 12 - 2 + 0 = - 1 ; \; \det ( A ) \neq 0
\Rightarrow A \tmop{es} \tmop{invertible}.$$

A continuación calculamos la matriz adjunta de $A$, cuyos elementos son los
adjuntos de los elementos de $A$. Recordemos que el adjunto (o cofactor) del
elemento $( i, j )$ es el determinante de su submatriz complementaria (esto
es, la que resulta de eliminar la fila y la columna de dicho elemento)
multiplicado por $( - 1 )^{i + j}$. Representamos por $\alpha_{\tmop{ij}}$ al
adjunto del elemento $a_{\tmop{ij}}$ de $A$:

\[\begin{array}{lll}
\alpha_{11} = \left|\begin{array}{cc}
  3 & 1\\
  - 5 & - 1
\end{array}\right| = - 3 + 5 = 2 ;\; & \alpha_{12} = - \left|\begin{array}{cc}
  - 1 & 1\\
  4 & - 1
\end{array}\right| = - ( 1 - 4 ) = 3 ;\; & \alpha_{13} = \left|\begin{array}{cc}
  - 1 & 3\\
  4 & - 5
\end{array}\right| = 5 - 12 = - 7 \\
\alpha_{21} = - \left|\begin{array}{cc}
  2 & 1\\
  - 5 & - 1
\end{array}\right| = - ( - 2 + 5 ) = - 3 ;\; & \alpha_{22} =
\left|\begin{array}{cc}
  0 & 1\\
  4 & - 1
\end{array}\right| = - 4 ;\; & \alpha_{23} = - \left|\begin{array}{cc}
  0 & 2\\
  4 & - 5
\end{array}\right| = - ( - 8 ) = 8 \\
\alpha_{31} = \left|\begin{array}{cc}
  2 & 1\\
  3 & 1
\end{array}\right| = 2 - 3 = - 1 ;\; & \alpha_{32} = - \left|\begin{array}{cc}
  0 & 1\\
  - 1 & 1
\end{array}\right| = - 1 ;\; & \alpha_{33} = \left|\begin{array}{cc}
  0 & 2\\
  - 1 & 3
\end{array}\right| = 0 - ( - 2 ) = 2
\end{array}\]

\[\tmop{Adj} A = \left(\begin{array}{c}
  \alpha_{\tmop{ij}}
\end{array}\right) = \left(\begin{array}{ccc}
  2 & 3 & - 7\\
  - 3 & - 4 & 8\\
  - 1 & - 1 & 2
\end{array}\right)\]

Finalmente, calculamos la matriz traspuesta de $\tmop{Adj} A$, y la
multiplicamos por $\dfrac{1}{\det ( A )}$:

\[A^{- 1} = \dfrac{1}{\det ( A )} ( \tmop{Adj} A )^t = \dfrac{1}{- 1}
\left(\begin{array}{ccc}
  2 & 3 & - 7\\
  - 3 & - 4 & 8\\
  - 1 & - 1 & 2
\end{array}\right)^t = \dfrac{1}{- 1}
\left(\begin{array}{ccc}
  2 & - 3 & - 1\\
  3 & - 4 & - 1\\
  - 7 & 8 & 2
\end{array}\right) = \left(\begin{array}{ccc}
  - 2 & 3 & 1\\
  - 3 & 4 & 1\\
  7 & - 8 & - 2
\end{array}\right)\]
\end{example}

{\pagebreak}

\newpage\section{Ecuaciones matriciales}

\begin{proposition}
  Una matriz $A$ es invertible si y sólo si es ``simplificable'', es decir, si y sólo si $A B = A C \Rightarrow B = C, \forall B, C$.
\end{proposition}

\begin{remark}
  La implicación $B = C \Rightarrow A B = A C$ es verdadera siempre, sea cual sea la matriz $A$. Lo que no es verdad siempre es la implicación contraria. Lo que dice esta proposición es que la implicación anterior es doble si y sólo si $A$ es invertible. Es decir, si $A$ es invertible se cumple que $B = C \Leftrightarrow A B = A C, \forall B, C$.
\end{remark}

\begin{remark}
  La proposición anterior se puede utilizar para resolver algunas ecuaciones matriciales, ya que, según dicha proposición, si $A$ es invertible, entonces
  las ecuaciones $X = Y$ y $A X = A Y$, son equivalentes: si multiplicamos los dos miembros de una ecuación matricial por una misma matriz {\tmstrong{regular{\tmstrong{}}}} obtenemos una ecuación equivalente.
  
  Así, por ejemplo, si $A$ es regular, para ``despejar'' $X$ en la ecuación $A X = B$, podemos multiplicar ambos miembros por $A^{- 1}$, que es también una matriz regular, obteniendo la ecuación equivalente $A^{- 1} A X = A^{- 1} B$, la cual se simplifica, ya que $A^{- 1} A = I$ y $I X = X$, resultando: $X = A^{- 1} B$.
  
  Se muestra a continuación el esquema de resolución de ecuaciones matriciales de distintas formas, aplicando la proposición anterior (en todos los casos
  se da por supuesto que las matrices inversas que se usan existen; si no existieran, no podría utilizarse este método):

  \[A X + B = C \Leftrightarrow A X = C - B \Leftrightarrow A^{- 1} A X = A^{-
  1} ( C - B ) \Leftrightarrow X = A^{- 1} ( C - B )\]
  
  \[X A + B = C \Leftrightarrow X A = C - B \Leftrightarrow X A A^{- 1} = ( C -
  B ) A^{- 1} \Leftrightarrow X = ( C - B ) A^{- 1}\]
  
  \[A X B + C = D \Leftrightarrow A X B = D - C \Leftrightarrow A^{- 1} A X B
  B^{- 1} = A^{- 1} ( D - C ) B^{- 1} \Leftrightarrow X = A^{- 1} ( D - C )
  B^{- 1}\]
  
  \[A X + B = C X + D \Leftrightarrow A X - C X = D - B \Leftrightarrow ( A - C
  ) X = D - B \Leftrightarrow X = ( A - C )^{- 1} ( D - B )\]
  
  \[X A + B = X C + D \Leftrightarrow X A - X C = D - B \Leftrightarrow X ( A -
  C ) = D - B \Leftrightarrow X = ( D - B ) ( A - C )^{- 1}\]
\end{remark}

\begin{remark}
  De todo lo anterior se deduce fácilmente que: si $A$ es invertible, la ecuación $A X = B$ tiene una sola solución; si $A$ es singular, la ecuación anterior tiene más de una solución (existen varias matrices $X$ que cumplen $A X = B$). Dicho de otro modo, si $A$ es singular, la ecuación $A X = A B$ tiene todas las soluciones de $X = B$ y algunas más.
\end{remark}

\begin{remark}
  Aunque todas las matrices que intervienen en una ecuación matricial sean invertibles, no siempre es posible despejar la matriz incógnita por el procedimiento descrito anteriormente, debido a la no conmutatividad del producto de matrices. Así, por ejemplo, es imposible despejar $X$ en la siguiente ecuación, aunque la matriz $A$ sea invertible:

  $$AX=XA$$

  En este caso, para resolver la ecuación habrá que representar los elementos de $X$ mediante letras y resolver el sistema de ecuaciones que se obtiene al igualar los productos elemento a elemento.
\end{remark}

\begin{example}
Hallar, si existe, una matriz $X$ que verifique la ecuación matricial
$B^2 X - B X = B - X$, siendo la matriz $B = \left(\begin{array}{cc}
  2 & - 1\\
  0 & 3
\end{array}\right)$.

En primer lugar, ``despejamos'' la matriz $X$ como si la ecuación fuese escalar.
Para ello, sumamos $X$ en los dos miembros de la ecuación, con lo que
obtenemos una ecuación equivalente:

$$B^2 X - B X = B - X \Leftrightarrow B^2 X - B X + X = B - X + X
\Leftrightarrow B^2 X - B X + X = B$$

A continuación, aplicamos la propiedad distributiva del producto respecto de
la suma de matrices, obteniendo:

$$B^2 X - B X + X = B \Leftrightarrow ( B^2 - B + I ) X = B$$



Obsérvese que al ``sacar factor común'' $X$, hemos colocado el factor común a la
derecha, porque así estaba colocado en los productos originales (no olvidar
que el producto de matrices no es conmutativo en general). Conviene también
fijarse en la matriz identidad que aparece al ``sacar factor común''.

Si la matriz $B^2 - B + I$ fuese regular, podríamos ``despejar'' la $X$
multiplicando los dos miembros de la ecuacion por su inversa. Vamos a
comprobar si es o no regular, hallando su determinante:

$$B^2 - B + I = \left(\begin{array}{cc}
  2 & - 1\\
  0 & 3
\end{array}\right)^2 - \left(\begin{array}{cc}
  2 & - 1\\
  0 & 3
\end{array}\right) + \left(\begin{array}{cc}
  1 & 0\\
  0 & 1
\end{array}\right) = \left(\begin{array}{cc}
  4 & - 5\\
  0 & 9
\end{array}\right) - \left(\begin{array}{cc}
  2 & - 1\\
  0 & 3
\end{array}\right) + \left(\begin{array}{cc}
  1 & 0\\
  0 & 1
\end{array}\right) = \left(\begin{array}{cc}
  3 & - 4\\
  0 & 7
\end{array}\right)$$

$$\det ( B^2 - B + I ) = \det \left(\begin{array}{cc}
  3 & - 4\\
  0 & 7
\end{array}\right) = 3 \cdot 7 - 0 \cdot ( - 4 ) = 21 \neq 0 \Rightarrow B^2 -
B + I \tmop{es} \tmop{invertible}$$

Ahora ya sabemos que la matriz que multiplica a $X$ es invertible. Por tanto,
al multiplicar los dos miembros de la ecuación por su inversa obtenemos una
ecuación equivalente:

$$( B^2 - B + I ) X = B \Leftrightarrow ( B^2 - B + I )^{- 1} ( B^2 - B + I ) X
= ( B^2 - B + I )^{- 1} B \Leftrightarrow X = ( B^2 - B + I )^{- 1} B$$

Ahora, para hallar $X$, sólo queda efectuar las operaciones indicadas en la
expresión anterior. La matriz inversa que ahí aparece la calcularemos
utilizando la matriz adjunta:

$$( B^2 - B + I )^{- 1} = \frac{1}{\det ( B^2 - B + I )} [ \tmop{Adj} ( B^2 - B
+ I ) ]^t$$

$$\tmop{Adj} ( B^2 - B + I ) = \tmop{Adj} \left(\begin{array}{cc}
  3 & - 4\\
  0 & 7
\end{array}\right) = \left(\begin{array}{cc}
  7 & 0\\
  4 & 3
\end{array}\right) ; [ \tmop{Adj} ( B^2 - B + I ) ]^t =
\left(\begin{array}{cc}
  7 & 0\\
  4 & 3
\end{array}\right)^t = \left(\begin{array}{cc}
  7 & 4\\
  0 & 3
\end{array}\right)$$

$$( B^2 - B + I )^{- 1} = \dfrac{1}{21} \left(\begin{array}{cc}
  7 & 4\\
  0 & 3
\end{array}\right)$$

Finalmente, hay que calcular el producto:

$$X = ( B^2 - B + I )^{- 1} B = \dfrac{1}{21} \left(\begin{array}{cc}
  7 & 4\\
  0 & 3
\end{array}\right) \left(\begin{array}{cc}
  2 & - 1\\
  0 & 3
\end{array}\right) = \dfrac{1}{21} \left(\begin{array}{cc}
  14 & 5\\
  0 & 9
\end{array}\right) = \left(\begin{array}{cc}
  \frac{1}{2} & \frac{5}{21}\\
  0 & \frac{3}{7}
\end{array}\right)$$
\end{example}

\chapter{Sistemas de ecuaciones lineales}

\newpage\section{Definición de sistema lineal}

\begin{definition}[Ecuaciones]
Una \textbf{ecuación} es una expresión matemática que contiene un signo $=$, y expresa la igualdad de los valores de 
dos expresiones, que se llaman \textbf{miembros} de la ecuación. Los valores de los miembros de una ecuación pueden (y suelen) depender de términos
de valor desconocido o indeterminado, que reciben el nombre de \textbf{incógnitas} o \textbf{variables}. Una \textbf{sustitución}
de las incógnitas o variables de una ecuación es la asignación de un valor a cada una de ellas. Se llama \textbf{solución} de una
ecuación a toda sustitución que verifique la ecuación (es decir, tal que los valores de los miembros correspondientes a los
valores de las incógnitas sustituidos sean iguales). Se llama \textbf{conjunto solución} de una ecuación al conjunto de todas sus soluciones.
\textbf{Resolver} una ecuación es hallar todas sus soluciones. Se dice que dos ecuaciones son \textbf{equivalentes} cuando tienen el mismo
conjunto solución.
\end{definition}

\begin{remark}
  Cuando una ecuación tiene varias incógnitas, sus soluciones pueden representarse mediante \textit{vectores} de valores. Por ejemplo, la ecuación $x+2y=5$ tiene entre sus soluciones a $(1,2)$ y a $(3,1)$. Se acepta por convenio que las incógnitas están \textit{numeradas}, y que la sustitución de los valores se realiza en el orden en el que aparecen en el \textit{vector}. Así, en el ejemplo anterior, la solución $(1,2)$ es la asignación de $1$ a $x$ y de $2$ a $y$, ya que se admite que $x$ es la primera incógnita, e $y$ la segunda. A veces, la asignación se indica expresamente mediante igualdades, diciendo, por ejemplo, que $x=3,y=1$ es una solución de la ecuación $x+2y=5$.
\end{remark}

\begin{remark}
  Es importante la distinción entre \textit{solución} y \textit{conjunto solución}, ya que muchas ecuaciones no tienen una única solución. Por ejemplo, la ecuación $x+2y=5$ con $x$ e $y$ reales, tiene infinitas soluciones, como $(1,2),(3,1),(5,0),(4,1/2)$. Podemos representar su conjunto solución mediante una expresión que represente simbólicamente a todas sus soluciones. Para ello, representaremos una de ellas, la $y$, mediante otra letra, $t$, indicando con eso que en el conjunto solución, dicha incógnita puede tomar cualquier valor, comportándose como un parámetro. La otra incógnita la representamos mediante la una expresión que la relacione con el parámetro anterior. El conjunto solución de la ecuación $x+2y=5$ sería:
$\{(5-2t,t)|t\in\mathbb{R}\}$.
\end{remark}

\begin{remark}
  Las ecuaciones se definen dentro de algún conjunto en el que exista una relación de igualdad. Los valores de las incógnitas deben estar restringidos al conjunto de definición de la ecuación. Así, por ejemplo, se puede hablar de la ecuación $x^2+y^2=1$ definida en $\mathbb{R}$, y de la misma ecuación definida en $\mathbb{Z}$. En el primer caso, la ecuación tiene infinitas soluciones (que geométricamente se podrían interpretar como los puntos de la circunferencia de centro en $(0,0)$ y radio $1$). En el segundo caso, la ecuación tendría sólo cuatro soluciones: $(0,1),(1,0),(0,-1),(-1,0)$.
\end{remark}

\begin{definition}[Sistema de ecuaciones]
Un \textbf{sistema de ecuaciones} es un conjunto de ecuaciones con las mismas incógnitas. Se llama \textbf{solución} de un sistema a toda sustitución
que sea solución de todas sus ecuaciones. Se llama \textbf{conjunto solución} de un sistema al conjunto de todas sus soluciones (es decir, a la
intersección de los conjuntos solución de todas las ecuaciones que lo forman).
\end{definition}

\begin{definition}[Sistemas equivalentes]
  Se dice que dos sistemas de ecuaciones son equivalentes cuando tienen el mismo conjunto solución.
\end{definition}

\begin{remark}
  Este es el concepto clave para la resolución de sistemas de ecuaciones. Todos los métodos se basan en el mismo esquema: se trata de transformar el sistema que se quiere resolver en un sistema equivalente más sencillo, y resolver este último en lugar del primero; puesto que son equivalentes, las soluciones que obtengamos para el segundo serán las mismas que encontraríamos para el primero.
\end{remark}

\begin{definition}[Sistema de ecuaciones lineales]
Se llama \textbf{ecuación lineal} con las incógnitas $x_1,\hdots,x_n$, a cualquier ecuación equivalente a una ecuación de la forma: $a_{1}x_1+\cdots+a_nx_n=b$. Los números $a_1,\hdots,a_n$ reciben el nombre de \textbf{coeficientes} de la ecuación, y al número $b$ se le llama \textbf{término independiente}. Se llama, por tanto, \textbf{sistema de ecuaciones lineales} o también \textbf{sistema lineal de ecuaciones} con $m$ ecuaciones y $n$ incógnitas, $x_1,x_2,\ldots,x_n$, a todo sistema equivalente a uno de la forma:
\[\left\{\begin{array}{ccccccccc}
a_{11}x_1&+&a_{12}x_2&+&\cdots&+&a_{1n}x_n&=&b_1\\
a_{21}x_1&+&a_{22}x_2&+&\cdots&+&a_{2n}x_n&=&b_2\\
\vdots&&\vdots&&\vdots&&\vdots&&\vdots\\
a_{m1}x_1&+&a_{m2}x_2&+&\cdots&+&a_{mn}x_n&=&b_m
\end{array}\right.\]
\end{definition}

\begin{example}
  El siguiente es un sistema lineal de 2 ecuaciones con 3 incógnitas:
\[\left\{\begin{array}{rcl}
x-2y+z&=&2\\
2x-5y&=&-1
\end{array}\right.\]

El hecho de que en la segunda ecuación no aparezca la incógnita $z$ no impide que consideremos este conjunto de ecuaciones como un sistema de acuerdo con la definición anterior, ya que podemos considerar que la segunda ecuación es, en realidad, $2x-5y+0\cdot z=-1$.

Este sistema tiene infinitas soluciones. Su conjunto solución es el siguiente:
\[\left\{\left(12-5k,5-2k,k\right)\mid k\in\mathbb{R}\right\}\]

Podemos calcular soluciones del sistema utilizando la expresión anterior, asignando valores a $k$. Así, para $k=0$, obtenemos la solución $(12,5,0)$, para $k=1$, obtenemos $(7,3,1)$, y para $k=2$, $(2,1,2)$.

Todas las soluciones del sistema son soluciones de las dos ecuaciones que lo forman. Sin embargo, cada ecuación por separado tiene soluciones que no son solución de la otra. Así, por ejemplo, $(-3,-1,0)$ es solución de la segunda ecuación, pero no lo es de la primera, y $(4,1,0)$ es solución de la primera pero no de la segunda.
\end{example}

\begin{theorem}[Tipos de sistemas lineales]
Un sistema lineal de ecuaciones puede ser de uno de estos tres tipos, según el número de soluciones que tiene:
\begin{enumerate}
\item \textbf{Sistema compatible determinado}, si tiene una única solución (su conjunto solución tiene un único elemento).
\item \textbf{Sistema compatible indeterminado}, si tiene infinitas soluciones (su conjunto solución es infinito).
\item \textbf{Sistema incompatible}, si no tiene soluciones (su conjunto solución es el conjunto vacío).
\end{enumerate}
\end{theorem}

\begin{remark}
  Del teorema anterior se desprende que un sistema de ecuaciones lineales que tenga dos soluciones distintas, necesariamente ha de tener infinitas.
\end{remark}

\begin{remark}
  No se debe confundir \textit{tener infinitas soluciones} con que \textit{cualquier sustitución es solución}. Así, la ecuación $5x-y=1$ tiene infinitas soluciones, pero no cualquier par de números es solución de la misma. Por ejemplo, $(1,1)$ no es solución de dicha ecuación, ya que al sustituir $x$ por $1$ e $y$ por $1$, el primer miembro vale $4$, mientras que el segundo vale $1$.
\end{remark}

\begin{remark}
  \textbf{Discutir un sistema} es estudiar a cuál de esos tres tipos pertenece. Es decir, analizar si tiene o no alguna solución (si es compatible o incompatible), y, en caso de que sea compatible, si tiene una única solución (es compatible determinado) o tiene infinitas soluciones (es compatible indeterminado).
\end{remark}

\newpage\section{Expresión matricial de un sistema}

\begin{definition}
Dado el sistema:
\[\left\{\begin{array}{ccccccccc}
a_{11}x_1&+&a_{12}x_2&+&\cdots&+&a_{1n}x_n&=&b_1\\
a_{21}x_1&+&a_{22}x_2&+&\cdots&+&a_{2n}x_n&=&b_2\\
\vdots&&\vdots&&\vdots&&\vdots&&\vdots\\
a_{m1}x_1&+&a_{m2}x_2&+&\cdots&+&a_{mn}x_n&=&b_m
\end{array}\right.\]
Se llaman:
\begin{enumeratealpha}
\item \textbf{matriz de coeficientes} del sistema a la matriz $\matriz{cccc}{
a_{11}&a_{12}&\cdots&a_{1n}\\
a_{21}&a_{22}&\cdots&a_{2n}\\
\vdots&\vdots&\vdots&\vdots\\
a_{m1}&a_{m2}&\cdots&a_{mn}}$;
\item \textbf{matriz de incógnitas} del sistema a la matriz $\matriz{c}{x_1\\x_2\\\vdots\\x_n}$;
\item \textbf{matriz de términos independientes} del sistema a la matriz $\matriz{c}{b_1\\b_2\\\vdots\\b_m}$;
\item \textbf{matriz ampliada o matriz del sistema} a la matriz $\matriz{ccccc}{
a_{11}&a_{12}&\cdots&a_{1n}&b_1\\
a_{21}&a_{22}&\cdots&a_{2n}&b_2\\
\vdots&\vdots&\vdots&\vdots&\vdots\\
a_{m1}&a_{m2}&\cdots&a_{mn}&b_m}$
\end{enumeratealpha}
\end{definition}

\begin{theorem}
Todo sistema lineal de ecuaciones:
\[\left\{\begin{array}{ccccccccc}
a_{11}x_1&+&a_{12}x_2&+&\cdots&+&a_{1n}x_n&=&b_1\\
a_{21}x_1&+&a_{22}x_2&+&\cdots&+&a_{2n}x_n&=&b_2\\
\vdots&&\vdots&&\vdots&&\vdots&&\vdots\\
a_{m1}x_1&+&a_{m2}x_2&+&\cdots&+&a_{mn}x_n&=&b_m
\end{array}\right.\]
equivale a la ecuación matricial:
\[\matriz{cccc}{
a_{11}&a_{12}&\cdots&a_{1n}\\
a_{21}&a_{22}&\cdots&a_{2n}\\
\vdots&\vdots&\ddots&\vdots\\
a_{m1}&a_{m2}&\cdots&a_{mn}}\matriz{c}{x_1\\x_2\\\vdots\\x_n}
=\matriz{c}{b_1\\b_2\\\vdots\\b_m}
\]
o bien,
\[AX=B\]
siendo, $A$ la matriz de coeficientes, $X$ la matriz de incógnitas y $B$ la matriz de términos independientes del sistema.
\end{theorem}

\begin{remark}
  Cuando decimos que un sistema de ecuaciones numéricas \textit{equivale} a una ecuación matricial, queremos decir que cada hay una correspondencia biunívoca entre las soluciones del sistema y las soluciones de la ecuación matricial. La correspondencia presupuesta en el teorema anterior es obvia: cada matriz solución de la ecuación matricial contiene los valores de una sustitución de las incógnitas que es solución del sistema.
\end{remark}

\begin{remark}
  Si un sistema tiene igual número de ecuaciones que de incógnitas, su matriz de coeficientes será una matriz cuadrada. En este caso, si dicha matriz de coeficientes es invertible, podemos resolver la ecuación matricial correspondiente al sistema utilizando la matriz inversa de la matriz de coeficientes, y, de esa manera, resolver el sistema de ecuaciones:

\[AX=B \iff A^{-1}(AX)=A^{-1}B\iff  (A^{-1}A)X=A^{-1}B \iff IX=A^{-1}B \iff X=A^{-1}B\]
\end{remark}

\begin{example}
A continuación se muestran un sistema de ecuaciones y su expresión matricial:
$$\left\{\begin{array}{l}
  x + y + 2 z = 9\\
  3 x + 6 y - 5 z = 0\\
  2 x + 4 y - 3 z = 1
\end{array}\right. \Leftrightarrow \left(\begin{array}{ccc}
  1 & 1 & 2\\
  3 & 6 & - 5\\
  2 & 4 & - 3
\end{array}\right) \left(\begin{array}{c}
  x\\
  y\\
  z
\end{array}\right) = \left(\begin{array}{c}
  9\\
  0\\
  1
\end{array}\right) \Leftrightarrow A X = B$$

La matriz de coeficientes es $A$ y la matriz ampliada (o matriz del sistema)
es:
$$A^{\ast} = \left(\begin{array}{cccc}
  1 & 1 & 2 & 9\\
  3 & 6 & - 5 & 0\\
  2 & 4 & - 3 & 1
\end{array}\right).$$

Como la matriz $A$ es invertible, podríamos despejar $X$:
$$A X = B \Leftrightarrow A^{- 1} A X = A^{- 1} B \Leftrightarrow X = A^{- 1} B.$$

$$A^{- 1} = \dfrac{1}{|A|} ( \tmop{Adj} A )^t = \left(\begin{array}{ccc}
  2 & 11 & - 17\\
  - 1 & - 7 & 11\\
  0 & - 2 & 3
\end{array}\right) \Rightarrow X = A^{- 1} B = \left(\begin{array}{ccc}
  2 & 11 & - 17\\
  - 1 & - 7 & 11\\
  0 & - 2 & 3
\end{array}\right) \left(\begin{array}{c}
  9\\
  0\\
  1
\end{array}\right) = \left(\begin{array}{c}
  1\\
  2\\
  3
\end{array}\right)$$

Es decir, $x = 1$, $y = 2$, $z = 3$ es la solución del sistema.  
\end{example}



\newpage\section{Teorema de Rouché-Frobenius}

\begin{theorem}[Rouché-Fröbenius]Dado un sistema de ecuaciones
  lineales con n incógnitas $A X = B$, se tiene:
  \begin{itemize}
  \item $A X = B$ es compatible $\Leftrightarrow \tmop{rango} ( A ) =
    \tmop{rango} ( A^{\ast} )$
      
  \item $A X = B$ es compatible determinado $\Leftrightarrow
    \tmop{rango} ( A ) = \tmop{rango} ( A^{\ast} ) = n$
      
  \item $A X = B$ es compatible indeterminado $\Leftrightarrow
    \tmop{rango} ( A ) = \tmop{rango} ( A^{\ast} ) < n$
  \end{itemize}
\end{theorem}

\begin{remark}
  No se considera el caso $\tmop{rango} ( A ) = \tmop{rango} (
  A^{\ast} ) > n$, porque es imposible: el rango de $A$ no puede ser
  mayor que el número de incógnitas, porque el número de incógnitas es
  el número de columnas de $A$, y una matriz no puede tener un rango
  mayor que su número de columnas.
\end{remark}

\begin{remark}
  Suele ser bastante útil en la resolución de ejercicios tener en
  cuenta que el rango de la matriz ampliada es siempre mayor o igual
  que el de la matriz de coeficientes ($\tmop{rango} ( A^{\ast} )
  \geqslant \tmop{rango} ( A ) )$; al añadir una columna a una matriz
  nunca se reduce su rango: o se aumenta (si la columna añadida es
  independiente de las demás), o se queda igual (si añadimos una
  columna que depende linealmente de las que ya tenía la matriz).
\end{remark}

\begin{remark}
  Este teorema nos permite clasificar fácilmente cualquier sistema de
  ecuaciones:
  \begin{itemize}
  \item {\tmstrong{SI}} $\Leftrightarrow \tmop{rango} ( A ) \neq
    \tmop{rango} ( A^{\ast} )$
  \item {\tmstrong{SCD}} $\Leftrightarrow \tmop{rango} ( A ) =
    \tmop{rango} ( A^{\ast} ) = \text{número de incógnitas}$
  \item {\tmstrong{SCI}} $\Leftrightarrow \tmop{rango} ( A ) =
    \tmop{rango} ( A^{\ast} ) < \text{número de incógnitas}$
  \end{itemize}
\end{remark}

\begin{theorem}
  En un sistema compatible indeterminado con $n$ incógnitas y con
  $\tmop{rango} ( A ) = \tmop{rango} ( A^{\ast} ) = r$, hay $n - r$
  incógnitas que pueden tomar cualquier valor (se toman como
  ``parámetros''), mientras que los valores de las restantes $r$
  incógnitas (``incógnitas principales'') queda determinado por los
  valores asignados a esos $n - r$ ``parámetros''. Se dice entonces
  que el sistema es ``$( n - r ) - \text{paramétrico}$'', o bien que
  su conjunto de soluciones tiene $n - r$ {\tmstrong{grados de libertad}}. Es siempre posible, reducir el sistema a un sistema compatible
  determinado eliminando $n-r$ ecuaciones, y considerando $n-r$
  incógnitas como parámetros en la parte de los términos
  independientes.
\end{theorem}

\begin{remark}
  Es muy frecuente el caso de sistemas de 3 ecuaciones con 3
  incógnitas. Para estos sistemas, los casos posibles son los
  siguientes:
  \begin{enumeratealpha}
  \item $\tmop{rg}(A)=3;\tmop{rg}(A^{\ast})=3 \Rightarrow \text{SCD}$
  \item $\tmop{rg}(A)=2;\tmop{rg}(A^{\ast})=3 \Rightarrow \text{SI}$
  \item $\tmop{rg}(A)=2;\tmop{rg}(A^{\ast})=2 \Rightarrow \text{SCI
      uniparamétrico}$
  \item $\tmop{rg}(A)=1;\tmop{rg}(A^{\ast})=2 \Rightarrow \text{SI}$
  \item $\tmop{rg}(A)=1;\tmop{rg}(A^{\ast})=1 \Rightarrow \text{SCI
      biparamétrico}$
  \end{enumeratealpha}
\end{remark}



\newpage\section{Resolución de sistemas por el método de Gauss}

\begin{theorem}
  Si $A$ y $B$ son dos matrices equivalentes por filas, entonces los sistemas de ecuaciones que
  representan son también equivalentes.
\end{theorem}

\begin{remark}
  Para resolver una sistema de ecuaciones lineales por el método de Gauss (o
  de eliminación) se siguen los pasos siguientes.
  
    Primero. Escribir la matriz ampliada ($A^{\ast}$). Realizar operaciones
    elementales {\tmstrong{sobre sus filas}} hasta transformar dicha matriz en
    una matriz escalonada por filas.
    
    Segundo. Escribir el sistema de ecuaciones correspondiente a la matriz
    escalonada por filas obtenida antes.
    
    Tercero. Resolver dicho sistema escalonado, prescindiendo de las
    ecuaciones nulas ($0 = 0$) que pueden aparecer al final del mismo. La
    forma de resolver el sistema dependerá del tipo de sistema:
    \begin{itemize}
      \item SI. La última ecuación no nula será de la forma $0 = b_m$, siendo
      $b_m \neq 0$. Esa ecuación no se verifica nunca, por lo que,
      efectivamente, el sistema resulta ser incompatible: no tiene ninguna
      solución.
      
      \item SCD. Cada ecuación tendrá una incógnita menos que la anterior. Se
      resuelve el sistema ``desde abajo hacia arriba'': en la última ecuación
      despejamos la incógnita que aparece (puesto que el sistema es escalonado
      y SCD, sólo aparecerá una); luego sustituimos dicha incógnita en la
      ecuación anterior, y despejamos la otra incógnita que aparece (en esa
      penúltima ecuación deben aparecer sólo dos incógnitas); y así,
      sucesivamente: como cada ecuación tiene sólo una incógnita más que la
      siguiente, una vez hallados los valores de las incógnitas que hay en la
      siguiente, se puede despejar la nueva incógnita que aparezca.
      
      \item SCI. Seleccionamos la ``incógnitas principales'' (también llamadas \emph{básicas} o \emph{dependientes}), que son las
      correspondientes a las cabeceras de las filas en la matriz escalonada por filas
      (la cabecera de una fila es su primer elemento no nulo); el resto de las
      incógnitas se tomarán como ``parámetros'' (también se llaman \emph{independientes} o \emph{libres}). En cada ecuación se dejan las
      incógnitas principales en el primer miembro, y se pasan las
      incógnitas-parámetro al segundo miembro (como si fueran números). El
      sistema que queda (considerando únicamente las incógnitas principales
      como tales) es escalonado, y se resuelve ``desde abajo hacia arriba'',
      igual que en el caso anterior.
    \end{itemize}
\end{remark}

\begin{example}
Se considera el sistema lineal de ecuaciones dependiente del parámetro
real $m$:

  \begin{center}
    $\left\{\begin{array}{l}
      m x + y - 3 z = 5\\
      - x + y + z = - 4\\
      x + m y - m z = 1
    \end{array}\right.$
  \end{center}
  \begin{enumeratealpha}
    \item Discútase el sistema según los diferentes valores del parámetro $m$.
    
    Aplicaremos el Teorema de Rouché. Para ello, debemos calcular el rango de
    la matriz de coeficientes ($A$) y de la matriz ampliada ($A^{\ast}$), y
    compararlos entre sí, y con el número de incógnitas del sistema (3).
    Dichas matrices son:
    
    \[A = \left(\begin{array}{ccc}
      m & 1 & - 3\\
      - 1 & 1 & 1\\
      1 & m & - m
    \end{array}\right) ;\ A^{\ast} = \left(\begin{array}{cccc}
      m & 1 & - 3 & 5\\
      - 1 & 1 & 1 & - 4\\
      1 & m & - m & 1
    \end{array}\right)\]
    
    Comenzaremos calculando el rango de $A$. Dado que $\tmop{rango} ( A ) = 3 \Leftrightarrow \det ( A ) \neq 0$,
    hallaremos los valores de $m$ que anulan $\det ( A )$:
    
    \begin{eqnarray*}\det ( A ) & = & \left|\begin{array}{ccc}
      m & 1 & - 3\\
      - 1 & 1 & 1\\
      1 & m & - m
    \end{array}\right| = - m^2 + 1 + 3 m + 3 - m - m^2 = - 2 m^2 + 2 m + 4 = -
    2 ( m^2 - m - 2 ) \\
    & = & - 2 ( m - 2 ) ( m + 1 )\end{eqnarray*}
    
    \[\det ( A ) = 0 \Leftrightarrow - 2 ( m - 2 ) ( m + 1 ) = 0
    \Leftrightarrow m = \left\{\begin{array}{l}
      2\\
      - 1
    \end{array}\right.\]
    
    Ya tenemos que $\tmop{rango} ( A ) = 3 \ \forall m \in \mathbb{R}, \ m \neq 2 \text{ y } m \neq - 1$, y también que $\tmop{rango} (A) < 3$ para $m=2$ y $m=-1$. Ahora, para $m = 2$ y para $m = - 1$, sólo tenemos que determinar si el rango es 2 o 1. Podemos observar que, sea cual sea el valor de $m$, la matriz contiene un menor de orden 2 no nulo, que es el que se obtiene al quitar la primera columna y la tercera fila:
    
    \[\left|\begin{array}{cc}
      1 & - 3\\
      1 & 1
    \end{array}\right| = 1 + 3 = 4 \neq 0\]
    
    Por tanto, para cualquier valor de $m$, $\tmop{rango} ( A ) \geqslant 2$.
    En concreto, para $m = 2$ y para $m = - 1$, el rango ha de ser
    exactamente 2, ya que hemos comprobado antes que para esos valores el
    rango no era 3. En resumen:
    
    \[\tmop{rango} ( A ) = \left\{\begin{array}{ll}
      3, & \tmop{si} m \neq 2 \text{ y } m \neq - 1\\
      2 ,& \tmop{si} m = 2\\
      2, & \tmop{si} m = - 1
    \end{array}\right.\]
    
    A continuación calcularemos el rango de $A^{\ast}$ distinguiendo los
    mismos valores de $m$ que nos han dado distintos valores del rango de $A$.
    
    Para $m \neq 2$ y $m \neq - 1$, el rango de $A^{\ast}$ ha de ser
    necesariamente 3, ya que no puede ser mayor que 3, por tener sólo 3 filas,
    y tampoco puede ser menor que 3, porque el rango de $A^{\ast}$ nunca puede
    ser menor que el de $A$, que para esos valores de $m$ vale 3.
    
    Para hallar el rango en los dos casos restantes, aplicaremos el método de
    Gauss.
    
    Para $m = 2$, la matriz $A^{\ast}$ es la siguiente:
    
    \[A^{\ast} = \left(\begin{array}{cccc}
      2 & 1 & - 3 & 5\\
      - 1 & 1 & 1 & - 4\\
      1 & 2 & - 2 & 1
    \end{array}\right) \thicksim \left(\begin{array}{cccc}
      - 1 & 1 & 1 & - 4\\
      2 & 1 & - 3 & 5\\
      1 & 2 & - 2 & 1
    \end{array}\right) \sim \left(\begin{array}{cccc}
      - 1 & 1 & 1 & - 4\\
      0 & 3 & - 1 & - 3\\
      0 & 3 & - 1 & - 3
    \end{array}\right) \sim \left(\begin{array}{cccc}
      - 1 & 1 & 1 & - 4\\
      0 & 3 & - 1 & - 3\\
      0 & 0 & 0 & 0
    \end{array}\right)\]
    
    Hemos obtenido una matriz escalonada por filas equivalente con 2 filas no nulas. Por
    tanto, para $m = 2$, tenemos $\tmop{rango} ( A^{\ast} ) = 2$.
    
    Para $m = - 1$:
    
    \[A^{\ast} = \left(\begin{array}{cccc}
      - 1 & 1 & - 3 & 5\\
      - 1 & 1 & 1 & - 4\\
      1 & - 1 & 1 & 1
    \end{array}\right) \thicksim \left(\begin{array}{cccc}
      - 1 & 1 & - 3 & 5\\
      0 & 0 & 4 & - 9\\
      0 & 0 & - 2 & 6
    \end{array}\right) \sim \left(\begin{array}{cccc}
      - 1 & 1 & - 3 & 5\\
      0 & 0 & 4 & - 9\\
      0 & 0 & - 4 & 12
    \end{array}\right) \sim \left(\begin{array}{cccc}
      - 1 & 1 & - 3 & 5\\
      0 & 0 & 4 & - 9\\
      0 & 0 & 0 & 3
    \end{array}\right)\]
    
    Hemos obtenido una matriz escalonada por filas equivalente con 3 filas no nulas. Por
    tanto, para $m = - 1$, el rango de $A^{\ast}$ es 3.
    
    En resumen, hemos obtenido:
    
    \[\tmop{rango} ( A^{\ast} ) = \left\{\begin{array}{ll}
      3, & \text{si } m \neq 2 \text{ y } m \neq - 1\\
      2, & \text{si } m = 2\\
      3, & \text{si } m = - 1
    \end{array}\right.\]
    
    Comparando ahora ambos rangos entre sí y con el número de incógnitas
    ($n$), tenemos:
    \begin{itemize}
      \item si $m \neq 2$ y $m \neq - 1$, $\tmop{rango} ( A ) = \tmop{rango} (
      A^{\ast} ) = 3 = n \Rightarrow \text{sist. compatible determinado}$;
      
      \item si $m = 2$, $\tmop{rango} ( A ) = \tmop{rango} ( A^{\ast} ) = 2 <
      3 = n \Rightarrow \text{sist. compatible indeterminado}$;
      
      \item si $m = - 1$, $\tmop{rango} ( A ) = 2 \neq 3 = \tmop{rango} (
      A^{\ast} ) \Rightarrow \text{sist. incompatible}$.
    \end{itemize}
    \item Resuélvase el sistema para $m = 2$.
    
    Según acabamos de comprobar, para $m = 2$, el sistema es compatible
    indeterminado, es decir, tiene infinitas soluciones. Además, como $n -
    \tmop{rango} ( A ) = 3 - 2 = 1$, el sistema es uniparamétrico (1 grado de
    libertad).
    
    Resolveremos el sistema por el método de Gauss. Para ello, transformaremos
    la matriz ampliada en una matriz escalonada por filas equivalente mediante
    operaciones elementales sólo sobre sus filas:
    
    \[A^{\ast} = \left(\begin{array}{cccc}
      2 & 1 & - 3 & 5\\
      - 1 & 1 & 1 & - 4\\
      1 & 2 & - 2 & 1
    \end{array}\right) \thicksim \left(\begin{array}{cccc}
      - 1 & 1 & 1 & - 4\\
      2 & 1 & - 3 & 5\\
      1 & 2 & - 2 & 1
    \end{array}\right) \sim \left(\begin{array}{cccc}
      - 1 & 1 & 1 & - 4\\
      0 & 3 & - 1 & - 3\\
      0 & 3 & - 1 & - 3
    \end{array}\right) \sim \left(\begin{array}{cccc}
      - 1 & 1 & 1 & - 4\\
      0 & 3 & - 1 & - 3\\
      0 & 0 & 0 & 0
    \end{array}\right)\]
    
    Las operaciones elementales efectuadas han sido las siguientes:
    intercambiar la 1ª y la 2ª filas; sumarle a la
    2ª fila la 1ª multiplicada por 2; sumarle a la
    3ª fila la 1ª; restarle a la 3ª
    fila la 2ª.
    
    A continuación escribimos el sistema de ecuaciones cuya matriz ampliada es
    la matriz escalonada por filas así obtenida:
    
    \[\left\{\begin{array}{l}
      - x + y + z = - 4\\
      3 y - z = - 3\\
      0 = 0
    \end{array}\right.\]
    
    Resolvemos este sistema prescindiendo de la última ecuación nula (0=0).
    Para ello, tomaremos como incógnitas principales la $x$ y la $y$ (que son
    las cabeceras de las filas de la matriz escalonada por filas), y como parámetro la
    $z$. Para resaltar esto, llamaremos $z = \mu$. Pasamos este parámetro al
    segundo miembro de cada ecuación, y resolvemos desde abajo hacia arriba:
    
    \begin{eqnarray*}\left\{\begin{array}{l}
      - x + y + z = - 4\\
      3 y - z = - 3\\
      z = \mu
    \end{array}\right. & \sim & \left\{\begin{array}{l}
      - x + y = - 4 - \mu\\
      3 y = - 3 + \mu\\
      z = \mu
    \end{array}\right. \sim \left\{\begin{array}{l}
      - x + y = - 4 - \mu\\
      y = - 1 + \frac{1}{3} \mu\\
      z = \mu
    \end{array}\right. \sim \left\{\begin{array}{l}
      - x + ( - 1 + \frac{1}{3} \mu ) = - 4 - \mu\\
      y = - 1 + \frac{1}{3} \mu\\
      z = \mu
    \end{array}\right. \\ & \sim & \left\{\begin{array}{l}
      - x = - 4 - \mu + 1 - \frac{1}{3} \mu\\
      y = - 1 + \frac{1}{3} \mu\\
      z = \mu
    \end{array}\right. \sim \left\{\begin{array}{l}
      - x = - 3 - \frac{4}{3} \mu\\
      y = - 1 + \frac{1}{3} \mu\\
      z = \mu
    \end{array}\right. \sim \left\{\begin{array}{l}
      x = 3 + \frac{4}{3} \mu\\
      y = - 1 + \frac{1}{3} \mu\\
      z = \mu
    \end{array}\right.\end{eqnarray*}
    
    Las soluciones del sistema son:
    
    \[\left\{ ( x, y, z ) = \left( 3 + \frac{4}{3} \mu, - 1 + \frac{1}{3} \mu, \mu \right) \mid
    \mu \in \mathbb{R} \right\}\]
  \end{enumeratealpha}
\end{example}

\newpage\section{Sistemas de Cramer}

\begin{definition}
  Se dice que un sistema de ecuaciones lineales es un {\tmstrong{sistema de
  Cramer}} si su matriz de coeficientes es cuadrada y regular.
\end{definition}

\begin{remark}
  Un sistema de Cramer ha de tener igual número de ecuaciones que de
  incógnitas (para que la matriz de coeficientes sea cuadrada), y todas sus
  ecuaciones han de ser linealmente independientes. El determinante de la
  matriz de coeficientes ha de ser distinto de cero.
\end{remark}

\begin{theorem}
  Todo sistema de Cramer es compatible determinado, y su solución viene dada
  por ({\tmstrong{regla de Cramer}}):
  
      \[x_1 = \dfrac{\Delta_1}{\Delta} ; x_2 = \dfrac{\Delta_2}{\Delta} ; \ldots x_n = \dfrac{\Delta_n}{\Delta}\]
    
\noindent donde $\Delta = \det ( A )$ es el determinante de la matriz de los coeficientes, y $\Delta_i$ es el determinante de la matriz que se obtiene al sustituir en la matriz de los coeficientes la columna i-ésima por la columna de los términos independientes.
\end{theorem}

\begin{remark}
  Un sistema de Cramer se puede también resolver despejando $X$ en la ecuación matricial $A X = B$, utilizando la inversa de $A$. Obsérvese que si el sistema es de Cramer, por definición, $A$ es invertible. Los cálculos necesarios para hallar la inversa de $A$ y multiplicarla por $B$ son idénticos a los que hay que hacer al aplicar la regla de Cramer: en realidad, la regla de Cramer no es más que una forma fácilmente memorizable de realizar dichos cálculos.
\end{remark}

\begin{example}
Resolver el siguiente sistema por el método de Cramer:

\[\left\{\begin{array}{l}
  2 x + y - 3 z = 1\\
  - x + 5 y + z = 4\\
  3 x - 2 y - 4 z = - 1
\end{array}\right.\]

Observemos que el sistema tiene 3 ecuaciones y 3 incógnitas, y, por tanto, la
matriz de coeficientes es cuadrada. Si no fuera así, no podríamos utilizar el
método de Cramer. Calculamos en primer lugar el determinante de la matriz de coeficientes, $A$,
utilizando Sarrus:

\[\Delta = \det ( A ) = \left|\begin{array}{ccc}
  2 & 1 & - 3\\
  - 1 & 5 & 1\\
  3 & - 2 & - 4
\end{array}\right| = - 40 + 3 - 6 + 45 - 4 + 4 = 2\]

$|A|$ es distinto de cero, lo cual significa que la matriz de coeficientes es
regular, y, por tanto, el sistema es un sistema de Cramer (y es compatible
determinado). Si no fuera así, no podríamos aplicar Cramer.
A continuación, calculamos los determinantes que se obtiene al sustituir cada columna de $A$ por la columna de los términos independientes. Cada incógnita se calcula diviendo el determinante correspondiente a su columna entre el de $A$:

\[x = \dfrac{\Delta_1}{\Delta} = \dfrac{\left|\begin{array}{ccc}
  1 & 1 & - 3\\
  4 & 5 & 1\\
  - 1 & - 2 & - 4
\end{array}\right|}{\left|\begin{array}{ccc}
  2 & 1 & - 3\\
  - 1 & 5 & 1\\
  3 & - 2 & - 4
\end{array}\right|} = \dfrac{6}{2} = 3;\]

\[y = \dfrac{\Delta_2}{\Delta} = \dfrac{\left|\begin{array}{ccc}
  2 & 1 & - 3\\
  - 1 & 4 & 1\\
  3 & - 1 & - 4
\end{array}\right|}{\left|\begin{array}{ccc}
  2 & 1 & - 3\\
  - 1 & 5 & 1\\
  3 & - 2 & - 4
\end{array}\right|} = \dfrac{2}{2} = 1 ;\]

\[z = \dfrac{\Delta_3}{\Delta} = \dfrac{\left|\begin{array}{ccc}
  2 & 1 & 1\\
  - 1 & 5 & 4\\
  3 & - 2 & - 1
\end{array}\right|}{\left|\begin{array}{ccc}
  2 & 1 & - 3\\
  - 1 & 5 & 1\\
  3 & - 2 & - 4
\end{array}\right|} = \dfrac{4}{2} = 2\]

La solución del sistema es:
\[( x, y, z ) = ( 3, 1, 2 ).\]
\end{example}

\newpage\section{Sistemas homogéneos}

\begin{definition}
  [Sistema homogéneo] Se dice que un sistema de ecuaciones lineales es {\tmstrong{homogéneo}} si todos sus términos independientes son nulos.
\end{definition}

\begin{theorem}
  Todo sistema de ecuaciones lineales homogéneo es compatible, ya que tiene, al menos la solución $x_1 = 0, x_2 = 0, \ldots x_n = 0$, que se llama \emph{solución trivial o nula}.
\end{theorem}

\begin{remark}
  La expresión matricial de un sistema homogéneo es $A X = O$, donde $O$ es la matriz columna nula.
\end{remark}

\begin{remark}
  Un sistema homogéneo es compatible determinado si su única solución es la solución nula. Será compatible indeterminado si tiene alguna solución distinta de la nula. Del teorema de Rouché se deduce trivialmente que un sistema homogéneo es indeterminado si y sólo si el rango de su matriz de coeficientes es menor que el número de incógnitas.
\end{remark}

\begin{remark}
  En un sistema homogéneo, cualquier combinación lineal de soluciones del sistema es también solución del mismo.
\end{remark}

\begin{example}
Discutir el sistema de ecuaciones para los distintos valores del parámetro real $k$:

\begin{center}
  $\left\{\begin{array}{l}
    2 x - 3 y + z = 0\\
    x - k y - 3 z = 0\\
    5 x + 2 y - z = 0
  \end{array}\right.$
\end{center}

El sistema es homogéneo, ya que tiene nulos todos sus términos independientes. Por lo tanto, es siempre compatible. Sólo hay que averiguar si es compatible determinado o indeterminado. Para ello, bastará, según el Teorema de Rouché, con comparar el rango de la matriz de los coeficientes con el número de incógnitas. El sistema tiene 3 incógnitas, por lo que será determinado si y sólo si el rango de la matriz de los coeficientes es igual a 3. Será indeterminado en los demás casos.

Dado que la matriz de los coeficientes ($A$) es cuadrada de dimensión $3\times 3$, su rango será igual a 3 si y sólo si su determinante es distinto de cero. Por tanto, el sistema será compatible indeterminado para los valores de $k$ que anulen el determinante de $A$, y será compatible determinado para todos los demás valores de $k$.

Aplicando la regla de Sarrus:

\[\det ( A ) = \left|\begin{array}{ccc}
  2 & - 3 & 1\\
  1 & - k & - 3\\
  5 & 2 & - 1
\end{array}\right| = 2 k + 45 + 2 + 5 k - 3 + 12 = 7 k + 56\]

\[\det ( A ) = 0 \Leftrightarrow 7 k + 56 = 0 \Leftrightarrow k = - 8;\ \tmop{rango} ( A ) = 3 \Leftrightarrow \det ( A ) \neq 0 \Leftrightarrow k
\neq - 8.\]

En cualquier caso, el rango de $A$ será mayor o igual a 2, porque la primera
ecuación y la tercera son independientes entre sí (no son proporcionales).

Por tanto,

\[\tmop{rango} ( A ) = \left\{\begin{array}{ll}
  3, & \tmop{para} k \neq - 8\\
  2, & \tmop{para} k = - 8
\end{array}\right.\]

En el caso de $k = - 8$, el sistema será uniparamétrico, porque $n - r = 1$,
siendo $n$ el número de incógnitas, y $r$ el rango de $A$.

Es decir,
\begin{itemize}
\item Si $k \neq - 8$ el sistema es compatible determinado;
\item Si $k = - 8$ el sistema es compatible indeterminado uniparamétrico.
\end{itemize}

\end{example}

\part{Geometría Analítica}

\chapter{Vectores}

\newpage\section{Vectores libres}

\begin{definition}[Vector libre]Se llama {\tmstrong{vector libre}} a un conjunto
ordenado de tres números reales. Los números que forman un vector libre reciben
el nombre de {\tmstrong{componentes}}. Un vector libre $\vec{v}$ cuyas
componentes son (en este orden) $v_1$, $v_2$, $v_3$ se representa así:

\begin{center}
  $\vec{v} = ( v_1, v_2, v_3 )$
\end{center}
\end{definition}

\begin{definition}[$\mathbb{R}^3$]Al conjunto de todos los vectores libres se le
llama \textbf{espacio vectorial} $\mathbb{R}^3$. Es decir,

\begin{center}
  $\mathbb{R}^3 = \{ ( a, b, c ) / a, b, c \in \mathbb{R} \}$
\end{center}
\end{definition}

\begin{remark}Se llama \emph{producto cartesiano} de dos conjuntos $A$ y $B$ al
conjunto de todos los pares ordenados cuyo primer elemento es de $A$ y el
segundo de $B$. Se representa por $A \times B$. La definición de
$\mathbb{R}^3$ coincide con la del producto cartesiano $\mathbb{R} \times
\mathbb{R} \times \mathbb{R}$, de donde deriva el símbolo $\mathbb{R}^3$.\end{remark}

\begin{remark}El concepto de espacio vectorial es más general que este. En un anexo puede encontrarse una definición de espacio vectorial con toda la generalidad posible. Según dicha definición, existen otros espacios vectoriales formados por vectores que no tienen nada que ver con los vectores libres que acabamos de definir. No obstante, los vectores libres tienen un lugar especialmente importante entre los espacios vectoriales (también puede encontrarse la razón de esto en el anexo).\end{remark}

\begin{remark}Hay dos formas de definir los vectores libres, una algebraica y otra
geométrica. La que hemos dado aquí es la definición algebraica (los vectores
se definen a partir de los números reales, sin ninguna referencia a conceptos
geométricos como longitud, ángulos, puntos, etc.). Todas las definiciones y
teoremas subsiguientes se basan en esta definición algebraica, siendo, por
tanto, independientes de la aplicación geométrica de los vectores libres. De
todos modos, junto a cada definición o teorema daremos su definición
geométrica equivalente o interpretación geométrica, ya que esta es la
aplicación que nos interesa ahora.

La definición geométrica sería la siguiente. En primer lugar se define ``vector
fijo'' como ``segmento orientado en el espacio'' (recordar que segmento es una
porción de recta delimitada por dos puntos llamados extremos; orientado
significa que un extremo se considera origen del vector). A continuación, se
definen: ``módulo'' de un vector es su longitud (el módulo de un vector
$\vec{v}$ se representa por $| \vec{v} |$), ``dirección'' es la dirección de la recta que lo
contiene, ``sentido'' es su orientación dentro de la recta. Finalmente, ``vector
libre de módulo m, dirección r y sentido s'' se define como el conjunto de
todos los vectores fijos que tienen módulo m, dirección paralela a r y sentido
s. Las componentes de un vector se definen como sus proyecciones ortogonales
sobre los ejes.

Como se ve, los vectores fijos de un mismo vector libre se distinguen solo por
su origen (también llamado ``punto de aplicación''). De hecho, a los vectores
libres se les llama así porque no tienen un ``punto de aplicación'' fijo, sino
que se pueden ``aplicar'' en cualquier punto del espacio. Sólo representan una
dirección y una longitud en esa dirección, pero no dicen dónde comienza esa
longitud. Por ejemplo, el vector $( 1, 1, - 1 )$ se puede interpretar
geométricamente como: ``avanzar 1 metro hacia delante, 1 metro hacia la derecha
y 1 metro hacia abajo'', pero no informa del punto de partida.

Propiamente no podemos representar gráficamente un vector libre (que es un
conjunto infinito de segmentos orientados), pero se suele representar un
vector libre por uno de sus representantes (es decir, por algún vector fijo
que pertenezca a él).\end{remark}

\begin{remark}Los vectores aquí definidos son los vectores \emph{tridimensionales}. También existe un espacio vectorial de vectores de dos dimensiones (con dos componentes), $\mathbb{R}^2$, que se utilizan en geometría plana, y espacios vectoriales de vectores de más dimensiones, $\mathbb{R}^4$, $\mathbb{R}^5$,... formados por vectores con cuatro, cinco, o más componentes.\end{remark}



\newpage\section{Suma de vectores libres}

\begin{definition}Dados dos vectores libres, $\vec{u} = ( u_1, u_2, u_3 )$ y $\vec{v} = (
v_1, v_2, v_3 )$, se llama suma de $\vec{u}$ y $\vec{v}$, y se representa por
$\vec{u} + \vec{v}$, al vector libre cuyas componentes son la suma de las
componentes de $\vec{u}$ y $\vec{v}$. Es decir,

\begin{center}
  $\vec{u} + \vec{v} = ( u_1, u_2, u_3 ) + ( v_1, v_2, v_3 ) = ( u_1 + v_1,
  u_2 + v_2, u_3 + v_3 )$
\end{center}
\end{definition}

\begin{remark}Definición geométrica: los vectores se suman mediante la \emph{regla
del paralelogramo}: si se considera el paralelogramo cuyos lados son los
vectores $\vec{a}$ y $\vec{b}$, la diagonal que parte de su vértice común es
$\vec{a} + \vec{b}$, y la diagonal que une el extremo de $\vec{b}$ con el
extremo de $\vec{a}$ es $\vec{a} - \vec{b}$.\end{remark}

\begin{center}
  \includegraphics[width=7cm]{sumadevectores.pdf} \hspace{.5cm}
  \includegraphics[width=7cm]{sumadevectorespoligono.pdf}
\end{center}

\begin{theorem}
  [Propiedades de la suma]La suma de vectores libres es una operación
  interna que verifica las siguientes propiedades, para todo $\vec{u}$,
  $\vec{v}$, $\vec{w}$:
  
  \begin{enumeratealpha}
    \item Asociativa: $\vec{u} + ( \vec{v} + \vec{w} ) = ( \vec{u} + \vec{v} )
    + \vec{w}$
    
    \item Conmutativa: $\vec{u} + \vec{v} = \vec{v} + \vec{u}$
    
    \item Elemento neutro: $\vec{u} + \vec{o} = \vec{u}$, siendo $\vec{o} = (
    0, 0, 0 )$
    
    \item Elemento simétrico: $\vec{u} + ( - \vec{u} ) = \vec{o}$, siendo $-
    \vec{u} = ( - u_1, - u_2, - u_3 )$
  \end{enumeratealpha}
\end{theorem}

\newpage
\section{Producto por un escalar}

\begin{definition}[Producto por un escalar]Dado un vector libre $\vec{u} = ( u_1,
u_2, u_3 )$ y un escalar $\lambda$ de $\mathbb{R}$, se llama producto de
$\lambda$ por $\vec{u}$, y se representa por $\lambda \vec{u}$ al vector de
libre que se obtiene al multiplicar todas las componentes de $\vec{u}$ por
$\lambda$. Es decir,

\begin{center}
  $\lambda \vec{u} = \lambda ( u_1, u_2, u_3 ) = ( \lambda u_1, \lambda u_2,
  \lambda u_3 )$
\end{center}
\end{definition}

\begin{remark}Definición geométrica: el producto de un vector libre $\vec{v}$ por un
escalar $\lambda$ es otro vector libre que tiene la misma dirección que
$\vec{v}$, cuyo módulo es igual al módulo de $\vec{v}$ multiplicado por $|
\lambda |$, y cuyo sentido es igual al de $\vec{v}$ si $\lambda > 0$ y
contrario al de $\vec{v}$ si $\lambda < 0$.\end{remark}

\begin{center}
  \includegraphics[width=7cm]{productoporescalar.pdf}
\end{center}


\begin{theorem}
  [Propiedades del producto por un escalar]El producto por un escalar
  es una operación externa que verifica las propiedades siguientes, para todo
  vector $\vec{u}, \vec{v}, y \tmop{todo} \lambda, \mu \in \mathbb{R}$:
  
  \begin{enumeratealpha}
    \item Distributiva: $\left\{\begin{array}{l}
      \lambda ( \vec{u} + \vec{v} ) = \lambda \vec{u} + \lambda \vec{v}\\
      ( \lambda + \mu ) \vec{u} = \lambda \vec{u} + \mu \vec{u}
    \end{array}\right.$
    
    \item Asociativa: $\lambda ( \mu \vec{u} ) = ( \lambda \mu ) \vec{u}$
    
    \item Elemento neutro: $1 \vec{u} = \vec{u}$
  \end{enumeratealpha}
\end{theorem}

\begin{definition}[Dirección de un vector] Un vector $\vec{u}$ tiene la misma dirección que otro vctor $\vec{v}$ si y solo si existe algún $\lambda$ tal que $\vec{u} = \lambda \vec{v}$, es decir, si y solo si sus componentes son proporcionales a las de $\vec{v}$, o es nulo.\end{definition}

\begin{remark}Cuando más adelante estudiemos el concepto de dependencia lineal, veremos que esta definición podría resumirse diciendo que dos vectores tienen la misma dirección si son linealmente dependientes.\end{remark}

\newpage\section{Dependencia lineal de vectores}

\begin{definition}[Combinaci\'on lineal] Se dice que un vector $\vec{w}$ es una
  combinación lineal de un conjunto de vectores $\{ \vec{v}_1, \ldots,
  \vec{v}_k \}$ si existe un conjunto de escalares $\{ \lambda_1, \ldots,
  \lambda_k \}$ tales que:
  \begin{center}
    $\vec{w} = \lambda_1 \vec{v}_1 + \ldots + \lambda_k \vec{v}_k =
    \overset{k}{\underset{i = 1}{\sum}} \lambda_i \vec{v}_i$
  \end{center}
  Si un vector es una combinación lineal de un conjunto de vectores, también
  se dice que depende linealmente de ellos. A los escalares $\lambda_1, \ldots, \lambda_k$ se les llama coeficientes de
  la combinación lineal.
\end{definition}

\begin{example}
  El vector $(-6,1,2)$ es una combinación lineal de los
  vectores $\{ (1,-1,1), (2,0,3), (-2,1,1) \}$, ya que
  \begin{center}
    $2 (1,-1,1)-(2,0,3)+3(-2,1,1)=(-6,1,2)$
  \end{center}
Los coeficientes de la combinación lineal anterior serían: $2,
  - 1, 3$.
\end{example}

\begin{definition}
  [Dependencia lineal]Se dice que un conjunto de vectores es
  linealmente dependiente (o ligado) si al menos uno de ellos es una
  combinación lineal de los demás. En caso contrario, se dice que el conjunto
  de vectores es linealmente independiente (o libre).
\end{definition}

\begin{remark}Se puede demostrar que un conjunto de vectores $\{ \vec{v}_1, \ldots,
\vec{v}_k \}$ es linealmente independiente si y solo si
$\overset{k}{\underset{i = 1}{\sum}} \lambda_i \vec{v}_i = \vec{o} \Rightarrow
\lambda_i = 0, \forall i \in \{ 1, \ldots, k \}$, es decir, si la única
combinación lineal que da como resultado el vector nulo es la que tiene todos
los coeficientes nulos.\end{remark}

\begin{remark}Un conjunto de vectores que incluya al vector nulo siempre es ligado (ya
que el vector nulo siempre se puede obtener como combinación lineal de los
demás).\end{remark}

\begin{remark}Un conjunto de un único vector se considera siempre libre, salvo que
dicho vector sea $\vec{o}$.\end{remark}

\begin{remark}Un conjunto de dos vectores no nulos $\{ \vec{u}, \vec{w} \}$ es ligado
si y solo si los dos vectores son proporcionales, ya que si uno de los dos se
puede obtener como combinación lineal del otro, es que existe algún escalar
$\lambda$ tal que $\vec{u} = \lambda \vec{w}$ (esto es lo mismo que decir que
$\vec{u}$ y $\vec{w}$ son proporcionales).\end{remark}

\begin{remark}Se puede demostrar que si un conjunto de vectores $\{ \vec{v}_1, \ldots,
\vec{v}_k \}$ es linealmente independiente, entonces no existen dos
combinaciones lineales distintas de dichos vectores que den el mismo
resultado. La demostración (por reducción al absurdo) se deja como
ejercicio.\end{remark}

\begin{example}
  El conjunto de vectores, $\{ ( 1, - 1, 0 ), ( - 1, 1, 2 ), ( 2,
  - 2,-2 ) \}$, es linealmente dependiente porque al menos uno de ellos se puede
  obtener como combinación lineal de los otros dos, puesto que se tiene
  \begin{center}
    $( 2, - 2, -2 ) = 2 ( 1, - 1, 0 ) - ( - 1, 1, 2 )$
  \end{center}
En este caso, cualquiera de los tres vectores se puede obtener
  como combinación lineal de los otros dos. Pero, basta con uno de ellos para
  que el conjunto sea ligado. ¿Hay casos en los que alguno se pueda expresar
  como combinación lineal de los demás, pero solo ese pueda expresarse así? La
  respuesta es afirmativa. Buscar un ejemplo de esto se deja como ejercicio.
\end{example}

\begin{example}
  El conjunto de vectores, $\{ ( 2, - 1, 0 ), ( - 10, 5, 0 ) \}$,
  es ligado porque los dos vectores son proporcionales: $( - 10, 5, 0 ) = - 5 (
  2, - 1, 0 )$.
\end{example}

\newpage\section{Bases}

\begin{definition}
  [Conjunto generador]Se dice que un
  conjunto de vectores $S = \{ \vec{v}_1, \ldots, \vec{v}_k \}$ es un conjunto
  generador del espacio vectorial si cualquier vector del espacio se puede obtener como
  combinación lineal de los vectores de $S$.
\end{definition}

\begin{example}
  El conjunto $S_1 = \{ ( 1, 1, 0 ), ( 1, - 1, 0 ), (0, - 1, 1 ), ( - 1, 0, - 1 ) \}$ es
  un sistema generador de $\mathbb{R}^3$, porque cualquier vector de
  $\mathbb{R}^3$ se puede obtener como combinación lineal de los vectores de
  $S_1$. Otra cuestión sería demostrar esto que acabamos de afirmar (se
  propone como ejercicio).
\end{example}

\begin{definition}
  [Base]Se dice que un conjunto de
  vectores $S = \{ \vec{v}_1, \ldots, \vec{v}_k \}$ es una base del espacio vectorial si $S$
  es un conjunto libre y generador del espacio.
\end{definition}

\begin{example}
  El conjunto $S_2 = \{ ( 1, 1, 0 ), ( 1, - 1, 0 ), (0,-1,1) \}$ es una base de
  $\mathbb{R}^3$ porque es un conjunto generador (cualquier vector de
  $\mathbb{R}^3$ se puede obtener como combinación lineal de esos dos), y
  además es linealmente independiente. Sin embargo, el conjunto $S_1$ del ejemplo anterior no
  es una base, aunque sea generador, porque es linealmente dependiente (claro,
  si $S_2$ es generador, también $( - 1, 0, - 1 )$ se puede
  obtener como combinación lineal de los tres primeros vectores).
\end{example}

\begin{theorem}
  [Teorema de la dimensión]Todas las bases de un mismo espacio
  vectorial tienen el mismo número de vectores.
\end{theorem}

\begin{definition}
  [Dimensión]Se llama dimensión de un espacio vectorial al número de
  vectores de sus bases.
\end{definition}

\begin{remark}Según hemos visto en un ejemplo, la dimensión del espacio vectorial $\mathbb{R}^3$ es $3$, ya que encontramos una base con tres vectores. Esto nos permite concluir para nuestro espacio vectorial $\mathbb{R}^3$:
  \begin{itemize}
  \item Cualquier conjunto con más de tres vectores es linealmente dependiente.
  \item Todo conjunto generador debe tener al menos tres vectores.
  \item Un conjunto de tres vectores que sea libre ha de ser generador y, por tanto, una base.
  \end{itemize}
\end{remark}

\begin{definition}
  [Coordenadas de un vector]Sea $B = \{ \vec{u}_1, \vec{u}_2, \vec{u}_3 \}$ una base de
  $\mathbb{R}^3$, y sea $\vec{w}$ un vector de $\mathbb{R}^3$. Se dice que los escalares $\lambda_1,
  \lambda_2, \lambda_3$ son las coordenadas de $\vec{w}$ respecto de la base $B$
  si y solo si $\vec{w} = \lambda_1 \vec{u}_1 + \lambda_2\vec{u}_2 + \lambda_3 \vec{u}_3$.
  Para indicar que $\vec{w}$ es el vector cuyas coordenadas respecto de $B$
  son $\lambda_1, \lambda_2, \lambda_3$, se escribe: $\vec{w} ( \lambda_1,
  \lambda_2, \lambda_3 )_B$.
\end{definition}

\begin{remark}Existencia y unicidad de las coordenadas. Todo vector de $\mathbb{R}^3$ tiene
coordenadas respecto de cualquier base $B$, y, además, estas son únicas (es
decir, que cada vector tiene un único conjunto de coordenadas, y no hay
dos vectores con las mismas coordenadas).\end{remark}



\begin{definition}[Base canónica de $\mathbb{R}^3$]Se llama base canónica de
$\mathbb{R}^3$ a la siguiente:

  \[B_c = \{ \vec{i}, \vec{j}, \vec{k} \},\]

siendo $\vec{i} = ( 1, 0, 0 ), \vec{j} = ( 0, 1, 0 ), \vec{k} = ( 0, 0, 1 )$.
\end{definition}

\begin{remark}Las coordenadas de cualquier vector respecto de esta base coinciden con
sus componentes:

$$\vec{u} = ( u_1, u_2, u_3 ) = ( u_1, 0, 0 ) + ( 0, u_2, 0 ) + ( 0, 0, u_3 ) = u_1 ( 1, 0, 0 ) + u_2 ( 0, 1, 0 ) + u_3 ( 0, 0, 1 ) = u_1 \vec{i} + u_2
\vec{j} + u_3 \vec{k}$$

\end{remark}

\newpage\section{Puntos y vectores fijos}

\begin{definition} [Espacio Afín o Geométrico]El espacio afín está constituido por
un conjunto $E_3$, a cuyos elementos llamamos puntos, y una aplicación, que a
cada par de puntos $( P, Q )$ le asigna un vector $\vec{v}$ de
$\mathbb{R}^3$, que se representa por $\overrightarrow{P Q}$, de manera que:

\begin{enumeratealpha}
  \item Para todo P, Q, R $\in$ $E_3$, se verifica: $\overrightarrow{P Q} +
  \overrightarrow{Q R} = \overrightarrow{P R}$ (relación de Chasles).
  
  \item Para cada punto $P \in E_3$ y cada vector $\vec{v} \in \mathbb{R}^3$,
  existe un punto $Q \in E_3$ tal que $\vec{v} = \overrightarrow{P Q}$, y
  dicho punto $Q$ es el único que verifica esa igualdad.
\end{enumeratealpha}
\end{definition}

\begin{remark}Aquí estamos definiendo en realidad qué son los {\tmstrong{puntos}} (el
espacio afín sería simplemente el conjunto de todos los puntos). Los vectores
expresan ``desplazamientos'', los puntos expresan ``posiciones''. El vector
$\overrightarrow{P Q}$ es el desplazamiento que hay que hacer para alcanzar la
posición $Q$ a partir de la posición $P$.\end{remark}

\begin{remark}De manera análoga a como hemos definido el espacio geométrico, se define
también el plano geométrico o plano afín, llamado $E_2$, utilizando vectores
de $\mathbb{R}^2$ en lugar de vectores de $\mathbb{R}^3$.\end{remark}

\begin{definition} [Vector fijo]Se llama vector fijo a un par formado por un punto $P$
y un vector libre $\vec{v}$. Al punto $P$ se le llama
{\tmstrong{origen}} del vector fijo, y al punto $Q$ tal que $\vec{c} = \overrightarrow{PQ}$ se le
llama {\tmstrong{extremo}} del mismo.\end{definition}

\begin{remark}
  El símbolo $\overrightarrow{PQ}$ representa a un vector libre (el asociado al par de puntos $(P,Q)$, pero con frecuencia lo utilizaremos como representación del vector fijo con origen en $P$ y extremo en $Q$.
\end{remark}

\begin{theorem}
  [Primeras propiedades]Dados $P, P', Q, Q' \in E_3$ cualesquiera, se
  cumple:
  
  \begin{enumeratealpha}
    \item $\overrightarrow{P Q} = \vec{o} \Leftrightarrow P = Q$
    
    \item $\overrightarrow{P Q} = - \overrightarrow{Q P}$
    
    \item $\overrightarrow{P Q} = \overrightarrow{P' Q'} \Rightarrow
    \overrightarrow{P P'} = \overrightarrow{Q Q'}$
  \end{enumeratealpha}
\end{theorem}

{}

\newpage\section{Coordenadas cartesianas}

\begin{definition} [Sistema de referencia cartesiano]Un sistema de referencia
cartesiano es un par $( O ; B )$ formado por un punto $O$ de $E_3$, y una base
$B = \{ \overrightarrow{e_1}, \overrightarrow{e_2}, \overrightarrow{e_3} \}$
de $\mathbb{R}^3$. Al punto $O$ se le llama {\tmstrong{origen}} del sistema
de referencia.
\end{definition}

\begin{definition} [Coordenadas de un punto]Se llaman coordenadas cartesianas de un
punto $P$ en un sistema de referencia cartesiano $S = ( O ; B )$ a las
coordenadas del vector $\overrightarrow{O P}$ respecto de la base $B$ del
sistema de referencia. Para expresar que $P$ es el punto cuyas coordenadas
respecto del sistema de referencia $S = ( O ; B )$ son $p_1$, $p_2$ y $p_3$,
se escribe $P ( p_1, p_2, p_3 )_S$.
\end{definition}

\begin{remark}El subíndice $_S$ que indica el sistema de referencia utilizado suele
omitirse.\end{remark}

\begin{remark}Dado un sistema de referencia, las coordenadas determinan de manera
inequívoca a cada punto (no existen dos puntos distintos con las mismas
coordenadas). Por esta razón, un punto $P$ y ``su vector desde el origen'',
$\overrightarrow{O P}$, son ``intercambiables'', y a veces se escribe $P$ en
lugar de $\overrightarrow{O P}$, para simplificar las expresiones.\end{remark}

\begin{theorem}
  [Coordenadas de un vector fijo]Sean dos puntos $P ( p_1, p_2, p_3 )$
  y $Q ( q_1, q_2, q_3 )$ en un cierto sistema de referencia cartesiano $S = (
  O ; \{ \overrightarrow{e_1}, \overrightarrow{e_2}, \overrightarrow{e_3} \}
  )$. Las coordenadas de $\overrightarrow{P Q}$ respecto de la base del
  sistema de referencia utilizado son: $\overrightarrow{P Q} ( q_1 - p_1, q_2
  - p_2, q_3 - p_3 )$, es decir,
  \begin{center}
    $\overrightarrow{P Q} = \overrightarrow{O Q} - \overrightarrow{O P}$
  \end{center}
  
\end{theorem}


\section{Punto medio de un segmento}

\begin{theorem}
  Las coordenadas del punto medio $M$ de un segmento de extremos $A$ y $B$
  vienen dadas por:

    \[\overrightarrow{O M} = \dfrac{1}{2} ( \overrightarrow{O A} + \overrightarrow{O B} )\]
  
\end{theorem}

\begin{remark}Para poder demostrar el teorema anterior necesitaríamos una definición
de ``punto medio de un segmento''. Valdría esta: el punto medio del segmento $A
B$ es el punto $M$ tal que $\overrightarrow{A M} = \overrightarrow{M B}$
(piénsese así: el punto medio es aquel punto $M$ para el cual el
desplazamiento desde $A$ hasta $M$ es igual al desplazamiento desde $M$ hasta
$B$. Para demostrar la fórmula anterior utilizaremos la relación de Chasles:

$\overrightarrow{A M} + \overrightarrow{M B} = \overrightarrow{A B}
\Leftrightarrow \overrightarrow{A M} + \overrightarrow{A M} =
\overrightarrow{O B} - \overrightarrow{O A} \Leftrightarrow 2
\overrightarrow{A M} = \overrightarrow{O B} - \overrightarrow{O A}
\Leftrightarrow 2 ( \overrightarrow{O M} - \overrightarrow{O A} ) =
\overrightarrow{O B} - \overrightarrow{O A} \Leftrightarrow$

$\Leftrightarrow 2 \overrightarrow{O M} - 2 \overrightarrow{O A} =
\overrightarrow{O B} - \overrightarrow{O A} \Leftrightarrow 2
\overrightarrow{O M} = \overrightarrow{O B} - \overrightarrow{O A} + 2
\overrightarrow{O A} = \overrightarrow{O B} + \overrightarrow{O A}
\Leftrightarrow \overrightarrow{O M} = \dfrac{1}{2} ( \overrightarrow{O A} +
\overrightarrow{O B} )$\end{remark}

\begin{remark}Es fácil demostrar también que los puntos $M_1$ y $M_2$ que dividen a un
segmento $A B$ en tres partes iguales vienen dados por:

\[M_1 = \dfrac{1}{3} ( 2\overrightarrow{O A} + \overrightarrow{O B} )\text{ y }M_2 =\dfrac{2}{3} ( \overrightarrow{O A} + 2\overrightarrow{O B} )\]
\end{remark}

\begin{remark}Es más difícil demostrar que las coordenadas del baricentro $M$ de un
triángulo de vértices $A$, $B$ y $C$, vienen dadas por:

\[\overrightarrow{O M} = \dfrac{1}{3} ( \overrightarrow{O A} + \overrightarrow{O
B} + \overrightarrow{O C} )\]
\end{remark}



\newpage\section{Producto escalar}

\begin{definition}[Producto escalar]Dados dos vectores de $\mathbb{R}^3$,
$\vec{u} = ( u_1, u_2, u_3 ), \vec{v} = ( v_1, v_2, v_3 )$, se llama producto
escalar de $\vec{u}$ y $\vec{v}$, y se representa por $\vec{u} \cdot \vec{v}$,
al número real dado por:

\begin{center}
  $\vec{u} \cdot \vec{v} = ( u_1, u_2, u_3 ) \cdot ( v_1, v_2, v_3 ) = u_1
  \cdot v_1 + u_2 \cdot v_2 + u_3 \cdot v_3$
\end{center}
\end{definition}

\begin{remark}Definición geométrica: se llama producto escalar de dos vectores
$\vec{u}$ y $\vec{v}$ al producto de sus módulos por el coseno del ángulo que
forman sus direcciones. Es decir,
\begin{center}
  $\vec{u} \cdot \vec{v} = | \vec{u} \| \vec{v} | \cos ( \widehat{\vec{u},
  \vec{v}} )$
\end{center}
De esta definición se puede deducir, como teorema, la definición algebraica,
que recibe entonces el nombre de ``expresión analítica'' del producto escalar.\end{remark}

\begin{theorem}
  [Propiedades del producto escalar]Para todo $\vec{u}, \vec{v},
  \vec{w} \in \mathbb{R}^3, \lambda \in \mathbb{R}$ se cumple:
  
  \begin{enumeratealpha}
    \item Conmutatividad: $\vec{u} \cdot \vec{v} = \vec{v} \cdot \vec{u}$
    
    \item Distributividad: $\vec{u} \cdot ( \vec{v} + \vec{w} ) = \vec{u} \cdot
    \vec{v} + \vec{u} \cdot \vec{w}$
    
    \item Homogeneidad: $\lambda ( \vec{u} \cdot \vec{v} ) = ( \lambda \vec{u} )
    \cdot \vec{v} = \vec{u} \cdot ( \lambda \vec{v} )$
    
    \item Positividad: $\vec{u} \cdot \vec{u} > 0, \forall \vec{u} \neq
    \vec{o}$
  \end{enumeratealpha}
\end{theorem}

\begin{definition}[Módulo de un vector]Se llama módulo (o norma) de un vector
$\vec{u}$ de $\mathbb{R}^3$, y se representa por $| \vec{u} |$, a la raíz
cuadrada positiva del producto escalar de dicho vector por sí mismo:

\begin{center}
  $| \vec{u} | = \sqrt{\vec{u} \cdot \vec{u}} = \sqrt{u_1^2 + u_2^2 + u_3^2}$
\end{center}
\end{definition}

\begin{remark}Definición geométrica: ya vimos que se llama módulo de un vector a su
longitud. Si siguieramos el esquema geométrico, la fórmula anterior no sería
una definición, sino una consecuencia del teorema de Pitágoras.\end{remark}

\begin{remark}El símbolo que utilizamos para representar el módulo de un vector es el
mismo que el que se utiliza para representar el valor absoluto. Se distinguen
por su contenido. Por esta razón, también se utiliza a veces doble barra para
representar el módulo de un vector: $\| \vec{u} \|$.\end{remark}

\begin{remark}Se dice que un vector es \emph{unitario} (o que está
\emph{normalizado}) si su módulo es 1. Dado un vector $\vec{x}$ no nulo, hay
dos vectores unitarios en su misma dirección:

  \[\vec{u}_1 = \dfrac{\vec{x}}{| \vec{x} |},\ \vec{u}_2 = - \dfrac{\vec{x}}{|\vec{x} |}\]

\end{remark}

\newpage

\begin{definition}
  [Distancia entre dos puntos]Se llama distancia entre dos puntos $A$
  y $B$ al módulo del vector fijo $\overrightarrow{A B}$, y se representa por
  $d ( A, B )$:
  \begin{center}
    $d ( A, B ) = | \overrightarrow{A B} | = \sqrt{( b_1 - a_1 )^2 + ( b_2 -
    a_2 )^2 + ( b_3 - a_3 )^2}$
  \end{center}
  
\end{definition}

\begin{remark}En general, se define una distancia en un conjunto $S$ como una función
$d : S \times S \rightarrow \mathbb{R}$ que verifica las propiedades
siguientes:

\begin{enumeratealpha}
  \item $d ( x, y ) > 0 \ \forall x \neq y ; d ( x, x ) = 0$
  
  \item $d ( x, y ) = d ( y, x ), \forall x, y \in S$
  
  \item $d ( x, z ) \leqslant d ( x, y ) + d ( y, z ), \forall x, y, z \in S$
\end{enumeratealpha}

Es fácil comprobar que la distancia entre dos puntos cumple las propiedades
anteriores.

Existen otras formas de medir distancias. La anterior, que es la más natural,
y la que se estudia en geometría elemental, se llama ``distancia euclídea''.\end{remark}


\begin{definition}[Ángulo entre dos vectores]Sean $\vec{u}$ y $\vec{v}$ dos
vectores no nulos de $\mathbb{R}^3$. El ángulo que forma el vector $\vec{u}$
con el vector $\vec{v}$, que se representa por $á \tmop{ng} ( \vec{u}, \vec{v}
)$ o $( \widehat{\vec{u}, \vec{v}} )$, queda caracterizado por su coseno que
vale:

  $$\cos ( \widehat{\vec{u}, \vec{v}} ) = \dfrac{\vec{u} \cdot \vec{v}}{|
  \vec{u} \| \vec{v} |}$$

\end{definition}

\begin{remark}Definición geométrica: ángulo entre dos vectores es el ángulo que forman
sus direcciones.

La fórmula anterior, dada como definición, se deduce inmediatamente de la
definición geométrica del producto escalar.\end{remark}



\begin{definition}[Vectores ortogonales]Se dice que dos vectores de
$\mathbb{R}^3$, $\vec{u}$ y $\vec{v}$ son ortogonales (o perpendiculares) si
su producto escalar es nulo:

\begin{center}
  $\vec{u}$ y $\vec{v}$ son ortogonales $\Leftrightarrow \vec{u} \cdot \vec{v}
  = 0$
\end{center}
\end{definition}

\begin{remark}Definición geométrica: dos vectores son ortogonales o perpendiculares
cuando lo son sus direcciones (dos rectas son perpendiculares si forman un
ángulo recto).\end{remark}

\begin{remark}Una base de $\mathbb{R}^3$ se llama \emph{base ortogonal} cuando los
vectores que la forman son ortogonales dos a dos. Si, además, los vectores de
la base son unitarios, se dice que es una \emph{base ortonormal}. La base
canónica es ortonormal.\end{remark}

\begin{remark}Teorema de Pitágoras (versión algebraica):
\begin{center}
  $\vec{u}$ y $\vec{v}$ son ortogonales $\Leftrightarrow$ $| \vec{u} |^2 + |
  \vec{v} |^2 = | \vec{u} + \vec{v} |^2$
\end{center}
Demostración (recordar que el módulo al cuadrado es igual al producto escalar
del vector por sí mismo):

$| \vec{u} + \vec{v} |^2 = ( \vec{u} + \vec{v} ) ( \vec{u} + \vec{v} ) =
\vec{u} \cdot \vec{u} + \vec{u} \cdot \vec{v} + \vec{v} \cdot \vec{u} +
\vec{v} \cdot \vec{v} = | \vec{u} |^2 + 2 \vec{u} \cdot \vec{v} + | \vec{v}
|^2$

$| \vec{u} + \vec{v} |^2 = | \vec{u} |^2 + | \vec{v} |^2 \Leftrightarrow |
\vec{u} |^2 + 2 \vec{u} \cdot \vec{v} + | \vec{v} |^2 = | \vec{u} |^2 + |
\vec{v} |^2 \Leftrightarrow 2 \cdot \vec{u} \cdot \vec{v} = 0 \Leftrightarrow
\vec{u}$ y $\vec{v}$ son ortogonales\end{remark}

\begin{remark}Si dos vectores $\vec{u}$ y $\vec{v}$ son ortogonales, cualquier vector
de la dirección de $\vec{u}$ es ortogonal a cualquier vector de la dirección
de $\vec{v}$. Se dice entonces que la dirección de $\vec{u}$ y la dirección de
$\vec{v}$ son ortogonales.\end{remark}

\newpage

\begin{definition}[Proyección ortogonal]Sean $\vec{u}$ y $\vec{v}$ dos vectores de
$\mathbb{R}^3$, con $\vec{v} \neq \vec{o}$. Se dice que $\vec{u}_v$ es la
proyección ortogonal de $\vec{u}$ sobre $\vec{v}$ si $\vec{u}_v$ tiene la
misma dirección que $\vec{v}$ y $\vec{u} - \vec{u}_v$ es ortogonal a
$\vec{v}$.\end{definition}

\begin{theorem}
  La proyección ortogonal de $\vec{u}$ sobre $\vec{v} \neq \vec{o}$ viene dada
  por:
  
    \[\vec{u}_v = \text{$\dfrac{\vec{u} \cdot \vec{v}}{| \vec{v} |^2} 
    \vec{v}$}\]
  
\end{theorem}

\begin{remark}El módulo de la proyección ortogonal es: $| \vec{u}_v | = \dfrac{\vec{u}
\cdot \vec{v}}{| \vec{v} |}$.\end{remark}

\begin{remark}La proyección ortogonal de $\vec{u}$ sobre $\vec{v}$ es, de todos los
vectores con la misma dirección que $\vec{v}$, el más ``próximo'' a $\vec{u}$,
es decir, aquel $\vec{x} = \lambda \vec{v}$ que hace que $| \vec{u} - \vec{x}
|$ sea mínimo.\end{remark}

\vspace{.5cm}

\begin{center}
  \includegraphics[width=9cm]{proy_orto.jpg}
\end{center}

\newpage

\begin{example}
  Dado $\vec{v} = ( 18, 6, 12 )$, descomponer el vector $\vec{u} = ( 1, 5, 3
  )$ en la suma de un vector de la misma dirección que $\vec{v}$ y otro vector
  ortogonal a $\vec{v}$.
  
  Sea $\vec{u_v}$ el vector de la misma dirección que $\vec{v}$, y $\vec{w}$ el
  vector ortogonal a $\vec{v}$.
  
  \[\vec{u} = \vec{u_v} + \vec{w} \Leftrightarrow \vec{w} = \vec{u} - \vec{u_v}\]
  
  Como $\vec{u_v}$ tiene la misma dirección que $\vec{v}$, y $\vec{w} = \vec{u}
  - \vec{u_v}$ es ortogonal a $\vec{v}$, $\vec{u_v}$ es la proyección ortogonal de
  $\vec{u}$ sobre $\vec{v}$, que según el teorema anterior viene dada por:
  
  \[\vec{u_v} = \dfrac{\vec{u} \cdot \vec{v}}{| \vec{v} |} \cdot \dfrac{\vec{v}}{|
  \vec{v} |} = \dfrac{1 \cdot 18 + 5 \cdot 6 + 3 \cdot 12}{18^2 + 6^2 + 12^2}
  \cdot ( 18, 6, 12 ) = ( 3, 1, 2 )\]
  
  Efectivamente, $\vec{u_v}$ tiene la misma dirección que $\vec{v}$, ya que
  $\vec{u_v} = \frac{1}{6} \vec{u}$.
  
  \[\vec{w} = \vec{u} - \vec{u_v} = ( 1, 5, 3 ) - ( 3, 1, 2 ) = ( - 2, 4, 1 )\]
  
  Efectivamente, $\vec{z}$ es ortogonal a $\vec{u}$, ya que $\vec{z} \cdot
  \vec{u} = 18 \cdot ( - 2 ) + 6 \cdot 4 + 12 \cdot 1 = 0$.
\end{example}

\newpage\section{Producto vectorial}

\begin{definition}[Producto vectorial]Dados dos vectores de $\mathbb{R}^3$,
$\vec{u} = ( u_1, u_2, u_3 )$ y $\vec{v} = ( v_1, v_2, v_3 )$, se llama
producto vectorial de $\vec{u}$ por $\vec{v}$, y se representa por $\vec{u}
\wedge \vec{v}$ al vector dado por:
\begin{center}
  $\vec{u} \wedge \vec{v} = \left( \left|\begin{array}{cc}
    u_2 & u_3\\
    v_2 & v_3
  \end{array}\right|, - \left|\begin{array}{cc}
    u_1 & u_3\\
    v_1 & v_3
  \end{array}\right|, \left|\begin{array}{cc}
    u_1 & u_2\\
    v_1 & v_2
  \end{array}\right| \right)$
\end{center}
\end{definition}

\begin{remark}La fórmula anterior se puede resumir en un sólo ``determinante'' (no es un
verdadero determinante, ya que contiene vectores, y los determinantes sólo
contienen escalares) más fácil de recordar:

\begin{center}
  $\vec{u} \wedge \vec{v} = \left|\begin{array}{ccc}
    \vec{i} & \vec{j} & \vec{k}\\
    u_1 & u_2 & u_3\\
    v_1 & v_2 & v_3
  \end{array}\right|$
\end{center}
\end{remark}

\begin{theorem}
  [Propiedades ``geométricas'' del producto vectorial]Si $\vec{u}$ y
  $\vec{v}$ son linealmente dependientes, entonces $\vec{u} \wedge \vec{v} =
  \vec{o}$. Si $\vec{u}$ y $\vec{v}$ son independientes, entonces:
  
  \begin{enumeratealpha}
    \item La dirección de $\overrightarrow{\text{} u} \wedge \vec{v}$ es
    ortogonal a $\vec{u}$ y a $\vec{v}$ (es decir, $\vec{u} \cdot ( \vec{u}
    \wedge \vec{v} ) = \vec{v} \cdot ( \vec{u} \wedge \vec{v} ) = 0$).
    
    \item La orientación de $\{ \vec{u}, \vec{v}, \vec{u} \wedge \vec{v} \}$
    es la misma que la de $\overrightarrow{\{ i}, \vec{j}, \vec{k} \}$ (``regla
    del sacacorchos'' o ``de la mano derecha'')
    
    \item El módulo de $\vec{u} \wedge \vec{v}$ viene dado por: $|
    \text{$\vec{u} \wedge \vec{v}$} | = | \vec{u} \| \vec{v} | \tmop{sen} (
    \vec{u}, \vec{v} )$.
  \end{enumeratealpha}
\end{theorem}

\begin{center}
  \includegraphics[width=12cm]{producto_vectorial.jpg}
\end{center}


\begin{theorem}
  [Propiedades ``algebraicas'' del producto vectorial]Para todos los
  vectores $\vec{u}$, $\vec{v}$ y $\vec{w}$ de $\mathbb{R}^3$, y para todos
  los escalares $\lambda$ de $\mathbb{R}$, se cumple:
  
  \begin{enumeratealpha}
    \item $( \lambda \vec{u} ) \wedge \vec{v} = \vec{u} \wedge ( \lambda
    \vec{v} ) = \lambda ( \vec{u} \wedge \vec{v} )$
    
    \item $\vec{u} \wedge \vec{v} = - \vec{v} \wedge \vec{u}$
    
    \item $\vec{u} \wedge \vec{v} = \vec{o}$  si y solo si $\vec{u}$ y
    $\vec{v}$ son linealmente dependientes
    
    \item $\vec{u} \wedge ( \vec{v} + \vec{w} ) = \vec{u} \wedge \vec{v} +
    \vec{u} \wedge \vec{w}$
  \end{enumeratealpha}
\end{theorem}

\begin{remark}El producto vectorial no es sino una forma conveniente de determinar un
vector ortogonal a dos vectores dados, y está relacionado, como veremos a continuación, con el área de un paralelogramo.\end{remark}


\newpage

\begin{example}
  Hallar un vector unitario que sea ortogonal a $\vec{u} = ( 1, 1, - 2 )$ y a
  $\vec{v} = ( - 1, - 1, 1 )$.
  
  Existen infinitos vectores que son simultáneamente ortogonales a $\vec{u}$ y
  $\vec{v}$. El producto vectorial de $\vec{u}$ y $\vec{v}$ es uno de ellos.
  Para calcular el vector pedido, hallaremos dicho producto vectorial, y luego
  hallaremos un vector unitario de su misma dirección.
  
  $$\vec{u} \wedge \vec{v} = \left|\begin{array}{ccc}
    \vec{i} & \vec{j} & \vec{k}\\
    1 & 1 & - 2\\
    - 1 & - 1 & 1
  \end{array}\right| = - \vec{i} - \vec{j} = ( - 1, - 1, 0 )$$
  
  Un vector unitario de la misma dirección que el anterior es:
  $$\vec{x} =
  \dfrac{\vec{u} \wedge \vec{v}}{| \vec{u} \wedge \vec{v} |} =
  \dfrac{1}{\sqrt{2}} ( - 1, - 1, 0 ).$$
\end{example}

\begin{theorem}
  [Área de un paralelogramo]El área de un paralelogramo de vértices $A
  B C D$, donde los vértices $B$ y $C$ son contiguos al vértice $A$, viene
  dada por:
  \begin{center}
    $A = | \overrightarrow{A B} \wedge \overrightarrow{A C} |$
  \end{center}
  
\end{theorem}

\begin{center}
  \includegraphics[width=7cm]{area_of_parallelogram.pdf}
\end{center}

\begin{theorem}
  [Área de un triángulo]El área de un triángulo de vértices $A B C$
  viene dada por:
  \begin{center}
    $A = \dfrac{1}{2} | \overrightarrow{A B} \wedge \overrightarrow{A C} |$
  \end{center}
  
\end{theorem}

\begin{center}
  \includegraphics[width=7cm]{area_of_triangle.pdf}
\end{center}

\begin{remark}La definición de ``área'' escapa a los objetivos de este curso. Sin esa
definición no podemos propiamente demostrar los teoremas anteriores, por eso
en las observaciones siguientes nos limitamos a comprobar que las fórmulas
dadas en dichos teoremas responden a nuestra noción intuitiva de área, es
decir, que son coherentes con las fórmulas estudiadas en geometría
elemental.\end{remark}

\begin{remark}``Demostración'' de la fórmula del área de un paralelogramo:

Si $\alpha$ es el ángulo que forman $\overrightarrow{A B}$ y
$\overrightarrow{A C}$, tomando el lado $A B$ como base, la altura del
paralelogramo vendrá dada por $| \overrightarrow{A C} | \cdot \tmop{sen}
\alpha$

$| \overrightarrow{A B} \wedge \overrightarrow{A C} | = | \overrightarrow{A B}
\| \overrightarrow{A C} | \tmop{sen} \alpha = | \overrightarrow{A B} | \cdot
\tmop{altura} = \tmop{base} \cdot \tmop{altura}$\end{remark}



\newpage\section{Producto mixto}

\begin{definition}[Producto mixto]Dados tres vectores de $\mathbb{R}^3$,
$\vec{u}$, $\vec{v}$ y $\vec{w}$, se llama producto mixto de $\vec{u}$,
$\vec{v}$ y $\vec{w}$, y se representa por $[ \text{$\vec{u}$, $\vec{v}$ y
$\vec{w}$} ]$ al escalar dado por:
\begin{center}
  $\text{$[ \text{$\vec{u}$, $\vec{v}$ y $\vec{w}$} ] = \vec{u} \cdot (
  \vec{v} \wedge \vec{w} )$} = \left|\begin{array}{ccc}
    u_1 & u_2 & u_3\\
    v_1 & v_2 & v_3\\
    w_1 & w_2 & w_3
  \end{array}\right|$
\end{center}
\end{definition}

\begin{theorem}
  [Propiedades del producto mixto]Para cualesquiera vectores de
  $\mathbb{R}^3$, su producto mixto verifica las propiedades estudiadas para
  los determinantes. En particular:
  
  \begin{enumeratealpha}
    \item Es lineal respecto a cada vector: $[ \lambda \vec{u} + \mu \vec{u}',
    \vec{v}, \vec{w} ] = \lambda [ \vec{u}, \vec{v}, \vec{w} ] + \mu [
    \vec{u}', \vec{v}, \vec{w} ]$
    
    \item Es antisimétrico: $[ \vec{u}, \vec{v}, \vec{w} ] = - [ \vec{u},
    \vec{w}, \vec{v} ]$
    
    \item $[ \vec{u}, \vec{v}, \vec{w} ] = 0$ $\Leftrightarrow \{ \vec{u},
    \vec{v}, \vec{w} \}$ es un conjunto linealmente dependiente
  \end{enumeratealpha}
\end{theorem}

\begin{theorem}
  [Volumen de un prisma rectangular]El volumen de un prisma
  rectangular determinado por las aristas $A B$, $A C$ y $A D$, viene dado
  por:
  \begin{center}
    $V = \left|[ \overrightarrow{A B}, \overrightarrow{A C}, \overrightarrow{A D} ]\right|
    = \left|\overrightarrow{A B} \cdot ( \overrightarrow{A C} \wedge
    \overrightarrow{A D} )\right|$
  \end{center}
  
\end{theorem}

\begin{center}
  \includegraphics[width=7cm]{parallelepiped_volume.pdf}
\end{center}


\begin{theorem}
  [Volumen de un tetraedro]El volumen de un tetraedro de vértices $A B
  C D$, viene dado por:
  \begin{center}
    $V = \dfrac{1}{6} \left|[ \overrightarrow{A B}, \overrightarrow{A C},
    \overrightarrow{A D} ]\right| = \dfrac{1}{6} \left|\overrightarrow{A B} \cdot (
    \overrightarrow{A C} \wedge \overrightarrow{A D} )\right|$
  \end{center}
  
\end{theorem}


\begin{center}
  \includegraphics[width=5cm]{tetrahedron_volume.pdf}
\end{center}

\begin{remark}En cuanto a la definición de ``volumen'', tendríamos que decir lo mismo
que dijimos antes respecto al área. Para ``demostrar'' la fórmula basta con ver
que $| \overrightarrow{A C} \wedge \overrightarrow{A D} |$ es el área de la
base (área de un paralelogramo), y que $| \overrightarrow{A B} | \cos \alpha$
es la altura del prisma, siendo $\alpha$ el ángulo que forma
$\overrightarrow{A B}$ con el producto vectorial $\overrightarrow{A C} \wedge
\overrightarrow{A D}$ (es decir, el ángulo que forma la arista $A B$ con la
dirección perpendicular a la base).\end{remark}

\newpage\section{Lugar geométrico}

\begin{definition}
  [Lugar geométrico]Se llama lugar geométrico a un conjunto de puntos
  del espacio geométrico caracterizados por una determinada propiedad.
\end{definition}

\begin{remark}Que los puntos de un lugar geométrico estén caracterizados por una
determinada propiedad significa que todos los puntos del lugar geométrico
cumplen esa propiedad, y solamente ellos la cumplen. Sea $L$ un lugar
geométrico definido por una cierta propiedad $p$:

\begin{enumeratealpha}
  \item Si $P \in L$, entonces $P$ cumple $p$.
  
  \item Si $P \notin L$, entonces $P$ no cumple $p$.
\end{enumeratealpha}
Esto es equivalente a decir que:
\begin{enumeratealpha}
  \item Si $P$ cumple $p$, entonces $P \in L$.
  
  \item Si $P$ no cumple $p$, entonces $P \notin L$.
\end{enumeratealpha}
En definitiva: $P \in L \Leftrightarrow P$ cumple $p$.\end{remark}

\begin{remark}Cuando la condición que define un lugar geométrico puede expresarse
mediante una ecuación algebraica sobre las coordenadas de sus puntos, dicha
ecuación recibe el nombre de ``ecuación cartesiana del lugar geométrico''.\end{remark}

\begin{example}
  El lugar geométrico $S = \{ P \in E_3 / d ( P, C ) = \rho \}$ es el conjunto
  de todos los puntos cuya distancia a un cierto punto $C$ es igual a un
  determinado valor $\rho$, es decir, es la superficie esférica de centro $C$
  y radio $\rho$. La ecuación que define dicho lugar geométrico es: $d ( P, C
  ) = \rho$. Esta ecuación puede expresarse también así:
  
  $$d ( P, C ) = \rho \Leftrightarrow d^2 ( P, C ) = \rho^2 \Leftrightarrow ( x
  - c_1 )^2 + ( y - c_2 )^2 + ( z - c_3 )^2 = \rho^2$$
  
  siendo $x$, $y$ y $z$ las coordenadas de un punto cualquiera de la esfera, y
  $c_1$, $c_2$ y $c_3$ las coordenadas de $C$. Esta última expresión es la
  ecuación cartesiana de la esfera.
\end{example}

\begin{example}
  Hallar la ecuación del lugar geométrico de los puntos que se encuentran a la
  misma distancia de $A ( 1, 1, 1 )$ y $B ( 3, 3, 3 )$.
  
  $$S = \{ P \in \mathbb{R}^3 / d ( P, A ) = d ( P, B ) \}$$
  
  La ecuación pedida es $d ( P, A ) = d ( P, B )$. Sea $P ( x, y, z )$.
  
  \begin{eqnarray*}d ( P, A ) = d ( P, B ) & \Leftrightarrow & d^2 ( P, A ) = d^2 ( P, B ) \\
    & \Leftrightarrow & ( x - 1 )^2 + ( y - 1 )^2 + ( z - 1 )^2 = ( x - 3 )^2 + ( y - 3 )^2 + ( z - 3 )^2 \\
    & \Leftrightarrow & x^2 - 2 x + 1 + y^2 - 2 y + 1 + z^2 - 2 z + 1 = x^2 - 6 x + 9 + y^2 - 6 y + 9 + z^2 - 6 z + 9 \\
    & \Leftrightarrow & 4 x + 4 y + 4 z = 9 + 9 + 9 - 1 - 1 - 1 \\
    & \Leftrightarrow & 4 x + 4 y + 4 z = 24 \Leftrightarrow x + y + z = 6
  \end{eqnarray*}
  
  La ecuación de dicho lugar geométrico es

  \[x + y + z = 6.\]
  
  El punto medio del segmento $A B$, que es $C ( 2, 2, 2 )$ pertenece
  efectivamente a ese lugar geométrico, ya que la suma de sus coordenadas es
  6.
\end{example}

\chapter{Rectas y planos}

\newpage\section{Rectas}

\begin{definition}[Recta]Dados un punto $P$ del espacio $E_3$ y un vector no nulo
$\vec{u}$ de $\mathbb{R}^3$, se llama recta que pasa por $P$ y tiene la
dirección de $\vec{u}$ al lugar geométrico de $E_3$ definido por:
\begin{center}
  $r \equiv \{ X \in E_3 / \exists \lambda \in \mathbb{R}, \overrightarrow{P
  X} = \lambda \vec{u} \}$
\end{center}
\end{definition}

\begin{remark}Al vector $\vec{u}$ utilizado para definir la recta se le llama
{\emph{vector director}}, porque define la dirección de la recta. El vector
director de una recta no es único, es decir, si $\vec{u}$ y $\vec{v}$ son dos
vectores de la misma dirección, la recta que pasa por $P$ y tiene la dirección
de $\vec{u}$ es la misma que la recta que pasa por $P$ y tiene la dirección de
$\vec{v}$. Si $\vec{u}$ es un vector director de una recta $r$, cualquier
vector proporcional a $\vec{u}$ también lo es.\end{remark}

\begin{remark}Se suele decir que ``una recta $r$ pasa por un punto P''. Esto significa
que P es un punto de esa recta (pertenece a ella): $P \in r$.\end{remark}

\begin{remark}El conjunto de todos los vectores que unen dos puntos de una recta (es
decir, el conjunto de todos los $\overrightarrow{A B}$ tales que $A \in r$ y
$B \in r$) es la envolvente lineal del vector director de la misma, y se le
llama {\emph{dirección de la recta}}.\end{remark}

\begin{remark}Un punto y un vector determinan una recta (es decir, que hay una única
recta que pase por ese punto y tenga la dirección de ese vector). Sin embargo,
dos puntos distintos y dos vectores distintos pueden determinar la misma
recta. En concreto, sea $r$ la recta determinada por el punto $P$ y el vector
$\vec{u}$, y sea $s$ la recta determinada por el punto $Q$ y el vector
$\vec{v}$, es fácil comprobar que $r = s$ si y solo si $\vec{u}$, $\vec{v}$ y
$\overrightarrow{P Q}$ son proporcionales.\end{remark}

\begin{theorem}
  [Ecuaciones de la recta]La recta que pasa por el punto $P ( x_0,
  y_0, z_0 )$ y tiene la dirección de $\vec{u} = ( u_1, u_2, u_3 )$ admite las
  siguientes ecuaciones (en las que $P ( x, y, z )$ es un punto cualquiera de
  la recta):
  \begin{enumeratealpha}
    \item Ecuación vectorial: $\overrightarrow{O X} = \overrightarrow{O P} +
    \lambda \vec{u}, \lambda \in \mathbb{R}$.
    
    \item Ecuaciones paramétricas: $\left\{\begin{array}{l}
      x = x_0 + \lambda u_1\\
      y = y_0 + \lambda u_2\\
      z = z_0 + \lambda u_3
    \end{array}\right., \lambda \in \mathbb{R}$.
    
    \item Ecuación continua: $\dfrac{x - x_0}{u_1} = \dfrac{y - y_0}{u_2} =
    \dfrac{z - z_0}{u_3}$.
  \end{enumeratealpha}
\end{theorem}

{}



\begin{remark}La ecuación vectorial se deduce inmediatamente de la definición de
recta:

$$\overrightarrow{P X} = \lambda \vec{u} \Leftrightarrow \overrightarrow{O X} - \overrightarrow{O P} = \lambda \vec{u} \Leftrightarrow \overrightarrow{O X} = \overrightarrow{O P} + \lambda \vec{u}$$

Esta ecuación se escribe a veces con notación simplificada así:

$$X = P + \lambda \vec{u},$$

donde $X$ se sustituye por las coordenadas de un punto
cualquiera de la recta, y $P$ por las coordenadas del punto $P$.
\end{remark}

\begin{remark}Las ecuaciones paramétricas se obtienen igualando coordenada a
coordenada los vectores de la ecuación vectorial.\end{remark}

\begin{remark}La ecuación continua (que en realidad son dos ecuaciones) se obtiene
despejando el parámetro $\lambda$ en cada una de las ecuaciones paramétricas,
e igualando.\end{remark}

\begin{remark}Si fuese $u_1 = 0$ o $u_2 = 0$ o $u_3 = 0$, la ecuación continua no
tendría sentido. A veces se abusa de la notación dejando un
denominador nulo, queriendo expresar que el correspondiente numerador es
también nulo.\end{remark}

\begin{example}
  Hallar las ecuaciones de la recta que pasa por $A ( 1, - 1, 0 )$ y tiene la
  dirección de $\vec{u} = ( - 2, - 1, 3 )$.
  
  La ecuación vectorial es:

  $$\overrightarrow{O X} = ( 1, - 1, 0 ) + \lambda ( - 2, - 1, 3 ).$$
  
  Las ecuaciones paramétricas:
  
  $$r : \left\{\begin{array}{l}
    x = 1 - 2 \lambda\\
    y = - 1 - \lambda\\
    z = 3 \lambda
  \end{array}\right.$$
  
  La ecuación continua es:

  $$r : \dfrac{x - 1}{- 2} = \dfrac{y + 1}{- 1} = \dfrac{z}{3}.$$

\end{example}

\begin{example}
  Hallar dos puntos y un vector director de la recta $r :
  \left\{\begin{array}{l}
    x = - \lambda\\
    y = - 2\\
    z = 3 - 2 \lambda
  \end{array}\right.$.
  
  Las ecuaciones dadas son las paramétricas.

  Directamente, podemos dar como punto el $P ( 0, - 2, 3 )$ y como vector director el $\vec{v} = ( - 1, 0, - 2 )$.

  El segundo punto lo podemos obtener de varias maneras. Una sería dando
  un valor cualquiera a $\lambda$ (distinto de cero, porque con $\lambda = 0$
  obtendríamos el punto $P$), así para $\lambda = 2$ tenemos: $x = - 2$, $y =
  - 2$, $z = - 1$, es decir, el punto $Q ( - 2, - 2, - 1 )$. Otra forma sería
  sumar al vector $\overrightarrow{O P}$ el vector $\vec{v}$ o cualquiera
  proporcional a él.
\end{example}

\begin{theorem}
  [Puntos alineados]Tres puntos $A$, $B$ y $C$ están alineados (es
  decir, existe una recta que los contiene a los tres), si y solo si
  $\overrightarrow{A B}$ y $\overrightarrow{A C}$ son proporcionales.
\end{theorem}

\begin{remark}Esto es lo mismo que decir que el área del triángulo que determinan sea
cero, ya que el área del triángulo $A B C$ viene dada por $S = \frac{1}{2} |
\overrightarrow{A B} \wedge \overrightarrow{A C} |$, y $| \overrightarrow{A B}
\wedge \overrightarrow{A C} | = 0$ si y solo si $\overrightarrow{A B}$ y
$\overrightarrow{A C}$ son proporcionales\end{remark}

\begin{example}
  Dados los puntos $A ( 1, 1, - 1 ), B ( 2, - 3, 4 ), C ( \alpha, 0, \beta + 1
  )$ determinar $\alpha$ y $\beta$ para que estén alineados.
  
  $A, B, C$ alineados $\Leftrightarrow \exists \lambda / \overrightarrow{A B}
  = \lambda \overrightarrow{A C} \Leftrightarrow \exists \lambda / ( 2 - 1, -
  3 - 1, 4 + 1 ) = \lambda ( \alpha - 1, 0 - 1, \beta + 1 + 1 )
  \Leftrightarrow \exists \lambda / ( 1, - 4, 5 ) = \lambda ( \alpha - 1, - 1,
  \beta + 2 ) \Leftrightarrow \dfrac{\alpha - 1}{1} = \dfrac{- 1}{- 4} =
  \dfrac{\beta + 2}{5} \Leftrightarrow \left\{\begin{array}{l}
    \alpha - 1 = \dfrac{1}{4}\\
    \beta + 2 = \dfrac{5}{4}
  \end{array}\right. \Leftrightarrow \left\{\begin{array}{l}
    \alpha = \dfrac{5}{4}\\
    \beta = - \dfrac{3}{4}
  \end{array}\right.$
\end{example}

\begin{theorem}
  [Recta determinada por dos puntos]Dados dos puntos de $E_3$, $A \neq
  B$, existe una única recta que pase por ambos, que es la recta que pasa por
  $A$ y tiene la dirección de $\overrightarrow{A B}$.
\end{theorem}

\begin{example}
  Hallar la ecuación continua de la recta determinada por los puntos $A ( 1,
  1, 1 )$ y $B ( 2, 0, 2 )$
  
  Su vector director es $\overrightarrow{A B} = \overrightarrow{O B} -
  \overrightarrow{O A} = ( 2, 0, 2 ) - ( 1, 1, 1 ) = ( 1, - 1, 1 )$.
  
  Por tanto, $r : \dfrac{x - 1}{1} = \dfrac{y - 1}{- 1} = \dfrac{z - 1}{1}
  \Leftrightarrow x - 1 = - y + 1 = z - 1$.
\end{example}

\newpage\section{Planos}

\begin{definition}
  [Plano]Dados un punto $P$ de $E_3$, y dos vectores linealmente
  independientes $\vec{v}$ y $\vec{w}$ de $\mathbb{R}^3$, se llama plano que
  pasa por $P$ y tiene la dirección definida por $\vec{v}$ y $\vec{w}$, al
  lugar geométrico definido por:
  \begin{center}
    $\pi = \{ X \in E_3 / \exists \alpha, \beta \in \mathbb{R},
    \overrightarrow{P X} = \alpha \vec{v} + \beta \vec{w} \}$
  \end{center}
  
\end{definition}

\begin{remark}El conjunto de todos los vectores $\overrightarrow{P Q}$ tales que $P, Q
\in \pi$ es la envolvente lineal de $\{ \vec{v}, \vec{w} \}$.\end{remark}

\begin{remark}Se llama {\emph{dirección del plano $\pi$}} al subespacio vectorial
$\mathcal{L}( \vec{v}, \vec{w} )$. A los vectores utilizados para definir su
dirección, $\vec{v}$ y $\vec{w}$, se les llama {\emph{vectores directores}}
del plano.\end{remark}

\begin{remark}En lugar de decir que un punto $P$ pertenece a un plano $\pi$, se suele
decir que el plano $\pi$ pasa por el punto $P$.\end{remark}

\begin{remark}Es fácil comprobar que el plano $\pi_1$ determinado por $P_1$,
$\vec{v}_1$ y $\vec{w}_1$, y el plano $\pi_2$ determinado por $P_2$,
$\vec{v}_2$, $\overrightarrow{w_2}$, son el mismo plano si y solo si
$\mathcal{L}( \overrightarrow{v_1}, \overrightarrow{w_1} ) =\mathcal{L}(
\overrightarrow{v_2}, \overrightarrow{w_2} )$ y $\overrightarrow{P_1 P_2} \in
\mathcal{L}( \overrightarrow{v_1}, \overrightarrow{w_1} )$.\end{remark}

\begin{theorem}
  [Ecuaciones del plano]El plano $\pi$ que pasa por $P ( x_0, y_0, z_0
  )$ y tiene la dirección definida por $\vec{v} = ( v_1, v_2, v_3 )$ y
  $\vec{w} = ( w_1, w_2, w_3 )$ admite las siguientes ecuaciones:
  \begin{enumeratealpha}
    \item Ecuación vectorial: $\pi : \overrightarrow{P X} = \alpha \vec{v} +
    \beta \vec{w}$
    
    \item Ecuaciones paramétricas: $\pi \equiv \left\{\begin{array}{l}
      x = x_0 + \alpha v_1 + \beta w_1\\
      y = y_0 + \alpha v_2 + \beta w_2\\
      z = z_0 + \alpha v_3 + \beta w_3
    \end{array}\right.$
    
    \item Ecuación general (o implícita): $\pi : A x + B y + C z + D = 0$,
    
    siendo, $A = \left|\begin{array}{cc}
      v_2 & v_3\\
      w_2 & w_3
    \end{array}\right|$, $B = - \left|\begin{array}{cc}
      v_1 & v_3\\
      w_1 & w_3
    \end{array}\right|$, $C = \left|\begin{array}{cc}
      v_1 & v_2\\
      w_1 & w_2
    \end{array}\right|$, $D = - ( A x_0 + B y_0 + C z_0 )$
  \end{enumeratealpha}
\end{theorem}

\begin{remark}La ecuación vectorial es la utilizada en la definición. Las ecuaciones
paramétricas se obtienen igualando coordenada a coordenada en la ecuación
vectorial.\end{remark}

\begin{remark}La ecuación general se obtiene del siguiente modo (es importante conocer
este desarrollo):

Teniendo en cuenta que, según exige la definición, $\vec{v}$ y $\vec{w}$ son
linealmente independientes,

$\exists \alpha, \beta \in \mathbb{R}/ \overrightarrow{P X} = \alpha \vec{v}
+ b \vec{w} \Leftrightarrow \tmop{rango} ( \overrightarrow{P X}, \vec{v},
\vec{w} ) = 2 \Leftrightarrow \det ( \overrightarrow{P X}, \vec{v}, \vec{w} )
= 0 \Leftrightarrow \left|\begin{array}{ccc}
  x - x_0 & y - y_0 & z - z_0\\
  v_1 & v_2 & v_3\\
  w_1 & w_2 & w_3
\end{array}\right| = 0 \Leftrightarrow$

$\Leftrightarrow ( x - x_0 ) \left|\begin{array}{cc}
  v_2 & v_3\\
  w_2 & w_3
\end{array}\right| - ( y - y_0 ) \left|\begin{array}{cc}
  v_1 & v_3\\
  w_1 & w_3
\end{array}\right| + ( z - z_0 ) \left|\begin{array}{cc}
  v_1 & v_2\\
  w_1 & w_2
\end{array}\right| = 0 \Leftrightarrow A ( x - x_0 ) + B ( y - y_0 ) + C ( z -
z_0 ) = 0 \Leftrightarrow$

$\Leftrightarrow A x + B y + C z - A x_0 - B y_0 - C z_0 = 0 \Leftrightarrow A
x + B y + C z + D = 0$
\end{remark}

\begin{example}
  Hallar la ecuación general del plano que pasa por el punto $P ( 1, 0, 1 )$,
  y tiene por vectores directores a $\vec{v} = ( 1, 1, 1 )$ y $\vec{w} = ( 0,
  - 1, 1 )$. Hallar otro punto del plano.
  
  $\det ( \overrightarrow{P X}, \vec{v}, \vec{w} ) = 0 \Leftrightarrow
  \left|\begin{array}{ccc}
    x - 1 & y & z - 1\\
    1 & 1 & 1\\
    0 & - 1 & 1
  \end{array}\right| = 0 \Leftrightarrow 2 ( x - 1 ) - y - ( z - 1 ) = 0
  \Leftrightarrow 2 x - y - z - 1 = 0$
  
  La ecuación pedida es: $\pi : 2 x - y - z - 1 = 0$.
  
  Para calcular un punto del plano le damos un valor a $x$ e $y$ y calculamos
  el valor correspondiente de $z$ utilizando la ecuación del plano (¿podríamos
  seguir siempre este método?):
  
  $x = - 1 ; y = 1 \Rightarrow 2 ( - 1 ) - 1 - z - 1 = 0 \Rightarrow z = 4
  \Rightarrow Q ( - 1, 1, 4 ) \in \pi$
\end{example}

\begin{theorem}
  [Ecuación normal del plano]Dado un plano $\pi$, un punto suyo $P$ y
  un vector $\vec{n}$ no nulo ortogonal a su dirección, se tiene:
  \begin{center}
    $\pi = \{ X \in E_3 / \vec{n} \cdot \overrightarrow{P X} = 0 \}$
  \end{center}
  
\end{theorem}

\begin{remark}Es decir, que el plano $\pi$ admite como ecuación $\vec{n} \cdot
\overrightarrow{P X} = 0$ (ecuación normal del plano).\end{remark}

\begin{remark}Al vector $\vec{n}$ se le llama {\emph{vector normal del plano}}.\end{remark}

\begin{remark}Se dice que un vector es ortogonal a un conjunto de vectores, si es
ortogonal a todos ellos. En nuestro caso, $\vec{n}$ ha de ser ortogonal a
$\mathcal{L}( \vec{v}, \vec{w} )$, que es la dirección del plano. Es fácil
comprobar que un vector es ortogonal a $\mathcal{L}( \vec{v}, \vec{w} )$ si y
solo si es ortogonal a $\vec{v}$ y $\vec{w}$. Por tanto, si conocemos dos
vectores directores del plano $\vec{v}$ y $\vec{w}$, podemos tomar $\vec{n} =
\vec{v} \wedge \vec{w}$ como vector normal del plano (o también, cualquier
vector proporcional a este).\end{remark}

\begin{remark}Demostración: es inmediato comprobar que $X \in \pi \Rightarrow \vec{n}
\cdot \overrightarrow{P X} = 0$, ya que $\vec{n}$ es ortogonal a todos los
vectores de la dirección del plano y, si $X$ es un punto del plano, el vector
$\overrightarrow{P X}$ es un vector de la dirección del plano. Para demostrar
que $\vec{n} \cdot \overrightarrow{P X} = 0 \Rightarrow X \in \pi$, supongamos
que existe un punto $Q \notin \pi$ tal que $\vec{n} \cdot \overrightarrow{P Q} =
0$. Puesto que $\vec{n}$, $\vec{v}$ y $\vec{w}$ forman una base de
$\mathbb{R}^3$, deben existir $\alpha$, $\beta$ y $\gamma$ tales que
$\overrightarrow{P Q} = \alpha \vec{v} + \beta \vec{w} + \gamma \vec{n}$.
Entonces, $\vec{n} \cdot \overrightarrow{P Q} = 0 \Leftrightarrow \alpha
\vec{n} \cdot \vec{v} + \beta \vec{n} \cdot \vec{w} + \gamma \vec{n} \cdot
\vec{n} = 0$, pero como $\vec{n}$ es ortogonal a $\vec{v}$ y a $\vec{w}$, se
tiene $\vec{n} \cdot \overrightarrow{P Q} = 0 \Leftrightarrow \gamma \vec{n}
\cdot \vec{n} = 0 \Leftrightarrow \vec{n} = \vec{o}$ o $\gamma = 0$. No puede
ser $\vec{n} = \vec{o}$, luego ha de ser $\gamma = 0$, y esto significa que
existen $a$ y $\beta$ tales que $\overrightarrow{P Q} = \alpha \vec{v} + \beta
\vec{w}$, es decir, que $Q$ es un punto de $\pi$.\end{remark}

\begin{remark}Un plano queda determinado por un punto y un vector ortogonal a dicho
plano. La dirección del plano es el conjunto de todos los vectores ortogonales
al vector normal del plano.\end{remark}

\begin{remark}Los coeficientes de la ecuación general del plano son las coordenadas de
un vector normal del plano. En efecto, según se vio allí, $A$, $B$ y $C$ son
las coordenadas de $\vec{v} \wedge \vec{w}$, que es un vector ortogonal a la
dirección del plano (vector normal).\end{remark}

\begin{example}
  Hallar un vector normal del plano $\pi \equiv \left\{\begin{array}{l}
    x = 1 + \alpha + \beta\\
    y = - 2 \alpha\\
    z = 1 + 2 \alpha - \beta
  \end{array}\right.$.
  
  Nos han dado las ecuaciones paramétricas del plano, de las que fácilmente
  obtenemos dos vectores directores (tomando los coeficientes de los
  parámetros):
  
  $\vec{v} = ( 1, - 2, 2 ) ; \vec{w} = ( 1, 0, - 1 )$
  
  Un vector normal del plano será $\vec{n} = \vec{v} \wedge \vec{w} =
  \left|\begin{array}{ccc}
    \vec{i} & \vec{j} & \vec{k}\\
    1 & - 2 & 2\\
    1 & 0 & - 1
  \end{array}\right| = 2 \vec{i} + 3 \vec{j} + 2 \vec{k} = ( 2, 3, 2 )$.
\end{example}

\begin{example}
  Hallar la ecuación general del plano que pasa por $P ( - 2, 1, 0 )$ y tiene
  como vector normal al $\vec{n} = ( 1, 0, 1 )$.
  
  $$\pi : \vec{n} \cdot \overrightarrow{P X} = 0 \Leftrightarrow ( 1, 0, 1 ) \cdot ( x + 2, y - 1, z ) = 0 \Leftrightarrow x + 2 + z = 0 \Leftrightarrow x + z + 2 = 0$$
\end{example}

\begin{theorem}
  [Puntos coplanarios]Cuatro puntos $A$, $B$, $C$ y $D$ son
  coplanarios (es decir, existe un plano que los contiene a los cuatro), si y
  solo si $\det ( \overrightarrow{A B}, \overrightarrow{A C},
  \overrightarrow{A D} ) = 0$.
\end{theorem}

\begin{remark}Esto es lo mismo que decir que el volumen del prisma que determinan sea
0.\end{remark}

\begin{example}
  Determinar el valor de $\alpha$ para que los puntos $A ( 1, - 1, 2 ), B ( -
  2, 1, - 3 ), C ( 0, 1, 0 )$ y $D ( \alpha - 1, \alpha + 1, 2 )$ puedan ser
  coplanarios.
  
  $A, B, C, D$ son coplanarios $\Leftrightarrow \det ( \overrightarrow{A B},
  \overrightarrow{A C}, \overrightarrow{A D} ) = 0 \Leftrightarrow
  \left|\begin{array}{ccc}
    - 2 - 1 & 1 - ( - 1 ) & - 3 - 2\\
    0 - 1 & 1 - ( - 1 ) & 0 - 2\\
    \alpha - 1 - 1 & \alpha + 1 - ( - 1 ) & 2 - 2
  \end{array}\right| = 0 \Leftrightarrow$
  
  $\Leftrightarrow \left|\begin{array}{ccc}
    - 3 & 2 & - 5\\
    - 1 & 2 & - 2\\
    \alpha - 2 & \alpha + 2 & 0
  \end{array}\right| = 0 \Leftrightarrow - 4 ( \alpha - 2 ) + 5 ( \alpha + 2 )
  + 10 ( \alpha - 2 ) - 6 ( \alpha + 2 ) = 0 \Leftrightarrow \alpha =
  \dfrac{14}{5}$
\end{example}

\begin{theorem}
  [Plano determinado por tres puntos]Dados tres puntos de $E_3$ no
  alineados, $A$, $B$ y $C$, existe un único plano que contenga a los tres,
  que es el plano que pasa por uno de ellos y tiene la dirección definida por
  $\overrightarrow{A B}$ y $\overrightarrow{A C}$, es decir, el plano de
  ecuación: $\det ( \overrightarrow{A X}, \overrightarrow{A B},
  \overrightarrow{A C} ) = 0$.
\end{theorem}

\begin{theorem}
  [Ecuación segmentaria del plano]La ecuación general de un plano que
  corta a los ejes de coordenadas en los puntos $A ( a, 0, 0 )$, $B ( 0, b, 0
  )$ y $C ( 0, 0, c )$, con $a \neq 0$, $b \neq 0$ y $c \neq 0$, es:
  
  $\pi : \dfrac{x}{a} + \dfrac{y}{b} + \dfrac{z}{c} = 1$.
\end{theorem}

\begin{example}
  Hallar un vector normal del plano que corta a los ejes en los puntos $A ( 3,
  0, 0 )$, $B ( 0, 6, 0 )$ y $C ( 0, 0, 2 )$.
  
  Utilizando la ecuación segmentaria, hallamos su ecuación general:
  $\dfrac{x}{3} + \dfrac{y}{6} + \dfrac{z}{2} = 1 \Leftrightarrow 2 x + y + 3 z =
  6$
  
  Un vector normal es el $\vec{n} = ( 2, 1, 3 )$. También podíamos haber dado
  directamente el $( \frac{1}{3}, \frac{1}{6}, \frac{1}{2} )$.
\end{example}

\begin{theorem}
  [La recta como intersección de dos planos]
  \begin{enumeratealpha}
    \item Dados dos planos $\pi_1 : \overrightarrow{n_1} \cdot
    \overrightarrow{P X} = 0$ y $\pi_2 : \overrightarrow{n_2} \cdot
    \overrightarrow{Q X} = 0$, con $\overrightarrow{n_1}$ y
    $\overrightarrow{n_2}$ linealmente independientes, el lugar geométrico
    definido por el sistema de ecuaciones:
    
    $\left\{\begin{array}{l}
      \overrightarrow{n_1} \cdot \overrightarrow{P X} = 0\\
      \overrightarrow{n_2} \cdot \overrightarrow{Q X} = 0
    \end{array}\right.$ es una recta con vector director $\overrightarrow{n_1}
    \wedge \overrightarrow{n_2}$.
    
    \item La recta que pasa por $P ( x_0, y_0, z_0 )$ y tiene la dirección de
    $\vec{v} = ( v_1 \neq 0, v_2, v_3 )$, es la intersección de los planos
    $\pi_1 : \overrightarrow{n_1} \cdot \overrightarrow{P X}$ y $\pi_2 :
    \overrightarrow{n_2} \cdot \overrightarrow{P X}$, siendo
    $\overrightarrow{n_1} = ( v_2, - v_1, 0 )$ y $\overrightarrow{n_2} = (
    v_3, 0, - v_1 )$.
  \end{enumeratealpha}
\end{theorem}

\begin{remark}El teorema anterior dice dos cosas: 1) La intersección de dos planos con
distinta dirección es una recta; 2) Toda recta se puede expresar como
intersección de dos planos.\end{remark}

\begin{remark}Es fácil comprobar el teorema anterior utilizando el teorema de Rouché.
El sistema formado por las ecuaciones generales de dos planos es un sistema
lineal de dos ecuaciones con tres incógnitas. Si el rango de la matriz de
coeficientes es 2 (esto será así siempre que los vectores normales de los
planos no estén alineados), el rango de la matriz ampliada también será 2 (no
puede ser 3, ni menor que el de la de coeficientes), y, por tanto, el sistema
es compatible indeterminado uniparamétrico. El conjunto de soluciones es la
recta intersección de ambos planos.\end{remark}

\begin{example}
  Hallar las ecuaciones paramétricas de la recta $r : \left\{\begin{array}{l}
    3 x - 2 y + 4 z - 2 = 0\\
    2 x + 3 y - 5 z + 8 = 0
  \end{array}\right.$.
  
  Para escribir las ecuaciones paramétricas necesitamos un vector director y
  un punto.
  
  La recta viene dada como intersección de dos planos de vectores normales
  $\vec{n}_1 = ( 3, - 2, 4 )$ y $\vec{n}_2 = ( 2, 3, - 5 )$. Un vector
  director de la recta es $\vec{v} = \vec{n}_1 \wedge \vec{n}_2 =
  \left|\begin{array}{ccc}
    \vec{i} & \vec{j} & \vec{k}\\
    3 & - 2 & 4\\
    2 & 3 & - 5
  \end{array}\right| = ( - 2, 23, 13 )$.
  
  Para calcular un punto de la recta tenemos que hallar una solución del
  sistema. Para ello damos un valor a $x$ y resolvemos el sistema que queda.
  Haciendo, por ejemplo, $x = 0$:
  
  $\left\{\begin{array}{l}
    - 2 y + 4 z - 2 = 0\\
    3 y - 5 z + 8 = 0
  \end{array}\right. \Leftrightarrow \left\{\begin{array}{l}
    y = - 11\\
    z = - 5
  \end{array}\right.$. Un punto de la recta es $P ( 0, - 11, - 5 )$.
  
  Las ecuaciones paramétricas son: $r : \left\{\begin{array}{l}
    x = - 2 \lambda\\
    y = - 11 + 23 \lambda\\
    z = - 5 + 13 \lambda
  \end{array}\right., \lambda \in \mathbb{R}$.
\end{example}

\begin{example}
  Expresar como intersección de dos planos la recta que pasa por $P ( 2, 3, -
  2 )$ y tiene la dirección de $\vec{v} = ( 3, 1, 5 )$.
  
  Su ecuación continua es: $r : \dfrac{x - 2}{3} = \dfrac{y - 3}{1} = \dfrac{z +
  2}{5}$. Si escribimos en forma de sistema:
  
  $r : \left\{\begin{array}{l}
    \dfrac{x - 2}{3} = \dfrac{y - 3}{1}\\
    \dfrac{y - 3}{1} = \dfrac{z + 2}{5}
  \end{array}\right. \Leftrightarrow \left\{\begin{array}{l}
    x - 2 = 3 ( y - 3 )\\
    5 ( y - 3 ) = z + 2
  \end{array}\right. \Leftrightarrow \left\{\begin{array}{l}
    x - 3 y + 7 = 0\\
    5 y - z - 17 = 0
  \end{array}\right.$
\end{example}

{}

\newpage\section{Ortogonalidad y paralelismo de rectas y planos}

\begin{definition}
  [Ortogonalidad] Definición de ortogonalidad entre rectas y planos:
  \begin{enumeratealpha}
    \item Dos rectas son ortogonales si lo son sus direcciones (es decir, si
    lo son sus vectores directores).
    
    \item Dos planos son ortogonales si lo son sus vectores normales.
    
    \item Una recta y un plano son ortogonales si lo son sus direcciones (es
    decir, si el vector director de la recta es ortogonal a la dirección del
    plano, o lo que es lo mismo, si el vector director director de la recta
    tiene la misma dirección que el vector normal del plano).
  \end{enumeratealpha}
\end{definition}

\begin{remark}Las direcciones son conjuntos de vectores. Dos conjuntos de vectores son
ortogonales si todos los vectores de uno de ellos son ortogonales a todos los
vectores del otro. \end{remark}

\begin{example}
  Hallar una recta ortogonal al plano $\pi : 2 x - y + z - 1 = 0$ que pase por
  el origen.
  
  Para que la recta sea ortogonal al plano su vector director ha de ser
  ortogonal al mismo. Sirve por tanto un vector normal del plano como vector
  director. Como punto tenemos el origen. Por tanto la recta pedida es
  (ecuación continua):
  
  $r : \dfrac{x}{2} = \dfrac{y}{- 1} = z$
\end{example}

\begin{definition}
  [Paralelismo] Definición de paralelismo entre rectas y planos:
  \begin{enumeratealpha}
    \item Dos rectas son paralelas si tienen la misma dirección (es decir, si
    sus vectores directores son proporcionales).
    
    \item Dos planos son paralelos si tienen la misma dirección (es decir, si
    sus vectores normales son proporcionales).
    
    \item Una recta es paralela a un plano si la dirección de la recta está
    incluida en la del plano (es decir, si el vector director de la recta es
    ortogonal al vector normal del plano).
  \end{enumeratealpha}
\end{definition}

\begin{example}
  Hallar un plano paralelo a $\pi : x - 2 y + 3 z - 1 = 0$ que pase por el
  punto $P ( 2, 1, 0 )$.
  
  Para que sea paralelo, el plano pedido ha de tener el mismo vector normal
  que $\pi$, es decir, su ecuación general será de la forma:
  
  $\pi' : x - 2 y + 3 z + D = 0$
  
  Para hallar $D$, sustituimos las coordenadas del punto conocido en la
  ecuación del plano:
  
  $P \in \pi' \Leftrightarrow 2 - 2 \cdot 1 + 3 \cdot 0 + D = 0
  \Leftrightarrow D = 0$.
  
  El plano pedido es: $x - 2 y + 3 z = 0$.
\end{example}

\begin{remark}
  Se llama intersección entre dos o más lugares geométricos (o también, incidencia de uno en otros), al conjunto de puntos comunes a todos ellos. Para el caso concreto de rectas y planos se tiene que: 
  \begin{enumeratealpha}
    \item La intersección de dos rectas puede ser vacía, un punto o una recta.
    
    \item La intersección de dos planos puede ser vacía, una recta o un plano.
    
    \item La intersección de una recta y un plano puede ser vacía, un punto o
    una recta.
  \end{enumeratealpha}
\end{remark}

\begin{remark}La intersección se halla resolviendo el
sistema que forman las ecuaciones de los lugares geométricos que se
intersecan. Obsérvese, que, siendo las ecuaciones de rectas y planos lineales, los sistemas que determinan las intersecciones entre ellos son lineales.\end{remark}

\newpage\section{Posiciones relativas de rectas y planos}

\begin{remark}
  Las posiciones relativas entre rectas y planos pueden estudiarse analizando los sistemas que forman sus ecuaciones, o también estudiando las relaciones entre algunos de sus elementos característicos. En todos los casos se enunciarán teoremas para estudiar la posición relativa de que se trate por ambos métodos.
\end{remark}

\begin{remark}Muchos de los teoremas siguientes son consecuencias inmediatas del Teorema
de Rouché. Estudiar la posición relativa de rectas y planos se reduce con
ellos a discutir los sistemas que forman sus ecuaciones (que son siempre
lineales).\end{remark}

\begin{theorem}
  [Posiciones relativas de dos planos]Dados dos planos $\pi_1 : A_1 x
  + B_1 y + C_1 z + D_1 = 0$ y $\pi_2 : A_2 x + B_2 y + C_2 z + D_2 = 0$ se
  definen las matrices $M = \left(\begin{array}{ccc}
    A_1 & B_1 & C_1\\
    A_2 & B_2 & C_2
  \end{array}\right)$ y $M' = \left(\begin{array}{cccc}
    A_1 & B_1 & C_1 & D_1\\
    A_2 & B_2 & C_2 & D_2
  \end{array}\right)$, se tiene:
  \begin{enumeratealpha}
    \item si rango(M)=rango(M')=2, los planos son secantes (su intersección es
    una recta);
    
    \item si rango(M)=1 y rango(M')=2, los planos son paralelos no
    coincidentes ($\pi_1 \cap \pi_2 = \oslash$);
    
    \item si rango(M)=rango(M')=1, los planos son coincidentes ($\pi_1 =
    \pi_2$).
  \end{enumeratealpha}
\end{theorem}

\begin{theorem}
  Dados dos planos $\pi_1:\vec{n_1}\cdot\overrightarrow{P_1X}$ y $\pi_2:\vec{n_2}\cdot\overrightarrow{P_2X}$, se verifica:
  \begin{enumeratealpha}
    \item Si $\vec{n_1}$ y $\vec{n_2}$ no son paralelos, entonces $\pi_1$ y $\pi_2$ son secantes.
    \item Si $\vec{n_1}$ y $\vec{n_2}$ son paralelos y $P_2 \notin \pi_1$, entonces $\pi_1$ y $\pi_2$ son paralelos no coincidentes.
    \item Si $\vec{n_1}$ y $\vec{n_2}$ son paralelos y $P_2 \in \pi_1$, entonces $\pi_1$ y $\pi_2$ son coincidentes.
  \end{enumeratealpha}
\end{theorem}

\begin{theorem}
  [Posiciones relativas de tres planos]Dados tres planos $\pi_1 : A_1
  x + B_1 y + C_1 z + D_1 = 0$, $\pi_2 : A_2 x + B_2 y + C_2 z + D_2 = 0$ y
  $\pi_3 : A_3 x + B_3 y + C_3 z + D_3 = 0$, se definen las matrices $M =
  \left(\begin{array}{ccc}
    A_1 & B_1 & C_1\\
    A_2 & B_2 & C_2\\
    A_3 & B_3 & C_3
  \end{array}\right)$ y $M' = \left(\begin{array}{cccc}
    A_1 & B_1 & C_1 & D_1\\
    A_2 & B_2 & C_2 & D_2\\
    A_3 & B_3 & C_3 & D_3
  \end{array}\right)$, se tiene:
  \begin{enumeratealpha}
    \item si rango(M)=rango(M')=3, los planos son secantes en un punto;
    
    \item si rango(M)=2 y rango(M')=3, los planos son secantes dos a dos, o
    dos de ellos son paralelos entre sí y secantes con el tercero;
    
    \item si rango(M)=rango(M')=2, los planos son secantes en una recta;
    
    \item si rango(M)=1 y rango(M')=2; los planos son paralelos entre sí y al
    menos dos de ellos no coincidentes;
    
    \item si rango(M)=rango(M')=1; los tres planos son coincidentes.
  \end{enumeratealpha}
\end{theorem}

\begin{example}
  Estudiar la posición relativa de los planos: $\pi_1 : 3 x + 2 y - z = 2 ;
  \pi_2 : x + y + z = 5 ; \pi_3 : 2 x + y - 2 z = - 3$.
  
  $M = \left(\begin{array}{ccc}
    3 & 2 & - 1\\
    1 & 1 & 1\\
    2 & 1 & - 2
  \end{array}\right) ; M' = \left(\begin{array}{cccc}
    3 & 2 & - 1 & 2\\
    1 & 1 & 1 & 5\\
    2 & 1 & - 2 & - 3
  \end{array}\right)$
  
  $\det ( M ) = \left|\begin{array}{ccc}
    3 & 2 & - 1\\
    1 & 1 & 1\\
    2 & 1 & - 2
  \end{array}\right| = - 6 + 4 - 1 + 2 + 4 - 3 = 0 \Rightarrow \tmop{rango} (
  M ) = 2$; $M' \sim \left(\begin{array}{cccc}
    3 & 2 & - 1 & 2\\
    1 & 1 & 1 & 5\\
    0 & 0 & 0 & 0
  \end{array}\right) \Rightarrow \tmop{rango} ( M' ) = 2$
  
  rango(M)=rango(M')=2$\Rightarrow$los planos son secantes en una recta. La
  recta común es la intersección de dos cualesquiera de los tres planos
  (suponiendo que no haya dos coincidentes).
  
  
\end{example}

\begin{theorem}
  [Posiciones relativas de dos rectas]Dadas dos rectas $r :
  \left\{\begin{array}{l}
    A_1 x + B_1 y + C_1 z + D_1 = 0\\
    A_2 x + B_2 y + C_2 z + D_2 = 0
  \end{array}\right. $y $r' : \left\{\begin{array}{l}
    A_3 x + B_3 y + C_3 z + D_3 = 0\\
    A_4 x + B_4 y + C_4 z + D_4 = 0
  \end{array}\right.$, se definen las matrices $M = \left(\begin{array}{ccc}
    A_1 & B_1 & C_1\\
    A_2 & B_2 & C_2\\
    A_3 & B_3 & C_3\\
    A_4 & B_4 & C_4
  \end{array}\right)$ y $M' = \left(\begin{array}{cccc}
    A_1 & B_1 & C_1 & D_1\\
    A_2 & B_2 & C_2 & D_2\\
    A_3 & B_3 & C_3 & D_3\\
    A_4 & B_4 & C_4 & D_4
  \end{array}\right)$, se tiene:
  \begin{enumeratealpha}
    \item si rango(M)=3 y rango(M')=4, las rectas son cruzadas ($r \cap r' =
    \oslash$ y no son coplanarias);
    
    \item si rango(M)=rango(M')=3, las rectas son secantes (su intersección es
    un punto);
    
    \item si rango(M)=2 y rango(M')=3, las rectas son paralelas;
    
    \item si rango(M)=rango(M')=2, las rectas son coincidentes.
  \end{enumeratealpha}
\end{theorem}

\begin{remark}Dos rectas son coplanarias si existe algún plano que contenga a ambas.
Dos rectas son coplanarias cuando son secantes, paralelas o coincidentes.\end{remark}

\begin{theorem}
  Dadas dos rectas, $r:\overrightarrow{P_rX}=\lambda_r\vec{v_r}$ y $s:\overrightarrow{P_sX}=\lambda_s\vec{v_s}$, se verifica:
  \begin{enumeratealpha}
    \item Si $\det(\vec{v_r},\vec{v_s},\overrightarrow{P_rP_s})\neq 0$, entonces $r$ y $s$ se cruzan (no son coplanarias).
    \item Si $\det(\vec{v_r},\vec{v_s},\overrightarrow{P_rP_s}) = 0$, entonces $r$ y $s$ son coplanarias. En este caso,
      \begin{itemize}
      \item Si $\vec{v_r}$ y $\vec{v_s}$ no son paralelos, entonces $r$ y $s$ son secantes.
      \item Si $\vec{v_r}$ y $\vec{v_s}$ son paralelos y $P_r \notin s$, entonces $r$ y $s$ son paralelas no coincidentes.
      \item Si $\vec{v_r}$ y $\vec{v_s}$ son paralelos y $P_r \in s$, entonces $r$ y $s$ son coincidentes.
      \end{itemize}
  \end{enumeratealpha}
\end{theorem}

\begin{theorem}
  [Posiciones relativas de una recta y un plano]Dados una recta $r :
  \left\{\begin{array}{l}
    A_1 x + B_1 y + C_1 z + D_1 = 0\\
    A_2 x + B_2 y + C_2 z + D_2 = 0
  \end{array}\right. $y un plano $\pi : A_3 x + B_3 y + C_3 z + D_3 = 0$,, se
  definen las matrices $M = \left(\begin{array}{ccc}
    A_1 & B_1 & C_1\\
    A_2 & B_2 & C_2\\
    A_3 & B_3 & C_3
  \end{array}\right)$ y $M' = \left(\begin{array}{cccc}
    A_1 & B_1 & C_1 & D_1\\
    A_2 & B_2 & C_2 & D_2\\
    A_3 & B_3 & C_3 & D_3
  \end{array}\right)$, se tiene:
  \begin{enumeratealpha}
    \item si rango(M)=rango(M')=3 la recta y el plano son secantes (se cortan
    en un punto);
    
    \item si rango(M)=2 y rango(M')=3, la recta es paralela al plano;
    
    \item si rango(M)=rango(M')=2, la recta está contenida en el plano.
  \end{enumeratealpha}
\end{theorem}

\begin{theorem}
  Dados una recta $r:\overrightarrow{P_rX}=\lambda \vec{v_r}$ y un plano $\pi:\overrightarrow{P_{\pi}X}\cdot\vec{n_{\pi}}=0$, se verifica:
  \begin{enumeratealpha}
    \item Si $\vec{v_r}\cdot\vec{n_{\pi}}\neq0$, entonces la recta es secante al plano.
    \item Si $\vec{v_r}\cdot\vec{n_{\pi}} = 0$ y $P_r \notin \pi$, entonces la recta es paralela al plano (y no está contenida en él).
    \item Si $\vec{v_r}\cdot\vec{n_{\pi}} = 0$ y $P_r \in \pi$, entonces la recta está contenida en el plano.
  \end{enumeratealpha}
\end{theorem}

\newpage\section{Haz de planos}

\begin{definition}
  [Haz de planos]Dados dos planos
  
  $$\pi_1 : A_1 x + B_1 y + C_1 z + D_1 = 0$$
  
  $$\pi_2 : A_2 x + B_2 y + C_2 z + D_2 = 0$$
  
  se llama haz de planos determinado por $\pi_1$ y $\pi_2$ al conjunto de
  todos los planos cuya ecuación es de la forma:

    $$\alpha ( A_1 x + B_1 y + C_1 z + D_1 ) + \beta ( A_2 x + B_2 y + C_2 z + D_2 ) = 0$$

  con $\alpha \neq 0$ o $\beta \neq 0$.
\end{definition}

\begin{remark}El haz de planos determinado por $\pi_1$ y $\pi_2$ se puede escribir
también:

$$A_1 x + B_1 y + C_1 z + D_1 + \lambda ( A_2 x + B_2 y + C_2 z + D_2 ) = 0$$

Salvo porque esta expresión excluye al propio $\pi_2$ del haz.\end{remark}

\begin{remark}Por cada punto del espacio, $P \notin \pi_1 \cap \pi_2$, pasa un y solo un
plano del haz.\end{remark}

\begin{theorem}
  {\tmdummy}
  
  \begin{enumeratealpha}
    \item Si $\pi_1$ y $\pi_2$ son secantes en $r$, entonces el haz de planos
    determinado por $\pi_2$ y $\pi_2$ es el conjunto de todos los planos que
    contienen a $r$.
    
    \item Si $\pi_2$ y $\pi_2$ son paralelos, entonces el haz de planos
    determinado por $\pi_1$ y $\pi_2$ es el conjunto de todos los planos
    paralelos a ellos.
  \end{enumeratealpha}
\end{theorem}

\begin{example}
  Hallar la ecuación del plano que pasa por $P ( 1, 0, - 1 )$ y contiene a la
  recta
  $$r : \left\{\begin{array}{l}
    3 x + 2 y - z + 1 = 0\\
    2 x - y + z + 4 = 0
  \end{array}\right..$$
  
  El haz de planos que contienen a $r$ viene dado por:
  
  $$3 x + 2 y - z + 1 + \lambda ( 2 x - y + z + 4 ) = 0$$
  
  Ahora calculamos qué plano del haz anterior pasa por $P$ (para qué valor de
  $\lambda$ el punto $P$ cumple la ecuación anterior), sustituyendo las
  coordenadas de $P$ en la ecuación del haz:
  
  $$3 + 1 + 1 + \lambda ( 2 - 1 + 4 ) = 0 \Leftrightarrow \lambda = - 1$$
  
  El plano pedido se obtiene sustituyendo el valor anterior de $\lambda$ en la
  ecuación del haz:
  
  $$\pi : 3 x + 2 y - z + 1 - ( 2 x - y + z + 4 ) = 0 \Leftrightarrow x + 3 y - 2 z - 3 = 0.$$
\end{example}


\chapter{Distancias y ángulos}

\newpage\section{Ángulo entre dos rectas}

\begin{definition}
  Sea r una recta que tiene la dirección de $\vec{u}_r$ y s una recta que
  tiene la dirección de $\vec{u}_s$. Se llama ángulo entre r y s al menor de
  los cuatro ángulos que forman $\vec{u}_r$, $\vec{u}_s$, $- \vec{u}_r$ y $-
  \vec{u}_s$.
\end{definition}

\begin{theorem}
  Sea r una recta que tiene la dirección de $\vec{u}_r$ y s una recta que
  tiene la dirección de $\vec{u}_s$. El ángulo entre r y s viene dado por:
  \begin{center}
    $\cos ( \widehat{r, s} ) = | \cos ( \vec{u}_r, \vec{u}_s ) |$
  \end{center}
  
\end{theorem}

\begin{example}Hallar el ángulo formado por las rectas $r :
\left\{\begin{array}{l}
  x = 3 + 2 \lambda\\
  y = 2 + \lambda\\
  z = - 3 + 2 \lambda
\end{array}\right.$  y $s : \left\{\begin{array}{l}
  3 x - y + z - 5 = 0\\
  x + y - z = 0
\end{array}\right.$

Vector director de $r$: $\vec{u}_r = ( 2, 1, 2 )$. Vector director de $s$:
$\vec{u}_s = ( 3, - 1, 1 ) \wedge ( 1, 1, - 1 ) = ( 0, 4, 4 )$

$\cos ( \widehat{r, s} ) = | \cos ( \vec{u}_r, \vec{u}_s ) | = |
\dfrac{\vec{u}_r \cdot \vec{u}_s}{| \vec{u}_r \| \vec{u}_s |} | = | \dfrac{( 2,
1, 2 ) \cdot ( 0, 4, 4 )}{\sqrt{2^2 + 1^2 + 2^2} \cdot \sqrt{0^2 + 4^2 + 4^2}}
| = | \dfrac{12}{\sqrt{9} \sqrt{32}} | = \dfrac{\sqrt{2}}{2}$

Por tanto, $\tmop{ang} ( r, s ) = \arccos \dfrac{\sqrt{2}}{2} = \dfrac{\pi}{4} (
45^{\circ} )$.
\end{example}

\section{Ángulo entre dos planos}

\begin{definition}
  Se llama ángulo entre dos planos $\pi_1$ y $\pi_2$ al ángulo entre una recta
  perpendicular a $\pi_1$ y una recta perpendicular a $\pi_2$.
\end{definition}

\begin{theorem}
  Sea $\pi_1$ un plano con vector normal $\vec{n}_1$ y sea $\pi_2$ un plano
  con vector normal $\vec{n}_2$. El ángulo entre $\pi_1$ y $\pi_2$ viene dado
  por:
  \begin{center}
    $\cos ( \widehat{\pi_{1,} \pi_2} ) = | \cos ( \widehat{\vec{n}_1,
    \vec{n}_2} ) |$
  \end{center}
  
\end{theorem}

\begin{example}
  Hallar el ángulo que forman los planos: $\text{} \pi_1 : 3 x - 2 y + 4 z - 2
  = 0 ; \pi_2 : x + y - z + 5 = 0$
  
  Vectores normales: $\vec{n}_1 = ( 3, - 2, 4 )$; $\vec{n}_2 = ( 1, 1, - 1 )$.
  
  $\cos ( \widehat{\pi_1, \pi_2} ) = | \cos ( \widehat{\vec{n}_1, \vec{n}_2} )
  | = | \dfrac{\vec{n}_1 \cdot \vec{n}_2}{| \vec{n}_1 \| \vec{n}_2 |} | = |
  \dfrac{( 3, - 2, 4 ) \cdot ( 1, 1, - 1 )}{\sqrt{3^2 + ( - 2 )^2 + 4^2}
  \sqrt{1^2 + 1^2 + ( - 1 )^2}} | = | \dfrac{- 3}{\sqrt{29} \sqrt{3}} | = 0,
  3216$
  
  $\tmop{ang} ( \pi_1, \pi_2 ) = \arccos 0, 3216 = 1, 2433 \tmop{rad} = 71,
  24^{\circ}$
\end{example}

\newpage\section{Ángulo entre una recta y un plano}

\begin{definition}
  Se llama ángulo entre una recta y un plano al ángulo que forma dicha recta
  con su proyección ortogonal sobre el plano.
\end{definition}

\begin{theorem}
  Sea $r$ una recta con vector director $\vec{u}_r$, y sea $\pi$ un plano con
  vector normal $\vec{n}_{\pi}$. El ángulo formado por $r$ y $\pi$ viene dado
  por:
  \begin{center}
    $\tmop{sen} ( \widehat{r, \pi} ) = | \cos ( \widehat{\vec{u}_r,
    \vec{n}}_{\pi} ) |$
  \end{center}
  
\end{theorem}

\begin{remark}El ángulo que forma una recta con un plano es complementario del ángulo
que forma dicha recta con una recta perpendicular al plano.\end{remark}

\begin{example}
  Dados la recta $r \equiv \frac{x}{2} = - y = z$ y el plano $\pi \equiv x + y
  + m z - 15 = 0$, determinar el valor de $m$ para que $r$ y $\pi$ formen un
  ángulo de $30^{\circ}$.
  
  Vector director de $r$: $\vec{v} = ( 2, - 1, 1 )$. Vector normal de $\pi$:
  $\vec{n} = ( 1, 1, m )$.
  
  Ángulo entre $r$ y $\pi$: $\tmop{sen} ( r, \pi ) = | \cos ( \vec{v}, \vec{n}
  ) | = | \dfrac{\vec{v} \cdot \vec{n}}{| \vec{v} \| \vec{n} |} | = | \dfrac{(
  2, - 1, 1 ) \cdot ( 1, 1, m )}{\sqrt{4 + 1 + 1} \sqrt{1 + 1 + m^2}} | = |
  \dfrac{m + 1}{\sqrt{6 ( m^2 + 2 )}} |$.
  
  Para que sea de 30º: $\tmop{sen} ( r, \pi ) = \tmop{sen}
  30^{\circ} = \dfrac{1}{2} \Leftrightarrow | \dfrac{m + 1}{\sqrt{6 ( m^2 + 2
  )}} | = \dfrac{1}{2} \Rightarrow \dfrac{( m + 1 )^2}{6 ( m^2 + 2 )} =
  \dfrac{1}{2^2} \Leftrightarrow$
  
  $\Leftrightarrow 2 ( m + 1 )^2 = 3 ( m^2 + 2 ) \Leftrightarrow m^2 - 4 m + 4
  = 0 \Leftrightarrow m = 2$
\end{example}

{}

\newpage\section{Distancia entre un punto y un plano}

\begin{definition}
  Se llama distancia entre un punto y un plano a la mínima de las distancias
  entre dicho punto y todos los puntos del plano: $d ( P, \pi ) = \min \{ d (
  P, Q ) / Q \in \pi \}$.
\end{definition}

\begin{definition}
  [Proyección ortogonal de un punto sobre un plano]Dados un punto P y
  un plano $\pi$, la proyección ortogonal de P sobre $\pi$ es el punto Q de
  $\pi$ tal que la dirección del vector $\overrightarrow{P Q}$ es ortogonal a
  la dirección del plano $\pi$.
\end{definition}

\begin{remark}Siempre existe un punto Q que cumpla lo anterior, y solo existe uno.\end{remark}

\begin{remark}Método práctico de cálculo de la proyección ortogonal de un punto P
sobre un plano $\pi$: hallar una recta $r$ perpendicular al plano $\pi$ que
pase por P; la proyección ortogonal de P sobre $\pi$ es la intersección de $r$
con $\pi$.\end{remark}

\begin{theorem}
  La distancia entre un punto $P ( x_0, y_0, z_0 )$ y un plano $\pi : A x + B
  y + C z + D = 0$ es la distancia entre P y la proyección ortogonal de P
  sobre $\pi$, y viene dada por:
  \begin{center}
    $d ( P, \pi ) = \dfrac{|A x_0 + B y_0 + C z_0 + D|}{\sqrt{A^2 + B^2 +
    C^2}}$
  \end{center}
  
\end{theorem}

\begin{example}
  Hallar la distancia del punto $P ( 3, 2, - 1 )$ al plano $\pi : 2 x - y - 2
  z + 3 = 0$.
  
  $d ( P, \pi ) = \dfrac{|2 \cdot 3 - 2 - 2 \cdot ( - 1 ) + 3|}{\sqrt{2^2 + ( -
  1 )^2 + ( - 2 )^2}} = \dfrac{9}{\sqrt{9}} = 3$
\end{example}

\begin{example}
  Hallar el punto simétrico de $P ( 3, 2, - 1 )$ respecto al plano $\pi : 2 x
  - y - 2 z + 3 = 0$.
  
  Calculamos la proyección ortogonal de $P$ sobre $\pi$. Para ello,
  determinamos en primer lugar la recta $r$ perpendicular a $\pi$ que pasa por
  $P$: esta es aquella cuyo vector director es el vector normal de $\pi$. Por
  tanto,
  
  $r \equiv \left\{\begin{array}{l}
    x = 3 + 2 \lambda\\
    y = 2 - \lambda\\
    z = - 1 - 2 \lambda
  \end{array}\right.$
  
  La proyección ortogonal de $P$ sobre $\pi$, que llamaremos $P_0$, es la
  intersección de esta recta con $\pi$:
  
  \begin{eqnarray*}P_0 = r \cap \pi \equiv \left\{\begin{array}{l}
    x = 3 + 2 \lambda\\
    y = 2 - \lambda\\
    z = - 1 - 2 \lambda\\
    2 x - y - 2 z + 3 = 0
  \end{array}\right. & \Leftrightarrow & \left\{\begin{array}{l}
    x = 3 + 2 \lambda\\
    y = 2 - \lambda\\
    z = - 1 - 2 \lambda\\
    2 ( 3 + 2 \lambda ) - ( 2 - \lambda ) - 2 ( - 1 - 2 \lambda ) + 3 = 0
  \end{array}\right. \\
  & \Leftrightarrow & \left\{\begin{array}{l}
    x = 3 + 2 \lambda\\
    y = 2 - \lambda\\
    z = - 1 - 2 \lambda\\
    \lambda = - 1
  \end{array}\right. \\
  & \Leftrightarrow & \left\{\begin{array}{l}
    x = 1\\
    y = 3\\
    z = 1
  \end{array}\right. \Rightarrow P_0 ( 1, 3, 1 )
\end{eqnarray*}
  
  La proyección ortogonal es el punto medio del segmento delimitado por $P$ y
  su simétrico, $P'$:
  
  $\overrightarrow{O P_0} = \dfrac{1}{2} ( \overrightarrow{O P} +
  \overrightarrow{O P'} ) \Leftrightarrow \overrightarrow{O P'} = 2
  \overrightarrow{O P_0} - \overrightarrow{O P} = 2 ( 1, 3, 1 ) - ( 3, 2, - 1
  ) = ( - 1, 4, 3 )$
\end{example}



\newpage\section{Distancia entre un punto y una recta}

\begin{definition}
  Se llama distancia entre un punto P y una recta r a la mínima de las
  distancias entre P y un punto de r: $d ( P, r ) = \min \{ d ( P, Q ) / Q \in
  r \}$.
\end{definition}

\begin{definition}
  [Proyección ortogonal de un punto sobre una recta]Se llama
  proyección ortogonal de un punto P sobre una recta r al punto Q de r tal que
  la dirección del vector $\overrightarrow{P Q}$ es ortogonal a la dirección
  de r.
\end{definition}

\begin{remark}La proyección ortogonal de un punto sobre una recta existe siempre y es
única.\end{remark}

\begin{remark}Método práctico de cálculo de la proyección ortogonal de un punto $P$
sobre una recta $r$. Hallar un plano perpendicular a $r$ que pase por $P$. La
proyección ortogonal de $P$ sobre $r$ es la intersección de $r$ con ese
plano.\end{remark}

\begin{theorem}
  La distancia entre un punto P y una recta $r : A_r + \lambda \vec{u}_r$ es
  la distancia entre P y la proyección ortogonal de P sobre r, y viene dada
  por:
  \begin{center}
    $d ( P, r ) = \dfrac{| \overrightarrow{P A_r} \wedge \vec{u}_r |}{|
    \vec{u}_r |}$
  \end{center}
  
\end{theorem}

\begin{remark}A lo largo de este tema utilizaremos la siguiente simbología abreviada:
la recta $r$ que pasa por el punto $P$ y tiene la dirección del vector
$\vec{u}$ se representará por $r : P + \lambda \vec{u}$. Es una forma
abreviada de la ecuación vectorial: $r : \overrightarrow{O X} =
\overrightarrow{O P} + \lambda \vec{u}$.\end{remark}

\begin{example}
  Calcular la distancia entre la recta $r : ( x, y, z ) = ( 2, 3, 4 ) +
  \lambda ( - 1, 2, 1 )$ y $P ( 3, - 3, 1 )$
  
  Tomamos el punto de la recta $r$, $A_r ( 2, 3, 4 )$:
  
  $d ( P, r ) = \dfrac{| \overrightarrow{P A_r} \wedge \vec{u}_r |}{| \vec{u}_r
  |} = \dfrac{| ( 2 - 3, 3 - ( - 3 ), 4 - 1 ) \wedge ( - 1, 2, 1 ) |}{\sqrt{( -
  1 )^2 + 2^2 + 1^2}} = \dfrac{| ( 0, 2, - 4 ) |}{\sqrt{6}} =
  \dfrac{\sqrt{20}}{\sqrt{6}} = \sqrt{\dfrac{10}{3}}$
\end{example}

\begin{example}
  Calcular la proyección ortogonal del punto $P ( - 1, 1, - 1 )$ sobre la
  recta:
  
  $r \equiv \left\{\begin{array}{l}
    x = - 2 \lambda\\
    y = 10 + 3 \lambda\\
    z = 4 \lambda
  \end{array}\right.$
  
  Hallamos el plano perpendicular a $r$ que pasa por $P$ (por ser
  perpendicular a $r$, su vector normal es vector director de la recta).
  Ecuación normal:
  
  $\pi : - 2 ( x + 1 ) + 3 ( y - 1 ) + 4 ( z + 1 ) = 0 \Leftrightarrow - 2 x +
  3 y + 4 z - 1 = 0$
  
  La proyección ortogonal de $P$ sobre $r$, $P_0$, será la intersección de $r$
  y $\pi$:
  
  $P_0 = r \cap \pi \equiv \left\{\begin{array}{l}
    x = - 2 \lambda\\
    y = 10 + 3 \lambda\\
    z = 4 \lambda\\
    - 2 x + 3 y + 4 z - 1 = 0
  \end{array}\right. \Leftrightarrow \left\{\begin{array}{l}
    x = - 2 \lambda\\
    y = 10 + 3 \lambda\\
    z = 4 \lambda\\
    - 2 ( - 2 \lambda ) + 3 ( 10 + 3 \lambda ) + 4 ( 4 \lambda ) - 1 = 0
  \end{array}\right. \Leftrightarrow \left\{\begin{array}{l}
    x = 2\\
    y = 7\\
    z = - 4\\
    \lambda = - 1
  \end{array}\right.$
  
  El punto pedido es $P_0 ( 2, 7, - 4 )$.
\end{example}

\newpage\section{Distancia entre dos planos paralelos}

\begin{definition}
  Se llama distancia entre dos planos paralelos $\pi_1$ y $\pi_2$ a la mínima
  de las distancias entre un punto de $\pi_1$ y un punto de $\pi_2$: $d (
  \pi_1, \pi_2 ) = \min \{ d ( P, Q ) / P \in \pi_1, Q \in \pi_2 \}$.
\end{definition}

\begin{theorem}
  Dados dos planos paralelos $\pi_1 : A x + B y + C z + D_1 = 0$, $\pi_2 : A x
  + B y + C z + D_2 = 0$, la distancia entre ellos es igual a la distancia
  entre un punto cualquiera de $\pi_1$ y el plano $\pi_2$, y viene dada por:
  \begin{center}
    $d ( \pi_1, \pi_2 ) = \dfrac{|D_1 - D_2 |}{\sqrt{A^2 + B^2 + C^2}}$
  \end{center}
  
\end{theorem}

\section{Distancia entre dos rectas}

\begin{definition}
  Dadas dos rectas $r_1$ y $r_2$ se llama distancia entre ellas a la mínima de
  las distancias entre un punto de $r_1$ y un punto de $r_2$: $d ( r_1, r_2 )
  = \min \{ d ( P, Q ) / P \in r_1, Q \in r_2 \}$.
\end{definition}

\begin{theorem}
  [Distancia entre dos rectas paralelas]La distancia entre dos rectas
  paralelas $r_1 : A_1 + \lambda \vec{u}_1$ y $r_2 : A_2 + \lambda \vec{u}_2$
  es igual a la distancia entre un punto cualquiera de $r_1$ y la recta $r_2$:
  \begin{center}
    $d ( r_1, r_2 ) = \dfrac{| \overrightarrow{A_1 A_2} \wedge \vec{u}_2 |}{|
    \vec{u}_2 |}$
  \end{center}
  
\end{theorem}

\begin{theorem}
  [Distancia entre dos rectas cruzadas]La distancia entre dos rectas
  cruzadas $r_1 : A_1 + \lambda \vec{u}_1$ y $r_2 : A_2 + \lambda \vec{u}_2$
  viene dada por:
  \begin{center}
    $d ( r_1, r_2 ) = \dfrac{[ \overrightarrow{A_1 A_2}, \vec{u}_1, \vec{u}_2
    ]}{| \vec{u}_1 \wedge \overrightarrow{u_2} |}$
    
    
  \end{center}
\end{theorem}

\begin{example}
  Hallar la distancia entre las rectas: $r : x - 1 = y = - 4 z$ y $s : ( x, y,
  z ) = ( 1, 1, 2 ) + \lambda ( 1, 2, 0 )$
  
  Tomamos un punto de $r$ y un punto de $s$: $A_r ( 1, 0, 0 )$, $A_s ( 1, 1, 2
  )$, y hallamos el vector que los une:
  
  $\overrightarrow{A_r A_s} = ( 1, 1, 2 ) - ( 1, 0, 0 ) = ( 0, 1, 2 )$.
  
  Vector director de $r$: $\vec{u}_r = ( 4, 4, - 1 )$.
  
  Vector director de $s$: $\vec{u}_s = ( 1, 2, 0 )$.
  
  $d ( r, s ) = \dfrac{[ \overrightarrow{A_r A_s}, \vec{u}_r, \vec{u}_s ]}{|
  \vec{u}_r \wedge \vec{u}_s |} = \dfrac{\left|\begin{array}{ccc}
    0 & 1 & 2\\
    4 & 4 & - 1\\
    1 & 2 & 0
  \end{array}\right|}{| ( 4, 4, - 1 ) \wedge ( 1, 2, 0 ) |} = \dfrac{7}{| ( 2,
  - 1, 4 ) |} = \dfrac{7}{\sqrt{2^2 + ( - 1 )^2 + 4^2}} = \dfrac{7}{\sqrt{21}} =
  \sqrt{\dfrac{7}{3}}$
\end{example}

{}

\newpage\section{Perpendicular común}

\begin{definition}
  Dadas dos rectas cruzadas se llama perpendicular común a ellas a una recta
  perpendicular a ambas y secante con ambas.
\end{definition}

\begin{remark}Se puede demostrar que siempre existe una perpendicular común, y que es
única.\end{remark}

\begin{remark}La distancia entre dos rectas cruzadas es igual a la distancia entre los
puntos en que la perpendicular común corta a cada una de ellas. Es decir, la
perpendicular común es la recta que pasa por los puntos de ambas rectas más
próximos entre sí.\end{remark}

\begin{theorem}
  Sean dos rectas cruzadas $r : A_r + \lambda \vec{u}_r$ y $s : A_s + \lambda
  \overrightarrow{u_s}$, la perpendicular común a ellas viene dada por:
  \begin{center}
    $t : \left\{\begin{array}{l}
      \det ( \overrightarrow{A_r X}, \vec{u}_r, \vec{u}_r \wedge \vec{u}_s ) =
      0\\
      \det ( \overrightarrow{A_s X}, \vec{u}_s, \vec{u}_r \wedge \vec{u}_s ) =
      0
    \end{array}\right.$
  \end{center}
  
\end{theorem}

\begin{remark}Otro método para hallar la perpendicular común consiste en hallar los
puntos en que esa recta corta a ambas. Sean, dichos puntos $P_r$ y $P_s$. Cada
uno de ellos debe cumplir las ecuaciones de su recta, luego: $P_r = A_r +
\lambda_r \vec{u}_r$ y $P_s = A_s + \lambda_s \vec{u}_s$. Además, se deben
cumplir dos condiciones (el vector que une ambos puntos ha de ser ortogonal
tanto a $r$ como a $s$, ya que está en la perpendicular común):

$\left\{\begin{array}{l}
  \overrightarrow{P_r P_s} \cdot \vec{u}_r = 0\\
  \overrightarrow{P_r P_s} \cdot \vec{u}_s = 0
\end{array}\right.$

El sistema anterior nos dará los valores de $\lambda_r$ y $\lambda_s$ que
cumplen la condición, y, por tanto, los puntos $P_r$ y $P_s$ buscados. La
perpendicular común será la recta que pasa por $P_r$ y $P_s$.
\end{remark}

\begin{example}
  Hallar la perpendicular común a las rectas $r : x - 1 = y = - 4 z$ y $s : (
  x, y, z ) = ( 1, 1, 2 ) + \lambda ( 1, 2, 0 )$.
  
  Utilizando la fórmula del teorema anterior, tomamos un punto de $r$ y un
  punto de $s$, $A_r ( 1, 0, 0 )$ y $A_s ( 1, 1, 2 )$.
  
  Hallamos un vector director de $r$ y uno de $s$: $\overrightarrow{u_r} = (
  4, 4, - 1 )$, $\vec{u}_s = ( 1, 2, 0 )$, y calculamos su producto vectorial:
  
  $\overrightarrow{u_r} \wedge \vec{u}_s = ( 4, 4, - 1 ) \wedge ( 1, 2, 0 ) =
  \left|\begin{array}{ccc}
    \vec{i} & \vec{j} & \vec{k}\\
    4 & 4 & - 1\\
    1 & 2 & 0
  \end{array}\right| = 2 \vec{i} - \vec{j} + 4 \vec{k} = ( 2, - 1, 4 )$
  
  La perpendicular común es:
  
  $t : \left\{\begin{array}{l}
    \det ( \overrightarrow{A_r X}, \vec{u}_r, \vec{u}_r \wedge \vec{u}_s ) =
    0\\
    \det ( \overrightarrow{A_s X}, \vec{u}_s, \vec{u}_r \wedge \vec{u}_s ) = 0
  \end{array}\right. \Leftrightarrow \left\{\begin{array}{l}
    \left|\begin{array}{ccc}
      x - 1 & y & z\\
      4 & 4 & - 1\\
      2 & - 1 & 4
    \end{array}\right| = 0\\
    \left|\begin{array}{ccc}
      x - 1 & y - 1 & z - 2\\
      1 & 2 & 0\\
      2 & - 1 & 4
    \end{array}\right| = 0
  \end{array}\right. \Leftrightarrow \left\{\begin{array}{l}
    5 x - 6 y - 4 z - 5 = 0\\
    8 x - 4 y - 5 z + 6 = 0
  \end{array}\right.$
  
  Utilizando los puntos de corte de la perpendicular común. Escribimos $r$ en
  paramétricas:
  
  $r : x - 1 = y = - 4 z \Leftrightarrow \dfrac{x - 1}{4} = \dfrac{y}{4} =
  \dfrac{z}{- 1} \Leftrightarrow \left\{\begin{array}{l}
    x = 1 + 4 \mu\\
    y = 4 \mu\\
    z = - \mu
  \end{array}\right.$
  
  Punto de corte con $r$: $P_r ( 1 + 4 \mu, 4 \mu, - \mu )$. Punto de corte
  con $s$: $P_s ( 1 + \lambda, 1 + 2 \lambda, 2 )$.
  
  Hallamos el vector $\overrightarrow{P_r P_s} = ( 1 + \lambda, 1 + 2 \lambda,
  2 ) - ( 1 + 4 \mu, 4 \mu, - \mu ) = ( \lambda - 4 \mu, 1 + 2 \lambda - 4
  \mu, 2 + \mu )$.
  
  Este vector ha de ser ortogonal a $r$ y a $s$:
  
  $\overrightarrow{P_r P_s} \cdot \vec{u}_r = 0 \Leftrightarrow ( \lambda - 4
  \mu, 1 + 2 \lambda - 4 \mu, 2 + \mu ) \cdot ( 4, 4, - 1 ) = 0
  \Leftrightarrow 12 \lambda - 33 \mu + 2 = 0$
  
  $\overrightarrow{P_r P_s} \cdot \vec{u}_s = 0 \Leftrightarrow ( \lambda - 4
  \mu, 1 + 2 \lambda - 4 \mu, 2 + \mu ) \cdot ( 1, 2, 0 ) = 0 \Leftrightarrow
  5 \lambda - 12 \mu + 2 = 0$
  
  Resolvemos el sistema anterior: $\lambda = - 2 ; \mu = - 2 / 3 \Rightarrow
  A_r ( - 5 / 3, - 8 / 3, 2 / 3 ), A_s ( - 1, - 3, 2 )$
  
  La recta $t$ es la que pasa por $A_s$ y $A_r$: $t : ( x, y, z ) = ( - 1, -
  3, 2 ) + k ( 2, - 1, 4 )$.
\end{example}


\part{Análisis}

\chapter{Límites y Continuidad}

\newpage\section{Concepto de límite}

\begin{definition}[Límite (finito) de una función en un punto]
  El límite de una función $f$ en un punto $x_0$ (o cuando $x$ tiende a $x_0$) es el valor al que se aproxima la función cuando $x$ se aproxima a $x_0$. Se representa por $\limite{x}{x_0}{f}$.
\end{definition}

\begin{example}
  Sea la función $f(x)=\dfrac{\ln{x+1}}{x}$. ¿A qué valor se aproxima $f(x)$ cuando $x$ se aproxima a $0$? Dicho valor será el límite de $f$ en $0$, es decir, $\limite{x}{0}{\dfrac{\ln{x+1}}{x}}$. Vamos a tratar de intuir ese valor calculando valores de $f(x)$ para valores de $x$ próximos a $0$:
\[\begin{array}{c|c|c|c|c|c|c|c|c}x&-0.5&-0.1&-0.01&-0.001&0.001&0.01&0.1&0.5\\ \hline
    f(x)&1.3862&1.0536&1.005&1.0005&0.9995&0.995&0.9531&0.8109\end{array}\]
Como puede apreciarse, conforme $x$ se va aproximando a $0$, $f(x)$ se va aproximando a $1$. Parece que $\limite{x}{0}{f}=1$.

La gráfica de esta función (figura~\ref{fig:limites1}) nos confirma esa sospecha.

\begin{figure}[hb]
\centering
\includegraphics[width=12cm]{limites1_cropped.pdf}
\caption{Límite de una función en un punto.}
\label{fig:limites1}
\end{figure}

\end{example}

\begin{remark}
  Esta es una definición poco formal, en la que <<se aproxima>> hay que entenderlo en el sentido de <<se aproxima infinitamente>> o <<se aproxima tanto como se quiera>>. Así, por ejemplo, para $f(x)=x^2$, se podría decir que cuando $x$ <<se aproxima>> a $0$ <<$f(x)$ se aproxima>> a $-1$, pero no <<se aproxima infinitamente>> o <<tanto como queramos>>, ya que $f(x)$ nunca valdrá menos de $0$, es decir, nunca se aproximará a menos de 1 unidad de distancia a $-1$. Sin embargo, sí podemos decir que cuando $x$ <<se aproxima>> a $0$, $f(x)$ <<se aproxima>> a $0$ <<tanto como queramos>>, ya que podremos encontrar un punto de $f(x)$ tan próximo a $0$ como deseemos, con tal de tomar un valor para $x$ suficientemente próximo a $0$.
\end{remark}

\begin{remark}
  Este concepto puede definirse formalmente del siguiente modo. Se dice que el límite de una función $f$ en un punto $x_0$ es $L$ si para todo $\epsilon > 0$ existe algún $\delta >0$ tal que si $|x-x_0|<\delta$ entonces $|f(x)-L|<\epsilon$. Se representa $\limite{x}{x_0}{f}=L$.
\end{remark}

\begin{remark}
  El límite de una función en un punto, si existe, es único.
\end{remark}

\begin{remark}
  Habitualmente, el límite de una función en un punto coincide con el valor de la función en ese punto. Lógicamente, la función se acerca al valor que finalmente alcanza. Cuando no ocurre así, es porque hay algún tipo de <<rareza>> en la definición de la función. Así ocurre, por ejemplo, en la función de la figura~\ref{fig:limites2}, cuya ecuación es:

\[f(x)=\left\{\begin{array}{ll}-x^2+4x&\text{si }x\neq2\\6&\text{si }x=2\end{array}\right.\]

\begin{figure}[hbt]
\centering
\includegraphics[width=12cm]{limites2_cropped.pdf}
\caption[El límite es distinto del valor de la función.]{El límite es distinto del valor de la función: \ensuremath{f(x)=\left\{\begin{array}{ll}-x^2+4x & x\neq2 \\ 6 & x=2\end{array}\right.}.}
\label{fig:limites2}
\end{figure}

En esta función:

\[f(2)=6;\hspace{1cm}\limite{x}{2}{f}=\limite{x}{2}{-x^2+4x}=-2^2+4\cdot 2=4\]

Por eso, para hallar el límite de una función en un punto, lo que hacemos normalmente es calcular el valor que dicha función tiene en dicho punto. Las herramientas de cálculo de límites serán útiles solo para hallar límites en puntos <<raros>>, es decir, en puntos en los que la función no está definida, o lo está de forma <<rara>>.
\end{remark}

\begin{remark}
  En el ejemplo de la figura~\ref{fig:limites2} se muestra también que el valor de la función en el punto no influye en el valor del límite. El límite habría sido el mismo con independencia de la altura a la que hubiésemos colocado el punto correspondiente a $x=2$. El límite se refiere solo a lo que sucede muy cerca del punto, pero no dice nada sobre lo que ocurre en el punto mismo.
\end{remark}

\begin{definition}[Límite infinito de una función en un punto]
  Se dice que el límite de una función $f$ en un punto $x_0$ es infinito cuando la función crece tanto como queramos cuando $x$ se acerca a $x_0$. Se representa $\limite{x}{x_0}{f}=\infty$. Se dice que el límite es $-\infty$ cuando la función decrece tanto como queramos.
\end{definition}

\begin{example}
  El límite de $f(x)=\dfrac{1}{x^2}$ en $x=0$ es infinito: $\limite{x}{0}{\dfrac{1}{x^2}}=\infty$, ya que al aproximarse $x$ a $0$, $f(x)$ crece <<tanto como queramos>> (figura~\ref{fig:limites6}).

\begin{figure}
\centering
\includegraphics[width=12cm]{limites6_cropped.pdf}
\caption{Límite infinito en un punto: $f(x)=\dfrac{1}{x^2}$}
\label{fig:limites6}
\end{figure}

\end{example}

\begin{remark}
  En realidad, cuando el límite de una función es $\infty$, lo que ocurre es que no tiene límite, es decir, que crece sin límite, en las proximidades de un punto. Cuando se dice que una función no tiene límite en un punto, a veces se dice de forma estricta, significando que no tiene un límite finito, y otras se dice de forma más amplia, significando que no tiene ningún comportamiento que podamos describir con una de las dos nociones de límite estudiadas hasta ahora (límite finito y límite infinito en un punto). Por ejemplo, en algunos casos se dirá que $f(x)=1/x^2$ no tiene límite en $x=0$, mientras que en otros casos se dirá que sí tiene límite, pero que es $\infty$. Cuando digamos que una función no tiene límite, tendremos que precisar si nos referimos a que no tiene límite finito, o a que no tiene límite de ningún tipo.

En la figura~\ref{fig:limites3} se muestran ejemplos de funciones que no tienen límite en un punto, ni siquiera en el sentido amplio de límite infinito.

\begin{figure}
\centering
\subfloat[$f(x)=\sqrt{x^2-1}$]{
\label{fig:limites3:a}
\includegraphics[width=7cm]{limites3_cropped.pdf}}
\hspace{1cm}
\subfloat[$g(x)=\sin{\dfrac{1}{x}}$]{
\label{fig:limites3:b}
\includegraphics[width=7cm]{limites4_cropped.pdf}}
\caption{Funciones que no tienen límite en un punto, ni finito ni infinito.}
\label{fig:limites3}
\end{figure}

La función $f$ no tiene límite en $0$, porque no hay función en torno a ese punto. La función no se aproxima a ningún valor cuando $x$ se aproxima a $0$ porque cuando $x$ se aproxima a $0$, no hay función. El dominio de $f$ es $(-\infty,-1]\cup[1,\infty)$.

La función $g$ no tiene límite en $0$ porque al aproximarse $x$ a $0$, la función oscila infinitamente entre $-1$ y $1$, con oscilaciones cada vez más <<estrechas>>.
\end{remark}

\begin{remark}
  La definición formal de límite infinito en un punto es la siguiente. Se dice que el límite de una función $f$ en un punto $x_0$ es infinito si para todo $M$ existe algún $\delta >0$ tal que si $|x-x_0|<\delta$ entonces $f(x)>M$. Se representa así: $\limite{x}{x_0}{f}=\infty$. Se dice que el límite de una función $f$ en un punto $x_0$ es menos infinito si para todo $M$ existe algún $\delta>0$ tal que si $|x-x_0|<\delta$ entonces $f(x)<M$. Se representa así: $\limite{x}{x_0}{f}=-\infty$.
\end{remark}

\begin{definition}
  [Límites laterales] Se llaman límites laterales, por la derecha y por la izquierda, respectivamente, de una función $f$ en un punto $x_0$ a los valores a los que se aproxima la función cuando $x$ se aproxima a $x_0$, por la derecha y por la izquierda, respectivamente. Se representan por: $\limite{x}{x_0^+}{f}$ el límite por la derecha, y $\limite{x}{x_0^-}{f}$ al límite por la izquierda.
\end{definition}

\begin{remark}
  Los límites laterales pueden ser finitos o infinitos, o no existir.
\end{remark}

\begin{figure}
\centering
\subfloat{\label{fig:limites5:a}
\includegraphics[width=7cm]{limites5_cropped.pdf}}
\hspace{1cm}
\subfloat{\label{fig:limites5:b}
\includegraphics[width=7cm]{limites5b_cropped.pdf}}\\
\subfloat{\label{fig:limites5:c}
\includegraphics[width=7cm]{limites5c_cropped.pdf}}
\hspace{1cm}
\subfloat{\label{fig:limites5:d}
\includegraphics[width=7cm]{limites7_cropped.pdf}}
\caption{Límites laterales}
\label{fig:limites5}
\end{figure}

\begin{remark}
  La definición formal de los límites laterales sería la siguiente:

  \begin{itemize}
  \item $\limite{x}{x_0^-}{f}=L \iff \left(\forall \epsilon > 0 \exists \delta > 0,0<x_0-x<\delta \Rightarrow |f(x)-L|<\epsilon\right)$
  \item $\limite{x}{x_0^+}{f}=L \iff \left(\forall \epsilon > 0 \exists \delta > 0,0<x-x_0<\delta \Rightarrow |f(x)-L|<\epsilon\right)$
  \item $\limite{x}{x_0^-}{f}=\infty \iff \left(\forall M > 0 \exists \delta > 0,0<x_0-x<\delta \Rightarrow f(x)>M\right)$
  \item $\limite{x}{x_0^+}{f}=\infty \iff \left(\forall M > 0 \exists \delta > 0,0<x-x_0<\delta \Rightarrow f(x)>M\right)$
  \item $\limite{x}{x_0^-}{f}=-\infty \iff \left(\forall M < 0 \exists \delta > 0,0<x_0-x<\delta \Rightarrow f(x)<M\right)$
  \item $\limite{x}{x_0^+}{f}=-\infty \iff \left(\forall M < 0 \exists \delta > 0,0<x-x_0<\delta \Rightarrow f(x)<M\right)$
  \end{itemize}
\end{remark}

\begin{theorem}[Teorema de existencia del límite]
  El límite de una función en un punto existe si y solamente si existen los límites laterales y son iguales. En ese caso el límite es igual a los límites laterales.
\end{theorem}

\begin{remark}
  El teorema anterior se puede interpretar en el sentido estricto de existencia de límites, para límites finitos, y también en sentido amplio, para límites infinitos.
\end{remark}

\begin{definition}
  [Límites en el infinito] El límite de una función $f$ en el infinito es el valor al que se aproxima la función cuando $x$ crece indefinidamente. Se representa por $\limite{x}{\infty}{f}$. El límite de una función $f$ en menos infinito es el valor al que se aproxima la función cuando $x$ decrece indefinidamente. Se representa por $\limite{x}{-\infty}{f}$.
\end{definition}

\begin{remark}
  Los límites en el infinito pueden ser finitos o infinitos. En el segundo caso, en la definición anterior, la expresión <<$f$ se aproxima a $\infty$>> hay que interpretarlo en el sentido de que $f$ crece <<tanto como queramos>>.
\end{remark}

\begin{figure}
\centering
\subfloat{\label{fig:limites8:a}
\includegraphics[width=8cm]{limites8_cropped.pdf}}
\hspace{1cm}
\subfloat{\label{fig:limites8:b}
\includegraphics[width=8cm]{limites8b_cropped.pdf}} \\
\subfloat{\label{fig:limites8:c}
\includegraphics[width=8cm]{limites8c_cropped.pdf}}
\hspace{1cm}
\subfloat{\label{fig:limites8:d}
\includegraphics[width=8cm]{limites8d_cropped.pdf}} \\
\subfloat{\label{fig:limites8:e}
\includegraphics[width=8cm]{limites8e_cropped.pdf}}
\hspace{1cm}
\subfloat{\label{fig:limites8:f}
\includegraphics[width=8cm]{limites8f_cropped.pdf}}
\caption{Límites en el infinito.}
\label{fig:limites8}
\end{figure}

\begin{remark}
  Las definiciones formales de estos límites serían las siguientes.

  \begin{itemize}
  \item $\limite{x}{\infty}{f}=L \iff \left(\forall \epsilon > 0, \exists x_0, x \geq x_0 \Rightarrow |f(x)-L|<\epsilon\right)$
  \item $\limite{x}{-\infty}{f}=L \iff \left(\forall \epsilon > 0, \exists x_0, x \leq x_0 \Rightarrow |f(x)-L|<\epsilon\right)$
  \item $\limite{x}{\infty}{f}=\infty \iff \left(\forall M, \exists x_0, x \geq x_0 \Rightarrow f(x)>M\right)$
  \item $\limite{x}{-\infty}{f}=\infty \iff \left(\forall M, \exists x_0, x \leq x_0 \Rightarrow f(x)>M\right)$
  \item $\limite{x}{\infty}{f}=-\infty \iff \left(\forall M, \exists x_0, x \geq x_0 \Rightarrow f(x)<M\right)$
  \item $\limite{x}{-\infty}{f}=-\infty \iff \left(\forall M, \exists x_0, x \leq x_0 \Rightarrow f(x)<M\right)$
  \end{itemize}

\end{remark}



\newpage\section{Cálculo de límites}

\begin{theorem}
  El límite de una función elemental en cualquier punto interior de su dominio es igual al valor de la función en dicho punto.
\end{theorem}

\begin{remark}
  Según el teorema anterior, para calcular el límite de cualquier función elemental en cualquier punto interior de su dominio no tenemos más que calcular el valor de la función en dicho punto.
\end{remark}

\begin{remark}
  Se llama \emph{funciones elementales} a las siguientes funciones, y a todas las combinaciones de las mismas mediante las operaciones de suma, producto, cociente y composición.

\begin{itemize}
\item Función constante: $f(x)=k$.
\item Función identidad: $f(x)=x$.
\item Función raíz enésima: $f(x)=\sqrt[n]{x},n\in\mathbb{N}$.
\item Función exponencial: $f(x)=a^x,a>0$.
\item Función logaritmo: $f(x)=\log_b(x),b>0,b\neq1$.
\item Funciones trigonométricas: $f(x)=\sin x;f(x)=\cos x$.
\item Funciones trigonométricas inversas: $f(x)=\sin^{-1}x;f(x)=\cos^{-1}x$.
\end{itemize}

Esta definición incluye las funciones algebraicas (los polinomios, las funciones racionales y las funciones irracionales), además de las funciones trascendentes (exponenciales, logarítmicas, trigonométricas y trigonométricas inversas). Las únicas funciones no elementales con las que vamos a trabajar son las funciones definidas a trozos y la exponencial-potencial, $f(x)^{g(x)}$.
\end{remark}

\begin{remark}
  Se dice que un punto es interior de un conjunto $A$ cuando existe algún entorno de dicho punto que está completamente contenido en el conjunto $A$. Es decir, se trata de todos los puntos del conjunto excepto los puntos que están en la frontera del mismo. En $\mathbb{R}$, si $A$ es un intervalo abierto, todos sus puntos son interiores, y si $A$ es un intervalo cerrado $[a,b]$, entonces son interiores todos los puntos excepto $a$ y $b$.

Los dominios de todas las funciones elementales son intervalos o uniones de intervalos. Por tanto, para calcular el límite de cualquier función elemental en un punto que no sea extremo de alguno de los intervalos que forman el dominio, solo tenemos que calcular el valor de la función en dicho punto. Además, la mayoría de las funciones elementales tienen dominios formados por intervalos abiertos. Las únicas funciones cuyos dominios tienen puntos frontera dentro del dominio son las raíces de índice par y las trigonométricas inversas.

Con este teorema podemos calcular, por tanto, cualquier límite de una función elemental en cualquier punto interior de su dominio. Los restantes teoremas de esta sección nos dirán cómo calcular límites de funciones elementales en puntos frontera del dominio (para el caso de raíces de índice par), en puntos exteriores al dominio y en el infinito. También veremos cómo calcular límites de funciones definidas a trozos y de la exponencial-potencial.
\end{remark}

\begin{remark}
  El teorema anterior es en realidad un corolario práctico de los siguientes teoremas más generales.

\bigskip
  Teorema. Dadas dos funciones cualesquiera, $f$ y $g$, si $\limite{x}{a}{f}$ y $\limite{x}{a}{g}$, existen y son finitos, entonces:
  \begin{itemize}
  \item El límite en $a$ de la suma de $f$ y $g$ existe, y es igual a la suma de los límites: $\limite{x}{a}{f+g}=\limite{x}{a}{f}+\limite{x}{a}{g}$.
  \item El límite en $a$ del producto de $f$ y $g$ existe, y es igual al producto de los límites: $\limite{x}{a}{fg}=\limite{x}{a}{f}\limite{x}{a}{g}$.
  \item Si, además, $\limite{x}{a}{g}\neq0$, entonces el límite del cociente de $f$ entre $g$ existe, y es igual al cociente de los límites: $\limite{x}{a}{\dfrac{f}{g}}=\dfrac{\limite{x}{a}{f}}{\limite{x}{a}{g}}$.
  \end{itemize}

\bigskip
  Teorema. Dadas dos funciones cualesquiera, $f$ y $g$,tales que $\limite{x}{a}{g}=L$ y $\limite{x}{L}{f}=M$, entonces el límite en $a$ de la composición $f\circ g$ existe y vale $M$: $\limite{x}{a}{f\circ g}=\limite{x}{\limite{x}{a}{g}}{f}$.

\bigskip
  Teorema.
  \begin{itemize}
  \item Función constante: $\limite{x}{a}{k}=k$.
  \item Función identidad: $\limite{x}{a}{x}=a$.
  \item Función raíz: $\limite{x}{a}{\sqrt[n]{x}}=\sqrt[n]{a}$, si $n$ es impar; $\limite{x}{a}{\sqrt[n]{x}}=\sqrt[n]{a}$ para todo $a>0$, si $n$ es par.
  \item Función logaritmo: $\limite{x}{a}{\log_b{x}}=\log_b{a}$, para todo $a>0$.
  \item Función exponencial: $\limite{x}{a}{b^x}=b^a$.
  \item Funciones trigonométricas: $\limite{x}{a}{\sin x}=\sin a$; $\limite{x}{a}{\cos x}=\cos a$.
  \item Funciones trigonométricas inversas: $\limite{x}{a}{\sin^{-1}x}=\sin^{-1}a$, para todo $a\in(-1,1)$; $\limite{x}{a}{\cos^{-1}x}=\cos^{-1}a$, para todo $a\in(-1,1)$.
  \end{itemize}
\end{remark}

\begin{theorem}[Reglas de cálculo con infinito]
  Para calcular límites en el infinito, o cuando el límite de una parte de la expresión sea infinito, se pueden aplicar las siguientes \emph{reglas de cálculo con infinito}. En estas reglas, $k$ representa a un número real cualquiera.
  \begin{itemize}
  \item Suma:
$$\infty+\infty=\infty;\hspace{1cm}-\infty+(-\infty)=-\infty;\hspace{1cm}k+\infty=\infty;\hspace{1cm}k-\infty=-\infty.$$
  \item Producto:
$$\infty\cdot\infty=\infty;\hspace{1cm}-\infty\cdot\infty=\infty\cdot (-\infty)=-\infty;\hspace{1cm}-\infty\cdot(-\infty)=\infty;$$
$$k\cdot\infty=\left\{\begin{array}{ll}\infty&\text{si }k>0\\-\infty&\text{si }k<0\end{array}\right.;\hspace{1cm} k\cdot(-\infty)=\left\{\begin{array}{ll}-\infty&\text{si }k>0\\\infty&\text{si }k<0\end{array}\right..$$
  \item Cociente:
$$\dfrac{k}{\pm\infty}=0;\hspace{1cm}\dfrac{k}{0^+}=\left\{\begin{array}{ll}\infty&\text{si }k>0\\-\infty&\text{si }k<0\end{array}\right.; \dfrac{k}{0^-}=\left\{\begin{array}{ll}-\infty&\text{si }k>0\\\infty&\text{si }k<0\end{array}\right..$$
  \item Composición:
$$f(\infty)=\limite{x}{\infty}{f};\hspace{1cm}f(-\infty)=\limite{x}{-\infty}{f}.$$
  \end{itemize}
\end{theorem}

\begin{remark}
Ya hemos visto que las expresiones $0^+$ y $0^-$ pueden utilizarse para representar que $x$ tiende a $0$ por la derecha y por la izquierda, respectivamente. Con este significado sólo pueden usarse como parte de la expresión $\limite{x}{0^+}{f}$ o $\limite{x}{0^-}{f}$. Sin embargo, a veces, las expresiones anteriores se abrevian así: $f(0^+)$ y $f(0^-)$.

  La expresión $0^+$ también pueden representar al límite nulo de una función en un punto $a$ tal que existe algún entorno de $a$ en el que la función es positiva, o bien, al límite lateral nulo de una función en un punto $a$ tal que existe algún intervalo $(a,a+\delta)$, si el límite es por la derecha, o $(a-\delta,a)$, si el límite es por la izquierda, en el que la función es positiva. Análogamente, la expresión $0^-$ puede representar al límite nulo de una función que se aproxima a un punto, por la derecha, por la izquierda o por ambos lados, con valores exclusivamente negativos. También se puede utilizar para límites en el infinito, entiendiendo que la función se acerca a $0$ en el infinito, pero de modo que a partir de determinado punto, todos los valores de la función son positivos (para $0^+$) o negativos (para $0^-$). Así, por ejemplo, podríamos decir que $\limite{x}{0}{x^2}=0^+$ y que $\limite{x}{-\infty}{1/x}=0^-$, y que $\limite{x}{-\infty}{e^x}=0^+$.
\end{remark}

\begin{remark}
  Para entender bien las reglas anteriores conviene recordar que se trata solo de reglas de cálculo de límites. No hay ningún número que se llame $\infty$. Por tanto, una expresión como $\infty\cdot\infty$, no representa al producto de dos números, sino más bien al límite del producto de dos funciones cuyos límites son infinitos.
\end{remark}

\begin{remark}
  Cada una de las anteriores reglas de cálculo se podría escribir de forma rigurosa como un teorema. Daremos solo un ejemplo. La regla según la cual $\infty+\infty=\infty$ se corresponde con el teorema siguiente: dadas dos funciones $f$ y $g$, si $\limite{x}{a}{f}=\infty$ y $\limite{x}{a}{g}=\infty$, entonces $\limite{x}{a}{(f+g)}=\infty$.
\end{remark}

\begin{theorem}
  [Límites infinitos y en el infinito de las funciones elementales y de la doble exponencial] En el cálculo de límites se pueden aplicar las siguientes reglas:
  \begin{itemize}
  \item Polinomios: los límites en el infinito de un polinomio son iguales a los límites en el infinito de su monomio de mayor grado.
  \item Logaritmo:
$$\log_b0^+=\left\{\begin{array}{ll}\infty&\text{si }0<b<1\\-\infty&\text{si }b>1\end{array}\right.;\hspace{1cm} \log_b\infty=\left\{\begin{array}{ll}-\infty&\text{si }0<b<1\\\infty&\text{si }b>1\end{array}\right.$$
  \item Exponencial y doble exponencial:
$$a^{-\infty}=\left\{\begin{array}{ll}\infty&\text{si }0<a<1\\0^+&\text{si }a>1\end{array}\right.;\hspace{1cm} a^{\infty}=\left\{\begin{array}{ll}0^+&\text{si }0<a<1\\\infty&\text{si }a>1\end{array}\right.;$$
$$\infty^\infty = \infty;\hspace{1cm} \infty^{-\infty}=0^+;\hspace{1cm}(0^+)^\infty=0^+.$$
  \item Trigonométricas:
    \[\nexists \sen (\pm\infty);\ \nexists \cos (\pm\infty);\ \nexists \tg (\pm\infty)\]
    \[\tg \left((2k+1)\dfrac{\pi}{2}\right)^- = \infty;\ \tg \left((2k+1)\dfrac{\pi}{2}\right)^+ = -\infty;\]
  \item Trigonométricas inversas: $\limite{x}{\infty}{\arctg x} = \dfrac{\pi}{2}$; $\limite{x}{-\infty}{\arctg x} = -\dfrac{\pi}{2}$
  \end{itemize}
\end{theorem}

\begin{remark}
  También las <<fórmulas>> anteriores son en realidad una forma abreviada de expresar teoremas sobre límites:

  \begin{itemize}
  \item Polinomios: $\limite{x}{\pm\infty}{a_nx^n+a_{n-1}x^{n-1}\hdots+a_1x+a_0}=\limite{x}{\pm\infty}{a_nx^n}$.
  \item Logaritmo: $\limite{x}{0^+}{\log_bx}=\left\{\begin{array}{ll}\infty&\text{si }0<b<1\\-\infty&\text{si }b>1\end{array}\right.$; $\limite{x}{\infty}{\log_bx}=\left\{\begin{array}{ll}-\infty&\text{si }0<b<1\\\infty&\text{si }b>1\end{array}\right.$
  \item Exponencial: $\limite{x}{-\infty}{a^x}=\left\{\begin{array}{ll}\infty&\text{si }0<a<1\\0^+&\text{si }a>1\end{array}\right.$; $\limite{x}{\infty}{a^x}=\left\{\begin{array}{ll}0^+&\text{si }0<a<1\\\infty&\text{si }a>1\end{array}\right.$
  \end{itemize}
\end{remark}

\begin{remark}
  Si se repasan todas las reglas de cálculo de límites dadas hasta ahora se observará que hay algunos casos no contemplados. Así, por ejemplo, en las reglas para el producto de infinitos, vimos que $k\cdot\infty=\infty$ si $k>0$, y $k\cdot\infty=-\infty$ si $k<0$, pero ¿qué pasa si $k=0$? Estos casos no contemplados en las reglas generales son las llamadas <<indeterminaciones>>.
\end{remark}

\begin{definition}
  [Indeterminaciones] Se llama así a expresiones obtenidas en el proceso de cálculo de límites, que no tienen un valor determinado, en el sentido de que límites con distintos valores pueden llevar a la misma expresión al sustituir $x$ por el valor al que tiende, y evaluar la expresión obtenida, de acuerdo con las reglas dadas hasta ahora. Dichas indeterminaciones son las siguientes:

\[\dfrac{0}{0};\hspace{0.5cm}\dfrac{k}{0},\,k\neq0;\hspace{0.5cm}\dfrac{\pm\infty}{\pm\infty};\hspace{0.5cm}\infty-\infty;\hspace{0.5cm}0\cdot(\pm\infty);\hspace{0.5cm}1^{\pm\infty};\hspace{0.5cm}(0^+)^0;\hspace{0.5cm}\infty^0\]
\end{definition}

\begin{example}
  Tal como se vio al principio, $\limite{x}{0}{\dfrac{\ln(x+1)}{x}}=1$. Si aplicamos las reglas de cálculo de límites estudiadas hasta ahora, para calcular ese límite, procederíamos del siguiente modo. En primer lugar, pensaríamos que se trata de una función elemental, ya que es el cociente de dos funciones elementales, una función logarítmica y la identidad. Por lo tanto, con la confianza de poder aplicar el primer teorema de cálculo de límites, calcularíamos el valor de la función en el punto en el que queremos hallar el límite:
\[\limite{x}{0}{\dfrac{\ln(x+1)}{x}}=\dfrac{\ln(0+1)}{0}=\dfrac{\ln1}{0}=\dfrac{0}{0}\]
Encontramos que $0$ no está en el dominio de la función, ya que en ese punto el denominador se anula. Además, hemos obtenido una \emph{indeterminación} $\dfrac{0}{0}$, es decir, una expresión para la que tampoco hemos estudiado ninguna regla en los teoremas de cálculo de límites infinitos. Así que, tendríamos que concluir que no sabemos cuánto vale el límite. Sin embargo, según vimos al comienzo de esta sección, ese límite vale 1 (aunque, en realidad, solo intuimos que ese es el límite, calculando valores de la función en puntos muy próximos a 0). ¿Cómo se puede demostrar que ese es el valor del límite? Lo estudiaremos más adelante.

Trataremos ahora de calcular este otro límite: $\limite{x}{2}{\dfrac{x-2}{x^2-4}}$. Procedemos del mismo modo. Se trata de una función racional, por tanto, elemental. Intentamos calcular el valor de la función en $x=2$, pero vemos que precisamente ese punto está fuera del dominio, ya que anula el denominador:
\[\limite{x}{2}{\dfrac{x-2}{x^2-4}}=\dfrac{2-2}{2^2-4}=\dfrac{0}{0}\]
Hemos obtenido la misma expresión que antes, la indeterminación $\dfrac{0}{0}$. Podríamos hacer lo mismo que hicimos en el caso anterior, y dar valores a $x$ próximos a $2$ para ver cuál es el límite. Sin embargo, en este caso haremos otra cosa. Vamos a simplificar la expresión de la función:
\[\dfrac{x-2}{x^2-4}=\dfrac{x-2}{(x+2)(x-2)}=\dfrac{1}{x+2},\forall x\neq2\]
La simplificación es válida para todo $x\neq2$, pero como el límite en $x=2$ es independiente del valor de la función en $x=2$, podemos calcular el límite utilizando la expresión simplificada. Como es una función elemental (racional), y $2$ es un punto interior del dominio, el límite será igual al valor de la función en el punto:
\[\limite{x}{2}{\dfrac{x-2}{x^2-4}}=\limite{x}{2}{\dfrac{1}{x+2}}=\dfrac{2}{2+2}=\dfrac{1}{2}\]
Esta es la razón por la que a la expresión $\dfrac{0}{0}$ se le llama indeterminación: tanto en un límite como en el otro habíamos llegado a la misma expresión $\dfrac{0}{0}$, pero el primer límite valía 1 y el segundo $\dfrac{1}{2}$. Así pues, no es posible saber cuál será el verdadero valor del límite partiendo solo de la expresión $\dfrac{0}{0}$.
\end{example}

\begin{theorem}
  [Resolución de indeterminaciones] Algunas reglas para la resolución de indeterminaciones son las siguientes:
  \begin{itemize}
  \item Indeterminación $\dfrac{k}{0},k\neq0$.

Esta indeterminación puede resolverse calculando los límites laterales, y comparándolos. El resultado será siempre, $\infty$, $-\infty$, o que no existe el límite, por ser distintos los límites laterales. Los límites laterales serán siempre infinitos.

  \item Indeterminación $\dfrac{0}{0}$.

Para funciones racionales, esta indeterminación se resuelve factorizando el numerador y el denominador, y simplificando los factores comunes.

Para funciones irracionales, esta indeterminación se resuelve racionalizando (eliminando la expresión irracional que se anula), habitualmente multiplicando numerador y denominador por la expresión conjugada de la expresión irracional que se anula.

Para funciones trascendentes, esta indeterminación se resuelve aplicando sustitución de infinitésimos equivalentes (siguiente sección) o la regla de L'Hôpital (tema siguiente).

  \item Indeterminación $\dfrac{\infty}{\infty}$.

Para funciones racionales o irracionales, se resuelve dividiendo numerador y denominador por $x^n$, siendo $n$ el grado del denominador (entiéndase, para un denominador irracional, que el grado es el mayor exponente de $x$, aun cuando sea fraccionario). Para funciones racionales puede aplicarse la regla siguiente: si el grado del numerador es mayor que el grado del denominador, el límite es $\pm\infty$ (el signo se determina dividiendo los signos de numerador y denominador); si el grado del numerador es menor que el del denominador, el límite es 0; si los grados son iguales, el límite es el cociente de los coeficientes principales del numerador y el denominador.

Para funciones trascendentes, se resuelve aplicando sustitución de infinitésimos equivalentes (siguiente sección), o la regla de L'Hôpital (tema siguiente).

  \item Indeterminación $\infty-\infty$.

Para funciones racionales, se resuelve reduciendo la expresión a una única fracción algebraica.

Para funciones irracionales, se resuelve multiplicando y dividiendo por la expresión conjugada.

Para funciones trascendentes se resuelve según el <<esquema>> siguiente:
\[f-g=f\left(1-\dfrac{g}{f}\right)\]
La expresión obtenida puede ser una interminación $\infty\cdot 0$, que habrá que resolver según se indica abajo.

  \item Indeterminación $0\cdot\infty$.

Se resuelve convirtiéndola en una indeterminación $\dfrac{\infty}{\infty}$ o $\dfrac{0}{0}$, de este modo:
\[0\cdot \infty=0\cdot\dfrac{1}{1/\infty}=\dfrac{0}{1/\infty}=\dfrac{0}{0};\hspace{2cm}0\cdot\infty=\dfrac{1}{1/0}\cdot{\infty}=\dfrac{\infty}{1/0}=\dfrac{\infty}{\infty}\]

  \item Indeterminación $1^{\infty}$.

Se resuelve aplicando que, si $\limite{x}{a}{f}=1$ y $\limite{x}{a}{g}=\pm\infty$, entonces
$$\limite{x}{a}{f^g}=e^{\limite{x}{a}{g(f-1)}},$$
donde $a$ puede ser un número, $\infty$ o $-\infty$. También es aplicable a límites laterales.

  \item Indeterminaciones $0^0$, $\infty^0$.

Se resuelven aplicando la fórmula siguiente, que las convierte en indeterminaciones $0\cdot\infty$:
$$\limite{x}{a}{f^g}=e^{\limite{x}{a}{g\ln f}}$$

  \end{itemize}
\end{theorem}

\begin{example}

  $\underset{x \rightarrow 2}{\lim}  \frac{2 x}{x - 2} = \frac{2 \cdot 2}{2 - 2}
= \frac{4}{0}$; indeterminación $\frac{k}{0}$. Calculamos los límites
laterales:

$\underset{x \rightarrow 2^+}{\lim}  \frac{2 x}{x - 2} = \frac{2 \cdot 2^+}{2
- 2^+} = \frac{4}{0^-} = - \infty$

$\underset{x \rightarrow 2^-}{\lim}  \frac{2 x}{x - 2} = \frac{2 \cdot 2^-}{2
- 2^-} = \frac{4}{0^+} = + \infty$

Como los límites laterales son distintos, no existe el límite.
\end{example}

\begin{example}

  $\underset{x \rightarrow 2}{\lim}  \frac{2 x^2 + 2 x - 12}{3 x^2 - 5 x - 2} =
\frac{2 \cdot 2^2 + 2 \cdot 2 - 12}{3 \cdot 2^2 - 5 \cdot 2 - 2} =
\frac{0}{0}$; es una indeterminación $\frac{0}{0}$ de función racional.

Factorizamos numerador y denominador: $\left\{\begin{array}{l}
  2 x^2 + 2 x - 12 = 2 ( x - 2 ) ( x + 3 )\\
  3 x^2 - 5 x - 2 = 3 ( x - 2 ) ( x + \frac{1}{3} )
\end{array}\right.$, y simplificamos:

$\underset{x \rightarrow 2}{\lim}  \frac{2 x^2 + 2 x - 12}{3 x^2 - 5 x - 2} =
\underset{x \rightarrow 2}{\lim}  \frac{2 ( x - 2 ) ( x + 3 )}{3 ( x - 2 ) ( x
+ \frac{1}{3} )} = \underset{x \rightarrow 2}{\lim} \frac{2 ( x + 3 )}{3 ( x +
\frac{1}{3} )} = \frac{2 ( 2 + 3 )}{3 ( 2 + \frac{1}{3} )} = \frac{10}{7}$
\end{example}

\begin{example}
  $\underset{x \rightarrow 2}{\lim}  \frac{x^2 - 4}{\sqrt{2} - \sqrt{x}} =
\frac{2^2 - 4}{\sqrt{2} - \sqrt{2}} = \frac{0}{0}$; es una indeterminación
$\frac{0}{0}$ de función irracional.

Multiplicamos y dividimos por el conjugado de la expresión irracional:

$\underset{x \rightarrow 2}{\lim}  \frac{x^2 - 4}{\sqrt{2} - \sqrt{x}} =
\underset{x \rightarrow 2}{\lim}  \frac{( x^2 - 4 ) ( \sqrt{2} + \sqrt{x} )}{(
\sqrt{2} - \sqrt{x} ) ( \sqrt{2} + \sqrt{x} )} = \underset{x \rightarrow
2}{\lim}  \frac{( x^2 - 4 ) ( \sqrt{2} + \sqrt{x} )}{2 - x} =$

$\tmop{factorizamos} \tmop{el} \tmop{polinomio} x^2 - 4, y
\tmop{simplificamos},$

$= \underset{x \rightarrow 2}{\lim}  \frac{( x + 2 ) ( x - 2 ) ( \sqrt{2} +
\sqrt{x} )}{- ( x - 2 )} = \underset{x \rightarrow 2}{\lim}  \frac{( x + 2 ) (
\sqrt{2} + \sqrt{x} )}{- 1} =$

$\tmop{finalmente}, \tmop{sustituimos} x \tmop{por} \tmop{el} \tmop{valor}
\tmop{al} \tmop{que} \tmop{tiende}, 2, \tmop{para} \tmop{hallar} \tmop{el} lí
\tmop{mite},$

$= \frac{( 2 + 2 ) ( \sqrt{2} + \sqrt{2} )}{- 1} = - 8 \sqrt{2}$
\end{example}

\begin{example}

  $\underset{x \rightarrow \infty}{\lim}  \frac{5 x^2 + 6 x - 1}{x^3 - x^2 + 3
x} = \frac{\underset{x \rightarrow \infty}{\lim} ( 5 x^2 + 6 x - 1
)}{\underset{x \rightarrow \infty}{\lim} ( x^3 - x^2 + 3 x )} =
\frac{\infty}{\infty}$; es una indeterminación $\frac{\infty}{\infty}$.

Multiplicamos y dividimos numerador y denominador por $x$ elevado a su mayor
exponente respectivo, y simplificamos:

$\underset{x \rightarrow \infty}{\lim}  \frac{5 x^2 + 6 x - 1}{x^3 - x^2 + 3
x} = \underset{x \rightarrow \infty}{\lim}  \frac{x^2 \left( \frac{5 x^2}{x^2}
+ \frac{6 x}{x^2} - \frac{1}{x^2} \right)}{x^3 \left( \frac{x^3}{x^3} -
\frac{x^2}{x^3} + \frac{3 x}{x^3} \right)} = \underset{x \rightarrow
\infty}{\lim}  \frac{x^2 \left( 5 + \frac{6}{x} - \frac{1}{x^2} \right)}{x^3
\left( 1 - \frac{1}{x} + \frac{3}{x^2} \right)} = \underset{x \rightarrow
\infty}{\lim}  \frac{5 + \frac{6}{x} - \frac{1}{x^2}}{x \left( 1 - \frac{1}{x}
+ \frac{3}{x^2} \right)} =$

$= \frac{5 + \frac{6}{\infty} - \frac{1}{\infty^2}}{\infty \cdot \left( 1 -
\frac{1}{\infty} + \frac{3}{\infty^2} \right)} = \frac{5 + 0 - 0}{\infty \cdot
( 1 - 0 + 0 )} = \frac{5}{\infty} = 0$
\end{example}

\begin{example}

  $\underset{x \rightarrow - \infty}{\lim}  \frac{\sqrt[4]{3 x^4 + 2 x^2 + 1} -
1}{2 x - 1} = \frac{\underset{x \rightarrow - \infty}{\lim} ( \sqrt[4]{3 x^4 +
2 x^2 + 1} - 1 )}{\underset{x \rightarrow - \infty}{\lim} ( 2 x - 1 )} =
\frac{\infty}{- \infty}$; indeterminación $\frac{\infty}{\infty}$.

Vamos a sacar $x^4$ de la raíz (utilizamos que $\sqrt[4]{x^4} = |x|$):

$\underset{x \rightarrow - \infty}{\lim}  \frac{\sqrt[4]{3 x^4 + 2 x^2 + 1} -
1}{2 x - 1} = \underset{x \rightarrow - \infty}{\lim}  \frac{\sqrt[4]{x^4
\left( 3 + \frac{2}{x^2} + \frac{1}{x^4} \right)} - 1}{2 x - 1} = \underset{x
\rightarrow - \infty}{\lim}  \frac{|x| \sqrt[4]{3 + \frac{2}{x^2} +
\frac{1}{x^4}} - 1}{2 x - 1} =$

=(como $x \rightarrow - \infty$, consideramos $x$ negativas, luego $|x| = -
x$)$= \underset{x \rightarrow - \infty}{\lim}  \frac{- x \sqrt[4]{3 +
\frac{2}{x^2} + \frac{1}{x^4}} - 1}{2 x - 1} =$

=(procedemos como en los casos anteriores)$= \underset{x \rightarrow -
\infty}{\lim}  \frac{x \left( - \sqrt[4]{3 + \frac{2}{x^2} + \frac{1}{x^4}} -
\frac{1}{x} \right)}{x \left( 2 - \frac{1}{x} \right)} =$

=(simplificamos la $x$)$= \underset{x \rightarrow - \infty}{\lim}  \frac{-
\sqrt[4]{3 + \frac{2}{x^2} + \frac{1}{x^4}} - \frac{1}{x}}{2 - \frac{1}{x}}
=$(sustituimos por $- \infty$ para hallar el límite)=

$= \frac{- \sqrt[4]{3 + \frac{2}{( - \infty )^2} + \frac{1}{( - \infty )^4}} -
\frac{1}{- \infty}}{2 - \frac{1}{- \infty}} = \frac{- \sqrt[4]{3}}{2}$
\end{example}

\begin{example}

  $\underset{x \rightarrow \infty}{\lim} ( \sqrt{2 x^2 + x + 4} - \sqrt{2 x^2 +
3 x - 2} ) = \underset{x \rightarrow \infty}{\lim} \sqrt{2 x^2 + x + 4} -
\underset{x \rightarrow \infty}{\lim} \sqrt{2 x^2 + 3 x - 2} =$

$= \sqrt{\underset{x \rightarrow \infty}{\lim} ( 2 x^2 + x + 4 )} -
\sqrt{\underset{x \rightarrow \infty}{\lim} ( 2 x^2 + 3 x - 2 )} =
\sqrt{\underset{x \rightarrow \infty}{\lim} 2 x^2} - \sqrt{\underset{x
\rightarrow \infty}{\lim} 2 x^2} = \sqrt{\infty} - \sqrt{\infty} = \infty -
\infty$

Es una indeterminación $\infty - \infty$. Multiplicamos y dividimos por el
conjugado:

$\underset{x \rightarrow \infty}{\lim} ( \sqrt{2 x^2 + x + 4} - \sqrt{2 x^2 +
3 x - 2} ) =$

$= \underset{x \rightarrow \infty}{\lim}  \frac{( \sqrt{2 x^2 + x + 4} -
\sqrt{2 x^2 + 3 x - 2} ) ( \sqrt{2 x^2 + x + 4} + \sqrt{2 x^2 + 3 x - 2}
)}{\sqrt{2 x^2 + x + 4} + \sqrt{2 x^2 + 3 x - 2}} =$

$= \underset{x \rightarrow \infty}{\lim}  \frac{( \sqrt{2 x^2 + x + 4} )^2 - (
\sqrt{2 x^2 + 3 x - 2} )^2}{\sqrt{2 x^2 + x + 4} + \sqrt{2 x^2 + 3 x - 2}} =
\underset{x \rightarrow \infty}{\lim}  \frac{( 2 x^2 + x + 4 ) - ( 2 x^2 + 3 x
- 2 )}{\sqrt{2 x^2 + x + 4} + \sqrt{2 x^2 + 3 x - 2}} =$

$= \underset{x \rightarrow \infty}{\lim} \frac{- 2 x + 6}{\sqrt{2 x^2 + x + 4}
+ \sqrt{2 x^2 + 3 x - 2}} = \frac{\underset{x \rightarrow \infty}{\lim} ( - 2
x + 6 )}{\underset{x \rightarrow \infty}{\lim} ( \sqrt{2 x^2 + x + 4} +
\sqrt{2 x^2 + 3 x - 2} )} = \frac{- \infty}{\infty}$

Obtenemos otra indeterminación. Esta es $\frac{\infty}{\infty}$. La resolvemos
como en el ejemplo anterior:

$\underset{x \rightarrow \infty}{\lim} \frac{- 2 x + 6}{\sqrt{2 x^2 + x + 4} +
\sqrt{2 x^2 + 3 x - 2}} = \underset{x \rightarrow \infty}{\lim}  \frac{- 2 x +
6}{\sqrt{x^2 \left( 2 + \frac{1}{x} + \frac{4}{x^2} \right)} + \sqrt{x^2
\left( 2 + \frac{3}{x} - \frac{2}{x^2} \right)}} =$

$= \underset{x \rightarrow \infty}{\lim}  \frac{- 2 x + 6}{|x| \sqrt{2 +
\frac{1}{x} + \frac{4}{x^2}} + |x| \sqrt{2 + \frac{3}{x} - \frac{2}{x^2}}} =
\underset{x \rightarrow \infty}{\lim}  \frac{x \left( - 2 + \frac{6}{x}
\right)}{x \left( \sqrt{2 + \frac{1}{x} + \frac{4}{x^2}} + \sqrt{2 +
\frac{3}{x} - \frac{2}{x^2}} \right)} =$

$= \underset{x \rightarrow \infty}{\lim}  \frac{- 2 + \frac{6}{x}}{\sqrt{2 +
\frac{1}{x} + \frac{4}{x^2}} + \sqrt{2 + \frac{3}{x} - \frac{2}{x^2}}} =
\frac{- 2}{\sqrt{2} + \sqrt{2}} = \frac{- 2}{2 \sqrt{2}} = \frac{-
1}{\sqrt{2}}$

\end{example}

\begin{example}

  $\underset{x \rightarrow \infty}{\lim}  \left( \frac{2 x - 3}{2 x + 5}
\right)^{2 x + 1} = \left( \underset{x \rightarrow \infty}{\lim}  \frac{2 x -
3}{2 x + 5} \right)^{\underset{x \rightarrow \infty}{\lim} ( 2 x + 1 )}$

Calculamos cada límite por separado:

$\underset{x \rightarrow \infty}{\lim} ( 2 x + 1 ) = \underset{x \rightarrow
\infty}{\lim} 2 x = 2 \cdot \infty = \infty$

$\underset{x \rightarrow \infty}{\lim}  \frac{2 x - 3}{2 x + 5} =
\frac{\infty}{\infty} = \underset{x \rightarrow \infty}{\lim}  \frac{x \left(
2 - \frac{3}{x} \right)}{x \left( 2 + \frac{5}{x} \right)} = \underset{x
\rightarrow \infty}{\lim}  \frac{2 - \frac{3}{x}}{2 + \frac{5}{x}} = \frac{2 -
\frac{3}{\infty}}{2 + \frac{5}{\infty}} = \frac{2 - 0}{2 + 0} = \frac{2}{2} =
1$

Así pues:

$\underset{x \rightarrow \infty}{\lim} \left( \frac{2 x - 3}{2 x + 5}
\right)^{2 x + 1} = 1^{\infty}$; es una indeterminación $1^{\infty}$, que
resolvemos aplicando la fórmula:

Si $\lim f = 1$ y $\lim g = \infty$, entonces $\lim f^g = e^{\lim g \cdot ( f
- 1 )}$.

$\underset{x \rightarrow \infty}{\lim} \left( \frac{2 x - 3}{2 x + 5}
\right)^{2 x + 1} = e^{\underset{x \rightarrow \infty}{\lim} ( 2 x + 1 )
\left( \frac{2 x - 3}{2 x + 5} - 1 \right)} = e^{\underset{x \rightarrow
\infty}{\lim} ( 2 x + 1 ) \left( \frac{2 x - 3 - ( 2 x + 5 )}{2 x + 5}
\right)} = e^{\underset{x \rightarrow \infty}{\lim} ( 2 x + 1 ) \left( \frac{-
8}{2 x + 5} \right)} =$

$= e^{\underset{x \rightarrow \infty}{\lim}  \frac{- 16 x - 8}{2 x + 5}} =
e^{\underset{x \rightarrow \infty}{\lim}  \frac{x \left( - 16 - \frac{8}{x}
\right)}{x \left( 2 + \frac{5}{x} \right)}} = e^{\underset{x \rightarrow
\infty}{\lim}  \frac{- 16 - \frac{8}{x}}{2 + \frac{5}{x}}} = e^{\frac{-
16}{2}} = e^{- 8}$
\end{example}

\begin{example}

  $\underset{x \rightarrow 2}{\lim}  \frac{|x - 2|}{x^2 - 4} = \frac{|2 -
2|}{2^2 - 4} = \frac{0}{0}$. Es una indeterminación $\frac{0}{0}$.
Calcularemos límites laterales.

Según la definición de valor absoluto:

$|x - 2| = \left\{\begin{array}{l}
  x - 2, \tmop{si} x \geqslant 2\\
  - ( x - 2 ), \tmop{si} x < 2
\end{array}\right.$

Por tanto, a la hora de calcular los límites laterales, si $x$ es mayor que 2,
sustituiremos $|x - 2|$ por $x - 2$, pero si $x$ es menor que 2, sustituiremos
$|x - 2|$ por $- ( x - 2 )$:

$\underset{x \rightarrow 2^+}{\lim}  \frac{|x - 2|}{x^2 - 4} = \underset{x
\rightarrow 2^+}{\lim}  \frac{x - 2}{x^2 - 4} = \underset{x \rightarrow
2^+}{\lim}  \frac{x - 2}{( x + 2 ) ( x - 2 )} = \underset{x \rightarrow
2^+}{\lim}  \frac{1}{x + 2} = \frac{1}{2 + 2} = \frac{1}{4}$

$\underset{x \rightarrow 2^-}{\lim}  \frac{|x - 2|}{x^2 - 4} = \underset{x
\rightarrow 2^-}{\lim}  \frac{- ( x - 2 )}{x^2 - 4} = \underset{x \rightarrow
2^-}{\lim}  \frac{- ( x - 2 )}{( x + 2 ) ( x - 2 )} = \underset{x \rightarrow
2^-}{\lim}  \frac{- 1}{x + 2} = \frac{- 1}{2 + 2} = \frac{- 1}{4}$

Como los límites laterales son distintos, no existe el límite.
\end{example}

\newpage\section{Infinitésimos equivalentes}

\begin{definition}
  [Infinitésimo] Se dice que una función $f$ es un infinitésimo en $a$ si $\limite{x}{a}{f}=0$, siendo $a$ un número, o bien $\infty$ o $-\infty$.
\end{definition}

\begin{definition}
  [Infinitésimos equivalentes] Dos infinitésimos en $a$, $f$ y $g$, son equivalentes si $\limite{x}{a}{\dfrac{f}{g}}=1$.
\end{definition}

\begin{theorem}
  [Principales infinitésimos equivalentes] Los siguientes pares de funciones son infinitésimos equivalentes en 0 ($f\approx g$ significa $f$ equivalente a $g$):
  \begin{itemize}
  \item $\sin x\approx x$
  \item $tan x \approx x$
  \item $1-\cos x \approx \dfrac{x^2}{2}$
  \item $\arcsin x \approx x$
  \item $\arctan x \approx x$
  \item $e^x-1 \approx x$
  \item $\ln (x+1) \approx x$
  \item $(1+x)^n-1 \approx nx$
  \item $\sqrt[n]{1+x}-1 \approx \dfrac{x}{n}$
  \end{itemize}
\end{theorem}

\begin{theorem}
  [Sustitución de infinitésimos equivalentes] Si $f$ y $g$ son infinitésimos equivalentes en $a$, y ambos no nulos en un entorno reducido de $a$, entonces, para cualquier función $h$ se cumple:
\[\limite{x}{a}{h\cdot f}=\limite{x}{a}{h\cdot g};\hspace{1cm}\limite{x}{a}{\dfrac{h}{f}}=\limite{x}{a}{\dfrac{h}{g}}\]
Es decir, se puede sustituir un infinitésimo por su equivalente (siempre que aparezca como factor de la expresión completa).
\end{theorem}

\begin{example}
  \[\limite{x}{\infty}{x^2\ln \left(1+\dfrac{1}{x}\right)}=\infty^2\cdot\ln\left(1+\dfrac{1}{\infty}\right)=\infty\cdot\ln(1+0)=\infty\cdot\ln1=\infty\cdot0\]
Es una indeterminación $\infty\cdot0$. La transformaremos en una indeterminación $0/0$:
\[\limite{x}{\infty}{x^2\ln\left(1+\dfrac{1}{x}\right)}=\limite{x}{\infty}{\dfrac{\ln\left(1+\dfrac{1}{x}\right)}{\dfrac{1}{x^2}}}=
\dfrac{\ln\left(1+\dfrac{1}{\infty}\right)}{\dfrac{1}{\infty^2}}=\dfrac{\ln 1}{0}=\dfrac{0}{0}\]
Sustituimos:
\[y=\dfrac{1}{x}\]
De modo que:
\[\limite{x}{\infty}{y}=\limite{x}{\infty}{\dfrac{1}{x}}=\dfrac{1}{\infty}=0^+\]
Así, pues:
\[\limite{x}{\infty}{\dfrac{\ln\left(1+\dfrac{1}{x}\right)}{\dfrac{1}{x^2}}}=\limite{y}{0^+}{\dfrac{\ln\left(1+y\right)}{y^2}}\]
Pero, $\ln(1+y)$ es un infinitésimo equivalente a $y$ en $0$, luego, podemos sustituir $\ln(1+y)$ por $y$:
\[\limite{y}{0^+}{\dfrac{\ln\left(1+y\right)}{y^2}}=\limite{y}{0^+}{\dfrac{y}{y^2}}=\limite{y}{0^+}{\dfrac{1}{y}}=\dfrac{1}{0^+}=\infty\]
Este ejemplo se incluye solo a modo de demostración de la aplicación del teorema de sustitución de infinitésimos equivalentes. En la práctica utilizaremos el Teorema de L'Hôpital, que permite calcular los mismos límites que el teorema de sustitución, pero de manera más directa.
\end{example}



\newpage\section{Continuidad}


\begin{definition}
  [Continuidad en un punto] Una función $f$ es {\tmstrong{continua en un punto $x_0$}} si y solo si existe $f ( x_0 )$, existe (y es finito) el límite de $f$ en $x_0$, y $\underset{x \rightarrow x_0}{\lim} f ( x ) = f ( x_0 )$.
\end{definition}

\begin{definition}
  Tipos de discontinuidades:
  \begin{enumerate}
    \item Una función, $f$ tiene una {\tmstrong{discontinuidad evitable}} en $x_0$ si existe $\underset{x \rightarrow x_0}{\lim} f ( x )$ y es finito, pero $f ( x_0 )$ no está definido, o $f ( x_0 ) \neq \underset{x \rightarrow  x_0}{\lim} f ( x )$.
    \item Una función $f$ tiene una {\tmstrong{discontinuidad inevitable}} en $x_0$ si no existe $\underset{x \rightarrow x_0}{\lim} f ( x )$ o es infinito. En este caso, la discontinuidad se clasifica como:
      \begin{itemize}
      \item \emph{discontinuidad de primera especie} (o de salto) cuando existen ambos límites laterales (pero, o bien alguno de ellos es infinito, o bien son distintos);
      \item \emph{discontinuidad de segunda especie} (o esencial) cuando no existe alguno de los límites laterales (no es finito ni infinito).
      \end{itemize}
  \end{enumerate}
\end{definition}

\begin{figure}
  \centering
  \subfloat[Discontinuidad evitable]{\label{fig:tiposdiscontinuidades:a}\includegraphics[width=5cm]{discontinuidades1_cropped.pdf}}
  \hspace{1cm}
  \subfloat[Discontinuidad inevitable de salto]{\label{fig:tiposdiscontinuidades:b}\includegraphics[width=5cm]{discontinuidades2_cropped.pdf}}
  \hspace{1cm}
  \subfloat[Discontinuidad inevitable esencial]{\label{fig:tiposdiscontinuidades:c}\includegraphics[width=5cm]{discontinuidades3_cropped.pdf}}
  \hspace{1cm}
  \caption{Tipos de discontinuidades}
  \label{fig:tiposdiscontinuidades}
\end{figure}

\begin{definition}
  [Continuidad en un intervalo abierto] Una función es {\tmstrong{continua en un intervalo abierto}} si y solo si es continua en todos los puntos del intervalo.
\end{definition}

\begin{definition}
  [Continuidad en un intervalo cerrado] Una función $f ( x )$ es {\tmstrong{continua en un intervalo cerrado}} $[ a, b ]$ si y solo si es continua en $( a, b )$ y $\underset{x \rightarrow a^+}{\lim} f ( x ) = f ( a )$ y $\underset{x \rightarrow b^-}{\lim} f ( x ) = f ( b )$.
\end{definition}

\begin{remark}
  A las condiciones $f(a) = \limite{x}{a^+}{f}$ y $f(b) = \limite{x}{b^-}{f}$ se les llama \emph{continuidad por derecha} y \emph{continuidad por la izquierda}, respectivamente.
\end{remark}

\begin{remark}
  Se dice que una función es \emph{continua} (sin especificar un punto ni un intervalo) cuando es continua en $\mathbb{R}$.
\end{remark}

\begin{theorem}
  Dadas dos funciones $f$ y $g$ continuas en $x_0$, se tiene:
  \begin{enumerate}
    \item $f + g$ es continua en $x_0$;
    
    \item $f \cdot g$ es continua en $x_0$;
    
    \item si $g ( x_0 ) \neq 0$, $\frac{f}{g}$ es continua en $x_0$.
  \end{enumerate}
\end{theorem}

\begin{theorem}
  Dadas dos funciones $f$ y $g$, si $g$ es continua en $x_0$ y $f$ es continua en $g ( x_0 )$, entonces $f \circ g$ es continua en $x_0$.
\end{theorem}

\begin{theorem}
  Continuidad de funciones elementales: 
  \begin{enumerate}
    \item La {\tmstrong{función constante}}, $f ( x ) = k, \forall x \in \mathbb{R}$, es continua en $\mathbb{R}$.
    
    \item La {\tmstrong{función identidad}}, $f ( x ) = x, \forall x \in \mathbb{R}$, es continua en $\mathbb{R}$.
    
    \item Toda {\tmstrong{función polinómica}}, $f ( x ) = \underset{i = 0}{\overset{n}{\Sigma}} a_i x^i$, es continua en $\mathbb{R}$.
    
    \item Toda {\tmstrong{función irracional}}, $f ( x ) = \sqrt[n]{\Sigma a_i x^i}, n \in \mathbb{Z}$, es continua en su dominio.
    
    \item Toda {\tmstrong{función racional}} es continua en su dominio.
    
    \item La {\tmstrong{función exponencial}}, $f ( x ) = e^x$, es continua en $\mathbb{R}$.
    
    \item La {\tmstrong{función logaritmo}}, $f ( x ) = \ln x$, es continua en su dominio, $( 0, \infty )$.
    
    \item Las {\tmstrong{funciones seno y coseno}} son continuas en $\mathbb{R}$.
  \end{enumerate}
\end{theorem}

\begin{example}
  Estudiar la continuidad de $f ( x ) = \dfrac{x - 1}{x^2 + x - 2}$.
  
{\tmstrong{Funciones racionales}}: una función racional es continua en todo $\mathbb{R}$ excepto en las raíces del denominador. Las discontinuidades en
las raíces del denominador pueden ser evitables o inevitables. Para distinguir unas de otras hay que calcular el límite de la función en el punto de
discontinuidad (se obtendrá una indeterminación $0 / 0$ o $k / 0$): si dicho límite no existe o es infinito, la discontinuidad es inevitable, si es finito, es evitable.

  Por ser racional, $f$ es continua en todo $\mathbb{R}$ excepto en las raíces del denominador. Calculamos dichas raíces:
  
  \[x^2 + x - 2 = 0 \Leftrightarrow x = \left\{\begin{array}{l} 1\\ - 2\end{array}\right..\]

  Luego, $f ( x )$ es continua en $\mathbb{R}- \{ 1, - 2 \}.$
  
  Estudiamos el tipo de discontinuidad en esos dos puntos, calculando los límites en ellos:
  
  \[\underset{x \rightarrow 1}{\lim} f ( x ) = \underset{x \rightarrow 1}{\lim}
  \dfrac{x - 1}{x^2 + x - 2} = \dfrac{0}{0} = \underset{x \rightarrow 1}{\lim} 
  \dfrac{x - 1}{( x - 1 ) ( x + 2 )} = \underset{x \rightarrow 1}{\lim} 
  \dfrac{1}{x + 2} = \dfrac{1}{1 + 2} = \dfrac{1}{3}\]
  
  Puesto que existe el límite y es finito, la discontinuidad en $x = 1$ es evitable: solo hay que definir $f ( 1 ) = 1 / 3$, o bien, redefinir $f$ como
  $f ( x ) = \frac{1}{x + 2}$.
  
  \[\underset{x \rightarrow - 2}{\lim} f ( x ) = \underset{x \rightarrow -
  2}{\lim} \dfrac{1}{x + 2} = \dfrac{1}{0} ; \underset{x \rightarrow -
  2^+}{\lim} \dfrac{1}{x + 2} = \dfrac{1}{- 2^+ + 2} = \dfrac{1}{0^+} = + \infty
  ; \underset{x \rightarrow - 2^-}{\lim} \dfrac{1}{x + 2} = \dfrac{1}{0^-} = -
  \infty\]
  
  Puesto que los límites laterales son distintos, no existe el límite de $f$ en $- 2$, luego dicha discontinuidad es inevitable.
\end{example}

\begin{example}
  Estudiar la continuidad de $f ( x ) = \left\{\begin{array}{l}
    \dfrac{1}{x - 2}, \tmop{si} x < 1\\
    x^2 - 2, \tmop{si} x \geqslant 1
  \end{array}\right.$.
  
{\tmstrong{Funciones definidas a trozos}}: se estudia la continuidad en el interior de cada trozo por separado, y en los extremos de cada trozo por
separado. La continuidad en cada trozo depende de la forma de la función en dicho trozo (si es polinómica, es continua en todo el trozo, si es racional,
será discontinua en las raíces del denominador que caigan dentro del trozo). Para estudiar la continuidad en los extremos de cada trozo, se calculan los
límites laterales en cada extremo, y se comparan entre sí y con el valor de la función en cada extremo.

  El primer trozo es una función racional, luego es continuo para todo $x$ excepto las raíces del denominador, es decir, $x = 2$, pero como esa raíz no
  está dentro del intervalo correspondiente a ese trozo, esto es $( - \infty, 1 )$, $f$ es continua en todo ese trozo.
  
  El segundo trozo es una función polinómica, luego es continua en todo el interior de su intervalo de validez, $( 1, \infty )$.
  
  Para estudiar la continuidad en el extremo de los trozos, que es $x = 1$, calculamos los límites laterales:
  
  \[\underset{x \rightarrow 1^-}{\lim} f ( x ) = \underset{x \rightarrow
  1^-}{\lim} \dfrac{1}{x - 2} = \dfrac{1}{1 - 2} = - 1 ; \underset{x \rightarrow
  1^+}{\lim} f ( x ) = \underset{x \rightarrow 1^+}{\lim} ( x^2 - 2 ) = 1^2 -
  2 = - 1\]
  
  Por el teorema de existencia del límite:
  \[\underset{x \rightarrow 1^-}{\lim}
  f ( x ) = \underset{x \rightarrow 1^+}{\lim} f ( x ) = - 1 \Rightarrow
  \underset{x \rightarrow 1}{\lim} f ( x ) = - 1\]
  
  Además,
  \[f ( 1 ) = - 1 = \underset{x \rightarrow 1}{\lim} f ( x ),\]
  luego $f$ es continua en $x = 1$. Por tanto, $f$ es continua en $\mathbb{R}$.
\end{example}

\section{Teorema de Bolzano}

\begin{theorem}
  [Bolzano] Si una función $f$ es continua en $[a,b]$, y el signo de $f(a)$ es distinto del signo de $f(b)$, entonces existe algún punto $c\in(a,b)$ tal que $f(c)=0$.
\end{theorem}

\begin{remark}
  La idea intuitiva es esta: si $f$ cambia de signo entre $a$ y $b$, entonces, o bien da un salto (no es continua), o bien tiene que cortar al eje horizontal en algún punto situado entre $a$ y $b$. A este teorema se le llama también Teorema de las Raíces.
\end{remark}

\begin{example}
  La función $f(x)=\cos(x)-x$ es continua en $\mathbb{R}$, por ser suma de dos funciones continuas. Tenemos que $f(0)=1>0$, pero $f(\pi/2)=-\pi/2<0$, por tanto, la función ha de valer 0 en algún punto del intervalo $(0,\pi/2)$, según se ve en la gráfica (figura~\ref{fig:continuidad1:a}). Sin embargo, la función $g(x)=(x+2)\ln|x^2+x-2|-2$, aunque $g(0)<0$, y $g(2)>0$, no corta al eje horizontal en el intevalo $(0,2)$, ya que tiene una discontinuidad en $x=1$ (figura~\ref{fig:continuidad1:b}).
\end{example}

\begin{figure}
\centering
\subfloat{\label{fig:continuidad1:a}
\includegraphics[width=8cm]{continuidad1a_cropped.pdf}}
\hspace{1cm}
\subfloat{\label{fig:continuidad1:b}
\includegraphics[width=8cm]{continuidad1b_cropped.pdf}}
\label{fig:continuidad1}
\caption{Teorema de Bolzano}
\end{figure}

\begin{theorem}
  [Weierstrass] Si una función $f$ es continua en $[a,b]$, entonces existen $c_1\in[a,b]$ y $c_2\in[a,b]$ tales que $f(c_1)\leq f(x)\leq f(c_2)$ para todo $x\in[a,b]$.
\end{theorem}

\begin{remark}
  La idea intuitiva es que una función continua en un intervalo cerrado tiene siempre en dicho intervalo un máximo y un mínimo. A este teorema se le llama también Teorema de Acotación en Intervalos Cerrados y Acotados.
\end{remark}

\begin{theorem}
  [Valores intermedios] Si una función $f$ es continua en $[a,b]$, entonces, para todo $k\in I$, existe algún $c\in(a,b)$, tal que $f(c)=k$, siendo $I=\left[f(a),f(b)\right]$, si $f(a)\leq f(b)$, o bien, $I=\left[f(b),f(a)\right]$, si $f(b)\leq f(a)$.
\end{theorem}

\begin{remark}
  La idea intuitiva es que una función continua en un intervalo cerrado $[a,b]$, toma en dicho intervalo todos los valores intermedios entre $f(a)$ y $f(b)$, que son los que tiene en los extremos del intervalo. Se trata de una generalización del teorema de Bolzano: si $f$ es continua en una intervalo cerrado, entonces corta a todas las rectas horizontales situdadas entre las que pasan por los puntos extremos del intervalo (figura~\ref{fig:continuidad2}).
\end{remark}

\begin{figure}
  \centering
  \includegraphics[width=12cm]{continuidad2_cropped.pdf}
  \label{fig:continuidad2}
  \caption{Teorema del valor intermedio}
\end{figure}


\newpage\section{Asíntotas y ramas infinitas}

\begin{definition}
  [Rama infinita] Se dice que una función tiene una rama infinita cuando $x$, $f(x)$ o ambas, crecen o decrecen indefinidamente (tienden a $\infty$ o a $-\infty$).
\end{definition}

\begin{definition}
  [Asíntota] Se dice que una recta es una asíntota de una función cuando una rama infinita de dicha función se aproxima infinitamente a dicha recta cuando la rama infinita crece o decrece. Se suele decir que son rectas tangentes en el infinito a una rama infinita de la función.
\end{definition}

\begin{theorem} [Asíntotas verticales]
  La recta $x=a$ es una asíntota vertical de la función $f(x)$ si algún límite lateral de $f$ en $a$ es infinito ($\pm\infty$).
\end{theorem}

\begin{theorem} [Asíntotas horizontales]
  La recta $y=b$ es una asíntota horizontal por la derecha de la función $f$ si $\limite{x}{\infty}{f}=b$. La recta $y=b$ es una asíntota horizontal por la izquierda de la función $f$ si $\limite{x}{-\infty}{f}=b$.
\end{theorem}

\begin{theorem} [Asíntotas oblicuas]
  La recta $y=mx+n$ es una asíntota oblicua por la derecha de la función $f$ si $m=\limite{x}{\infty}{\dfrac{f(x)}{x}}$ es finito, y $n=\limite{x}{\infty}{\left[f(x)-mx\right]}$ es finito. La recta $y=mx+n$ es una asíntota oblicua por la izquierda de la función $f$ si $m=\limite{x}{-\infty}{\dfrac{f(x)}{x}}$ es finito, y $n=\limite{x}{-\infty}{\left[f(x)-mx\right]}$ es finito.
\end{theorem}

\begin{remark}
  Una función puede no tener ninguna asíntota vertical, o tener varias, e incluso infinitas.
\end{remark}

\begin{remark}
  Si $x=a$ es asíntota vertical de $f$, entonces $f$ tiene una discontinuidad inevitable en $a$.
\end{remark}

\begin{remark}
  Si una función tiene una asíntota horizontal por la derecha, entonces no puede tener asíntota oblicua por la derecha. Lo mismo se puede decir respecto a las asíntotas por la izquierda.
\end{remark}

\begin{remark}
  Si una función racional tiene una asíntota horizontal u oblicua por la derecha, entonces esa misma recta es asíntota horizontal u oblicua, respectivamente, por la izquierda. Por tanto, cuando calculemos las asíntotas de las funciones racionales solo tendremos que calcular uno de los dos límites (habitualmente calcularemos $\limite{x}{\infty}{f}$, porque es más sencillo).
\end{remark}


\begin{example}
  Hallar las asíntotas de la función: $f(x)=\dfrac{x^3-x^2}{x^2-1}$.

Es una función racional. Puede tener asíntotas verticales en las raíces de su denominador:
\[x^2-1=0 \iff x\in\{-1,1\}\]
\[\limite{x}{-1}{f}=\limite{x}{-1}{\dfrac{x^3-x^2}{x^2-1}}=\dfrac{-2}{0}\]
La indeterminación obtenida se corresponde siempre con límites laterales infinitos, por lo que podemos asegurar que $x=-1$ es una asíntota vertical de $f$.
\[\limite{x}{1}{f}=\limite{x}{1}{\dfrac{x^3-x^2}{x^2-1}}=\dfrac{0}{0}=\limite{x}{1}{\dfrac{x^2(x-1)}{(x+1)(x-1)}}=
\limite{x}{1}{\dfrac{x^2}{x+1}}=\dfrac{1}{2}\]
Puesto que el límite en $1$ es finito, no hay asíntota vertical en ese punto, sino una discontinuidad evitable.
Para determinar si tiene asíntotas horizontales, calculamos sus límites en el infinito. Como es una función racional, basta con calcular uno de ellos:
\[\limite{x}{\infty}{f}=\limite{x}{\infty}{\dfrac{x^3-x^2}{x^2-1}}=\dfrac{\infty}{\infty}=\infty\]
Sabemos que el límite es $\infty$ porque el grado del numerador es mayor que el del denominador. Por lo tanto no hay asíntota horizontal por la derecha, y, puesto que es racional, tampoco por la izquierda.
Para determinar si tiene asíntota oblicua, calculamos los límites siguientes:
\[m=\limite{x}{\infty}{\dfrac{f(x)}{x}}=\limite{x}{\infty}{\dfrac{x^3-x^2}{x^3-x}}=\limite{x}{\infty}{\dfrac{x^2(x-1)}{x(x+1)(x-1)}}=
\limite{x}{\infty}{\dfrac{x}{x+1}}=\dfrac{\infty}{\infty}=1\]
\[n=\limite{x}{\infty}{[f(x)-mx]}=\limite{x}{\infty}{\left(\dfrac{x^3-x^2}{x^2-1}-x\right)}=\limite{x}{\infty}{\dfrac{x^3-x^2-x(x^2-1)}{x^2-1}}=
\limite{x}{\infty}{\dfrac{-x^2+x}{x^2-1}}=\dfrac{-\infty}{\infty}=-1\]
Por lo tanto, la recta $y=x-1$ es una asíntota oblicua de $f$ en $\infty$. Como $f$ es racional, sabemos que esa misma recta es asíntota en $-\infty$.

\begin{figure}
  \centering
  \includegraphics[width=12cm]{asintotas1_cropped.pdf}
  \label{fig:asintotas1}
  \caption{\ensuremath{f(x)=\dfrac{x^3-x^2}{x^2-1}}}
\end{figure}
\end{example}

\begin{example}
  Hallar las asíntotas de $f(x)=\dfrac{x^3+4x^2-x-16}{2x^2-8}$.

  Es una función racional. Por tanto, si tiene asíntotas verticales las tendrá en las raíces del denominador:
  \[2x^2-8 = 0 \iff x = \pm 2\]
  Para comprobar si existen asíntotas verticales en esos puntos, calculamos los límites de $f$ en ellos:
  \[\limite{x}{-2^-}{f} = \dfrac{-10}{0^+} = -\infty\]
  \[\limite{x}{-2^+}{f} = \dfrac{-10}{0^-} = \infty\]
  \[\limite{x}{2^-}{f} = \dfrac{6}{0^-} = -\infty\]
  \[\limite{x}{2^+}{f} = \dfrac{6}{0^+} = \infty\]
  Luego, efectivamente, la función tiene dos asíntotas verticales:
  \[AV_1: x=-2;\ AV_2:x=2\]

  Obsérvese que, en realidad, nos habría bastado con calcular uno solo de los límites laterales en cada punto: que un límite lateral sea infinito es condición suficiente para que haya asíntota. También podíamos simplemente haber comprobado que la discontinuidad en esos puntos no es evitable, es decir, que es del tipo $k/0$ y no del tipo $0/0$.

  Calculando el límite de la función en $\infty$ averiguamos si tiene asíntota horizontal. Es suficiente calcular uno de los dos límites en el infinito, porque al ser racional, sabemos que si dicho límite es finito, el otro será igual:
  \[\limite{x}{\infty}{f}=\dfrac{\infty}{\infty}=\infty\]

  Por lo tanto, la función no tiene asíntotas horizontales.

  Veremos si tiene asíntotas oblicuas calculando:
  \[m = \limite{x}{\infty}{\dfrac{f(x)}{x}} = \limite{x}{\infty}{\dfrac{x^2+4x^2-x-16}{x(2x^2-8)}} = \dfrac{1}{2}\]
  \[n = \limite{x}{\infty}{\left[f(x)-mx\right]} = \limite{x}{\infty}{\left[\dfrac{x^3+4x^2-x-16}{2x^2-8}-\dfrac{x}{2}\right]} = 2\]

  Luego la recta $y = \dfrac{1}{2}x + 2$ es asíntota oblicua de $f$ en $\infty$ y en $-\infty$.

  Obsérvese que no necesitamos calcular $m$ y $n$ en $-\infty$, porque ya sabemos que, si son finitos, tienen que ser iguales que en $\infty$, porque $f$ es racional.

  Obsérvese también que la asíntota horizontal interseca a la función en el punto $(0,2)$. Eso no es ningún problema: una asíntota puede cortar a la curva. Lo único que importa para que sea asíntota es cómo se comporta en el límite.

\begin{center}
\includegraphics[width = 12 cm]{asintotas1_cropped.pdf}
\end{center}
\end{example}


\begin{example}
  Hallar las asíntotas de la función $f(x)=\dfrac{\sqrt{e^{x}}-\ln(x+3)}{\sqrt{e^{x}}}$.

El dominio de la función es $\{x\in\mathbb{R}|x+3>0\}=(-3,\infty)$, que es el dominio de $\ln(x+3)$, ya que el resto de la expresión está definida en $\mathbb{R}$, y el denominador no se anula nunca, ya que $e^{x}>0,\forall x\in\mathbb{R}$. La función puede tener una asíntota vertical en los puntos en que se anule el argumento del logaritmo: $x=-3$. Calculamos el límite por la derecha en ese punto (el otro límite lateral no existe, pues es la frontera del dominio):
\[\limite{x}{-3^+}{f}=\limite{x}{-3^+}{\dfrac{\sqrt{e^{x}}-\ln(x+3)}{\sqrt{e^{x}}}}=\dfrac{\sqrt{e^{3}}-\ln0}{\sqrt{e^{3}}}=
\dfrac{\sqrt{e^{3}}-(-\infty)}{\sqrt{e^{3}}}=\infty\]
Por lo tanto, la recta $x=-3$ es una asíntota vertical de $f$.
La función no puede tener asíntotas horizontal ni oblicua por la izquierda, ya que el dominio está acotado por la izquierda. Para averiguar si tiene asíntota horizontal u oblicua por la derecha calculamos en primer lugar el límite de la función en $\infty$:
\[\limite{x}{\infty}{f}=\limite{x}{\infty}{\dfrac{\sqrt{e^{x}}-\ln(x+3)}{\sqrt{e^{x}}}}=1\]
Por tanto, la recta $y=1$ es una asíntota horizontal por la derecha, y no hay asíntotas oblicuas.
Nota: para calcular el límite anterior es necesario aplicar la regla de L'Hôpital, que se estudiará más adelante.
\end{example}

\begin{figure}
  \centering
  \includegraphics[width=12cm]{asintotas2_cropped.pdf}
  \label{fig:asintotas2}
  \caption{\ensuremath{f(x)=\dfrac{\sqrt{e^{x}}-\ln(x+3)}{\sqrt{e^{x}}}}}
\end{figure}

\chapter{Derivación}

\newpage\section{Concepto de derivada}

\begin{definition}
  [Derivada en un punto] Dada una función $f$ y un punto $x$ de su dominio, se llama \textbf{derivada de $f$ en $a$}, y se representa por $f'(a)$, al límite siguiente, si existe:
\[f'(a)=\limite{h}{0}{\dfrac{f(a+h)-f(a)}{h}}\]
\end{definition}

\begin{remark}
  Otra definición de derivada equivalente a la anterior es la siguiente:
\[f'(a)=\limite{x}{a}{\dfrac{f(x)-f(a)}{x-a}}\] 
\end{remark}

\begin{definition}
  [Derivabilidad] Se dice que una función $f$ es \textbf{derivable} en un punto $a$ de su dominio si existe $f'(a)$ (en sentido estricto, es decir, existe y es finito).
\end{definition}

\begin{remark}
  Se llama \textbf{derivadas laterales} de $f$ en $a$ por la derecha y por la izquierda, y se representan por $f'\left(a^+\right)$ y $f'\left(a^-\right)$, respectivamente, a los límites siguientes, si existen:
\[f'\left(a^+\right)=\limite{h}{0^+}{\dfrac{f(a+h)-f(a)}{h}}\hspace{1cm}f\left(a^-\right)=\limite{h}{0^-}{\dfrac{f(a+h)-f(a)}{h}}\]
Según el teorema de existencia del límite, $f$ es derivable en $a$ si y solo si $f'\left(a^-\right)=f'\left(a^+\right)$.
\end{remark}

\begin{remark}
  Se dice que una función tiene \textbf{derivada infinita} en $a$ cuando $f'(a)=\pm\infty$. Cuando una función tiene derivada infinita en un punto, se considera que no es derivable en dicho punto.
\end{remark}

\begin{remark}
  Se dice que una función es \emph{derivable en un conjunto abierto} cuando es derivable en todos los puntos de dicho conjunto. Se dice que una función es \emph{derivable} cuando es derivable en su dominio, siendo este un conjunto abierto.
\end{remark}

\begin{theorem}
  [Interpretación geométrica de la derivada en un punto] La derivada de una función $f$ en un punto $a$ es la pendiente de la recta tangente a la gráfica de $f$ en el punto $\left(a,f(a)\right)$.
\end{theorem}

\begin{remark}
  Utilizando la forma punto-pendiente, podemos, por tanto, escribir la \emph{ecuación de la recta tangente} a la gráfica de $f$ en $x=a$ así:
\[y-f(a)=f'(a)(x-a)\]
\end{remark}

\begin{remark}
  Se llama \textbf{recta normal} a una curva en un punto de la misma a la recta perpendicular a la tangente a dicha curva en dicho punto. Salvo en el caso de que la recta tangente sea horizontal o vertical, la pendiente de la recta tangente, $m_t$, y la pendiente de la recta normal, $m_n$, verifican la relación: $m_tm_n=-1$.
\end{remark}

\begin{remark}
  La recta tangente a la gráfica de una función en un punto puede ser \emph{secante} a dicha gráfica, tanto en el punto de tangencia como en otros. Así, por ejemplo, la recta tangente a la gráfica de $f(x)=x^3$ en $x=0$ es el eje horizontal, que es secante a la gráfica de $f$ en el origen. La tangente a $f(x)=x^4-x^2$ en $x=0$ es el eje horizontal, que interseca a la gráfica en los puntos $(-1,0)$ y $(1,0)$, además del propio punto de tangencia, $(0,0)$.

Por lo tanto, no se puede definir \emph{recta tangente} a una curva en un punto como la recta que ``toca'' a dicha curva en un solo punto. Habría que definirla como la recta que tiene la misma ``inclinación'' que tiene la curva en ese punto.
\end{remark}

\begin{figure}
  \centering
  \includegraphics[width=12cm]{significadoderivada_cropped.pdf}
  \caption{Significado geométrico de la derivada.}
  \label{fig:significadoderivada}
\end{figure}

\begin{remark}
  La derivada en un punto se puede interpretar de manera más general a través del concepto de tasa de variación. Se llama tasa de variación media de una función $f$ en un intervalo $(a,a+h)$ al cociente $\dfrac{\Delta f}{\Delta x}=\dfrac{f(a+h)-f(a)}{h}$. La derivada de $f$ en $a$ es, por tanto, el límite de la tasa de variación media cuando la amplitud del intervalo de variación de $x$ tiende a cero. Dicho límite se llama también \textbf{tasa de variación instantánea}. Este concepto tiene varias \emph{interpretaciones}. Geométricamente, la tasa de variación instantánea en un punto es, como ya se ha explicado, la pendiente de la recta tangente a la gráfica de la función (o lo que es lo mismo, la ``inclinación'' de la función en ese punto, cuántas unidades ``sube'' o ``baja'' la gráfica en dirección vertical, por cada unidad que nos desplazamos en horizontal hacia la derecha). En Física, el concepto de tasa de variación instantánea (y, por tanto, la derivada) tiene múltiples aplicaciones: la tasa de variación instantánea es la velocidad instantánea de variación de cualquier magnitud. Así, por ejemplo, la velocidad de un móvil en un instante será la derivada del desplazamiento en ese instante. En Economía se aplica, entre otros, al concepto de \textbf{coste marginal}. El coste marginal es lo que se incrementan los costes por cada unidad en que se incrementa la producción. El coste marginal vendrá dado por la derivada de la función de costes, que relaciona el coste con la producción.
\end{remark}

\begin{theorem}
  [Relación entre continuidad y derivabilidad] Si una función es derivable en $a$, entonces es también continua en $a$.
\end{theorem}

\begin{remark}
  El recíproco del teorema anterior no es verdadero. Una función puede ser continua en un punto pero no derivable en él. Así, por ejemplo, la función $f(x)=|x|$ es continua en $x=0$, pero no es derivable en ese punto, ya que $f'(0^-)=-1$ y $f'(0^+)=1$. Esquemáticamente:
\[f \text{ derivable} \Rightarrow f \text{ continua}\]
\[f \text{ continua} \nRightarrow f \text{ derivable}\]
\end{remark}

\begin{figure}
  \centering
  \includegraphics[width=12cm]{puntosangulosos_cropped.pdf}
  \caption{La función $f(x)=|x^2-1|$ es continua pero no derivable en $x=-1$ y en $x=-1$.}
  \label{fig:puntosangulosos}
\end{figure}

\begin{definition}
  [Función derivada] Se llama \textbf{función derivada} de $f$, y se representa por $f'$, a la función que en cada punto en que $f$ es derivable toma el valor de $f'(a)$.
\end{definition}

\begin{remark}
  Cuando hablemos de \emph{la derivada de una función}, habitualmente nos estaremos refiriendo a la función derivada.
\end{remark}

\begin{figure}
  \centering
  \includegraphics[width=12cm]{funcionderivada_cropped.pdf}
  \label{fig:funcionderivada}
  \caption{Función derivada.}
\end{figure}

\begin{remark}
  Obsérvese que la notación para la derivada de $f$ en un punto $a$, es coherente con la notación de la función derivada de $f$, representada por $f'$, y la notación para el valor de una función en un punto. Es indistinguible si $f'(a)$ representa a la derivada de $f$ en $a$, o al valor de $f'$ en $x=a$: y así debía ser, puesto que ambos valores son siempre el mismo. Conviene, no obstante, subrayar que $f'(a)$ es un símbolo que representa un número, que es la derivada de $f$ en $a$.
\end{remark}

\begin{definition}
  [Derivadas de orden superior] A la función derivada de la función derivada de $f$ se le llama \textbf{derivada segunda} de $f$, y se representa por $f''$. A la función derivada de la derivada segunda de $f$ se le llama \textbf{derivada tercera} de $f$, y se representa por $f'''$. De la misma manera se definen la derivada cuarta, quinta, etc. A todas estas derivadas se les denomina genéricamente \textbf{derivadas de orden superior} de $f$. A partir de la cuarta derivada, se utilizan números entre paréntesis, en lugar de apóstrofos: $f^{(4)},f^{(5)},\hdots,f^{(n)}$.
\end{definition}

\begin{remark}
  Cuando una función $f$ verifica que existe $f^{(n)}(a)$ para todo $n$ para todo $a$ del dominio de $f$, se dice que dicha función es \emph{derivable infinitamente}.
\end{remark}

\begin{remark}
  Existen varias simbologías para representar la derivada en un punto y la función derivada. La que nosotros utilizamos se denomina \emph{notación de Lagrange}. Otras simbologías frecuentes son:
  \begin{itemize}
  \item \emph{Notación de Leibniz}: la función derivada de una función $f$ de una variable $x$, se representa por:
    \[\dfrac{df}{dx}\text{, }\dfrac{df}{dx}(x)\text{ o bien }\dfrac{d}{dx}f(x)\]
    La derivada de $f$ en $a$ se representa:
    \[\dfrac{df}{dx}(a)=\left.\dfrac{df}{dx}\right|_{x=a}\]
    Las derivadas de orden superior se representan por:
    \[\dfrac{d^nf}{dx^n}\text{, }\dfrac{d^nf}{dx^n}(x)\text{, }\dfrac{d^n}{dx^n}f(x)\text{, o bien }\dfrac{d}{dx}\left(\dfrac{d}{dx}\left(\cdots\dfrac{df}{dx}\right)\right)\]
  \item \emph{Notación de Arbogast} (también conocida como de Euler o de Cauchy): la función derivada de una función $f$ se representa por:
    \[Df\text{, o bien }Df(x)\]
    Se puede indicar el nombre de la variable independiente como subíndice del operador $D$:
    \[D_xf\text{, o bien }D_xf(x)\]
    Las derivadas de orden superior se representan así:
    \[D^2f,D^3f, \hdots D^nf\]
  \end{itemize}
\end{remark}

\newpage\section{Cálculo de derivadas}

\begin{theorem}
  [Reglas de cálculo de derivadas] Cálculo de derivadas de funciones elementales:
  \begin{itemize}
  \item Derivada de una constante: $k'=0$.
  \item Derivada de $x$: $x'=1$.
  \item Derivada del producto de una constante por una función: $\left(kf\right)'=kf'$.
  \item Derivada de la suma: $\left(f+g\right)'=f'+g'$
  \item Derivada del producto: $\left(fg\right)'=f'g+fg'$
  \item Derivada del cociente: $\left(\dfrac{f}{g}\right)'=\dfrac{f'g-fg'}{g^2}$.
  \item \textbf{Regla de la cadena} (derivada de la composición): $\left(f\circ g\right)'(x)=f'\left[g(x)\right]\cdot g'(x)$.
  \item Derivada de la función inversa: $\left[f^{-1}(x)\right]'=\dfrac{1}{f'\left[f^{-1}(x)\right]}$.
  \item Derivada de una potencia: $\left(f^n\right)'=nf^{n-1}f'$.
  \item Derivada de una exponencial: $\left(a^f\right)'=a^ff'\ln a$
  \item Derivada de un logaritmo: $\left(\log_a f\right)'=\dfrac{f'}{f}\cdot\dfrac{1}{\ln a}$.
  \item Derivada de las funciones trigonométricas: $\left(\sen f\right)'=f'\cos f;\ \left(\cos f\right)'=-f'\sen f;\ \left(\tg f\right)'=f'\sec^2f;\ \left(\cotg f\right)'=-f'\cosec^2 f$.
  \item Derivada de las funciones trigonométricas inversas: $\left(\arcsen f\right)'=\dfrac{f'}{\sqrt{1-f^2}};\ \left(\arccos f\right)'=\dfrac{-f'}{\sqrt{1-f^2}};\ \left(arctg f\right)'=\dfrac{f'}{1+f^2}$.
  \item Derivada de la función exponencial-potencial: $\left(f^g\right)'=gf'f^{g-1}+g'f^g\ln f$.
  \end{itemize}
\end{theorem}

\begin{remark}
  [Derivación logarítmica] Para calcular la derivada de algunas funciones se puede seguir el procedimiento siguiente, denominado \emph{derivación logarítmica}: tomar logaritmos en la ecuación de la función cuya derivada se quiere calcular, $f$; derivar los dos miembros de la ecuación; multiplicar por $f$. Este método se puede usar para derivar las funciones exponenciales-potenciales, en lugar de la fórmula dada anteriormente. Por ejemplo, para hallar la derivada de $f(x)=x^x$, se seguiría este procedimiento:

  \begin{eqnarray*}f(x)=x^x & \iff & \ln f(x) = \ln x^x = x\ln x \\
    & \Rightarrow & \left(\ln f(x)\right)' = \left(x \ln x\right)' \\
    & \Rightarrow & \dfrac{f'(x)}{f(x)} = 1\cdot\ln x + x\cdot\dfrac{1}{x} = \ln x + 1\\
    & \Rightarrow & f'(x) = f(x)\left(\ln x + 1\right) = x^x(1+\ln x)
  \end{eqnarray*}
\end{remark}

\begin{remark}
  Algunas derivadas frecuentes que conviene conocer:
  \begin{itemize}
  \item $f(x)=\dfrac{1}{x}\Rightarrow f'(x)=\dfrac{-1}{x^2}$.
  \item $f(x)=\sqrt{x}\Rightarrow f'(x)=\dfrac{1}{2\sqrt{x}}$.
  \item $f(x)=e^x \Rightarrow f'(x)=e^x$.
  \item $f(x)=\ln x \Rightarrow f'(x)=\dfrac{1}{x}$.
  \end{itemize}
\end{remark}

\newpage\section{Teoremas de Rolle y del Valor Medio}

\begin{theorem}
  [Rolle] Si $f$ es continua en $[a,b]$ y derivable en $(a,b)$, y $f(a)=f(b)$, entonces existe algún $c\in(a,b)$ tal que $f'(c)=0$ (es decir, en el intervalo $(a,b)$ existe algún punto en el que la tangente es horizontal).
\end{theorem}

\begin{remark}
  Normalmente, en el punto $c$, $f$ tendrá un extremo relativo (en un apartado posterior se define este concepto). Es importante tener en cuenta que si no se cumplen las premisas, puede no existir dicho punto singular. Así ocurre con $f(x)=1/x^2$ en el intervalo $[-1,1]$: $f(-1)=f(1)=1$, pero no hay ningún punto $c$ en $(-1,1)$, en que $f'(c)=0$ (en realidad, $f$ no tiene ningún punto con derivada nula), porque $f$ no es continua en $[-1,1]$ (en particular, tiene una discontinuidad en $x=0$). Otro ejemplo sería la función $g(x)=|x|$, que verifica $g(-1)=g(1)=1$ y es continua en $[-1,1]$, pero no tiene ningún punto con derivada nula, ya que no es derivable en $(-1,1)$ (en particular, no es derivable en $x=0$).
\end{remark}

\begin{figure}
  \centering
  \subfloat{\label{fig:rolle:a}\includegraphics[width=5cm]{rolle1_cropped.pdf}}
  \hspace{1cm}
  \subfloat{\label{fig:rolle:b}\includegraphics[width=5cm]{rolle2_cropped.pdf}}
  \hspace{1cm}
  \subfloat{\label{fig:rolle:c}\includegraphics[width=5cm]{rolle3_cropped.pdf}}
  \hspace{1cm}
  \caption{Teorema de Rolle}
  \label{fig:rolle}
\end{figure}

\begin{example}
  Demostrar que la ecuación $2x+1=e^{-2x}$ tiene una única solución.

  Hay una solución casi trivial, $x=0$. Demostraremos que no hay más aplicando el teorema de Rolle.

  Sea

  \[f(x)=2x-e^{-2x}+1\]

  Obsérvese que las soluciones de la ecuación $2x+1=e^{-2}$ son las raíces de $f$, es decir, los valores de $x$ tales que $f(x)=0$. Ya sabemos que $f(0)=0$. Supongamos que existe otra solución de la ecuación, $x=b$, es decir, un número $b$ tal que $f(b)=0$.

  La función $f$ es continua y derivable en $\mathbb{R}$, y, por tanto, valga lo que valga $b$, es continua en el intervalo $[0,b]$, y derivable en  $(0,b)$. Dado que, supuestamente, $f(0)=f(b)=0$, según el teorema de Rolle deberá existir algún $c\in(0,b)$ tal que $f'(c)=0$. Sin embargo,

  \[f'(x)=2+2e^{-2x}>0\ \forall\;x\in\mathbb{R}\]

  Luego, no puede existir tal $b\neq0$ que verifique $f(b)=0$. Luego, la solución de la ecuación es única: $x=0$.
\end{example}

\begin{theorem}
  [Valor medio de Lagrange] Si $f$ es continua en $[a,b]$ y derivable en $(a,b)$, entonces existe algún punto $c\in(a,b)$ tal que:
  \[f'(c)=\dfrac{f(b)-f(a)}{b-a}\]
\end{theorem}

\begin{figure}
  \centering
  \includegraphics[width=10cm]{lagrange_cropped.pdf}
  \caption{Teorema del valor medio de Lagrange}
  \label{fig:lagrange}
\end{figure}

\begin{remark}
  Este teorema afirma que, si se cumplen las condiciones de continuidad y derivabilidad necesarias, en algún punto del intervalo, la tangente será paralela a la recta que une los extremos del intervalo. Dicho de otro modo, en algún punto del intervalo, la tasa de variación instantánea coincidirá con la tasa de variación media del intervalo. Resulta intuitivo si se piensa en términos de velocidad: un vehículo que recorre 100 km en una hora, tiene una velocidad media de 100 km por hora; eso no significa que siempre haya ido a esa velocidad, pero, necesariamente, en algún punto del trayecto su velocidad habrá sido exactamente de 100 km por hora.
\end{remark}

\begin{remark}
  El teorema del valor medio es una generalización del teorema de Rolle. O bien, el de Rolle es un caso particular del teorema del valor medio: efectivamente, el teorema de Rolle es la aplicación del teorema del valor medio a un intervalo $(a,b)$, en el que $f(a)=f(b)$.
\end{remark}

\begin{remark}
  El teorema del valor medio de Langrange, y otra versión del mismo, llamada de Cauchy, son de gran importancia teórica: están en la base de las demostraciones de muchos teoremas del Cálculo. Ellos a su vez dependen de una propiedad básica (pero difícil) de los números reales, que dice que todo conjunto acotado de números reales tiene un extremo superior (cota superior mínima). Desde el punto de vista práctico se utilizan poco. Sí son muy empleadas sus aplicaciones directas (como el teorema de L'Hôpital, que veremos a continuación).
\end{remark}

\newpage\section{Teorema de L'Hôpital}

\begin{theorem}
  [L'Hôpital] Sean $f$ y $g$ dos funciones definidas en un intervalo abierto uno de cuyos extremos es $a$, de modo que ni $g$ ni $g'$ se anulen en dicho intervalo, y tales que $\limite{x}{a}{f}=\limite{x}{a}{g}=0$ (o $\infty$), entonces, si existe $\limite{x}{a}{\dfrac{f'}{g'}}$, entonces también existe $\limite{x}{a}{\dfrac{f}{g}}$, y

      $$\limite{x}{a}{\dfrac{f}{g}}=\limite{x}{a}{\dfrac{f'}{g'}},$$

donde $a$ puede ser un número real, o $\pm\infty$.
\end{theorem}

\begin{remark}
  El teorema anterior se llama también \emph{Regla de L'Hôpital}, y es aplicable a límites laterales. Es una manera rápida de resolver indeterminaciones del tipo $0/0$ o $\infty/\infty$.
\end{remark}

\begin{example}
  Calcular el límite:

  \[L=\limite{x}{\infty}{\left(x+e^x\right)^{2/x}}\]

  Es una indeterminación $\infty^0$:

  \[\limite{x}{\infty}{\left(x+e^x\right)^{2/x}} = \left(\infty+e^\infty\right)^{2/\infty} = \infty^0\]

  Transformamos en una exponencial de base $e$:

  \[\left(x+e^x\right)^{2/x} = e^{\ln\left(x+e^x\right)^{2/x}} = e^{\frac{2}{x}\ln\left(x^+e^x\right)}\]

  Luego,

  \[L = e^{\limite{x}{\infty}{\frac{2}{x}\ln\left(x+e^x\right)}}=e^M\]

  El nuevo límite es una indeterminación $0\cdot\infty$, que transformamos en $\dfrac{\infty}{\infty}$:

  \[M=\limite{x}{\infty}{\dfrac{2}{x}\ln\left(x+e^x\right)} = \dfrac{2}{\infty}\ln\infty = 0\cdot\infty = \limite{x}{\infty}{\dfrac{2\ln\left(x+e^x\right)}{x}} = \dfrac{\infty}{\infty}\]

  Aplicando el teorema de L'Hôpital:

  \[M = \limite{x}{\infty}{2\dfrac{\frac{1+e^x}{x+e^x}}{1}} = 2\limite{x}{\infty}{\dfrac{1+e^x}{x+e^x}} = 2\dfrac{1+e^\infty}{\infty+e^\infty} = \dfrac{\infty}{\infty}\]

  Aplicando de nuevo L'Hôpital dos veces:

  \[M = 2\limite{x}{\infty}{\dfrac{e^x}{1+e^x}} = 2\dfrac{e^\infty}{1+e^\infty}=\dfrac{\infty}{\infty} = 2\limite{x}{\infty}{\dfrac{e^x}{e^x}} = 2\limite{x}{\infty}{1} = 2\]

  Por tanto,

  \[L = e^2\]
\end{example}

\begin{remark}
  Conviene comprobar que se cumplen las premisas del teorema antes de aplicarlo; de modo particular que estamos ante una indeterminación $0/0$ o $\infty/\infty$: la regla de L'Hôpital no es aplicable a cualquier cociente. Analícese el cálculo del siguiente límite realizado aplicando sucesivas veces la regla de L'Hôpital. ¿Es correcto?

  \begin{eqnarray*}
    \limite{x}{1}{\dfrac{x^3-2x^2+x}{x^3-3x+2}} & = & \limite{x}{1}{\dfrac{3x^2-4x+1}{3x^2-3}} \\
       & = & \limite{x}{1}{\dfrac{6x-4}{6x}} \\
       & = & \limite{x}{1}{\dfrac{6}{6}} \\
       & = & 1
  \end{eqnarray*}

  Otro error frecuente en la aplicación de este teorema consiste en calcular la derivada del cociente en lugar del cociente de las derivadas, como en el siguiente ejemplo (erróneo):

  \begin{eqnarray*}
    \limite{x}{1}{\dfrac{x^2-1}{x-1}} & = & \dfrac{1^2-1}{1-1} = \dfrac{0}{0} \\
      & = & \limite{x}{1}{\dfrac{2x(x-1)-(x^2-1)}{(x-1)^2}} \\
      & = & \limite{x}{1}{\dfrac{2x^2-2x-x^2+1}{(x-1)^2}} \\
      & = & \limite{x}{1}{\dfrac{x^2-2x+1}{x^2-2x+1}} \\
      & = & 1
  \end{eqnarray*}
\end{remark}

\clearpage



\newpage\section{Crecimiento}

\begin{definition}
  [Crecimiento y decrecimiento de una función] Sea $f$ una función, y $A$ un intervalo real. Diremos que $f$ es \textbf{creciente} en $A$ si para todo $x,y\in A$, se cumple que si $x<y$, entonces $f(x)<f(y)$. Diremos que $f$ es \textbf{decreciente} en $A$ cuando para todo $x,y\in A$ se cumple que si $x<y$, entonces $f(x)>f(y)$. Diremos que una función es \textbf{monótona} en un intervalo $A$ cuando sea o bien creciente en $A$ o bien decreciente en $A$.
\end{definition}

\begin{remark}
  Cuando una función $f$ verifica que para todo $x,y\in A$, si $x<y$, entonces $f(x)\leq f(y)$, se dice que es \emph{no decreciente} en $A$. Si para todo $x,y\in A$, se verifica que si $x<y$, entonces $f(x)\geq f(y)$, se dice que $f$ es \emph{no creciente} en $A$. Hay que tener cuidado de no confundir estos nombres con las negaciones de creciente y decreciente. No es lo mismo decir $f$ \emph{no es creciente en $I$}, que decir $f$ \emph{es no creciente en $I$}. Así, por ejemplo, la función $f(x)=x^3-x$ no es creciente en $(-1,1)$, pero tampoco es no creciente. Para evitar esta confusión, algunos llaman \emph{estrictamente crecientes} a las funciones que hemos llamado crecientes, y \emph{crecientes} a las funciones que hemos llamado no crecientes. Esta nomenclatura también tiene sus problemas: según esta terminología, una función constante sería creciente.
\end{remark}

\begin{definition}
  [Acotación] Se dice que una función $f$ está \textbf{acotada superiormente} en un intervalo $I$ cuando existe algún número $M$ tal que $f(x)\leq M$ para todo $x\in I$. Se dice que está \textbf{acotada inferiormente} en un intervalo $I$ cuando existe algún $L$ tal que $f(x)\geq L$ para todo $x\in I$. Se dice que $f$ está \textbf{acotada} en $I$ cuando está acotada superiormente e inferiormente en $I$.
\end{definition}

\begin{definition}
  [Máximos y mínimos] Se dice que el \textbf{máximo absoluto o global} de una función $f$ en un intervalo $I$ de su dominio es $f(a)$ si $f(a)\geq f(x)$ para todo $x\in I$. Se dice que el \textbf{mínimo absoluto o global} de una función $f$ en un intervalo $I$ de su dominio es $f(a)$ si $f(a)\leq f(x)$ para todo $x\in I$. Se dice que una función $f$ tiene un \textbf{máximo relativo o local} en un punto $a$ de su dominio si existe algún entorno $A$ de $a$ contenido en el dominio de $f$ tal que $f(a)\geq f(x)$ para todo $x\in A$. Se dice que una función $f$ tiene un \textbf{mínimo relativo o local} en un punto $a$ de su dominio si existe algún entorno $A$ de $a$ contenido en el dominio de $f$ tal que $f(a)\leq f(x)$ para todo $x\in A$. Decimos que una función tiene en el punto $a$ un \textbf{extremo absoluto o global} en un intervalo $I$ cuando alcanza su valor máximo o mínimo absoluto en $I$ en dicho punto. Decimos que una función tiene un \textbf{extremo relativo o local} en $a$ cuando tiene un máximo o mínimo relativo en dicho punto.
\end{definition}

\begin{remark}
  Algunos prefieren exigir que las desigualdades que definen a los máximos y mínimos relativos sean estrictas.
\end{remark}

\begin{remark}
  Cuando no se especifica un intervalo, se ha de sobreentender que el intervalo es el dominio de la función. Así, por ejemplo, si decimos que una función es creciente, debemos entender que lo es en su dominio. Si decimos que una función está acotada, queremos decir que está acotada en su dominio. Si decimos que $f$ tiene un máximo en $a$, debemos entender que $f(a)$ es el valor máximo de la función $f$ en su dominio.
\end{remark}

\begin{definition}
  [Punto singular] Se dice que una función tiene un punto singular en $a$ cuando, o bien $f$ no es derivable en $a$, o bien $f'(a)=0$.
\end{definition}

\begin{theorem}
  [Criterio de la primera derivada para el crecimiento] Sea $I$ un intervalo incluido en el dominio de una función $f$.
  \begin{itemize}
  \item Si $f'(x)>0,\;\forall x\in I$, entonces $f$ es creciente en $I$.
  \item Si $f'(x)<0,\;\forall x\in I$, entonces $f$ es decreciente en $I$.
  \end{itemize}
\end{theorem}

\begin{remark}
  Los intervalos de crecimiento o decrecimiento de una función vienen determinados por los siguientes puntos:
  \begin{itemize}
  \item Discontinuidades.
  \item Puntos sin derivada.
  \item Puntos con derivada nula.
  \end{itemize}
  Como en las discontinuidades no hay derivada, podríamos reducir los tres tipos de puntos a dos: puntos sin derivada y puntos con derivada nula, es decir, a los puntos singulares.
\end{remark}

\begin{theorem}
  [Condición necesaria de extremo relativo] Sea $I$ un intervalo incluido en el dominio de una función $f$. Si $f$ es derivable en un punto $a$ de $I$, y $f$ tiene un extremo relativo en $a$, entonces $f'(a)=0$.
\end{theorem}

\begin{remark}
  La condición es necesaria, pero no suficiente. Es decir, el recíproco no es cierto. Puede ser $f'(a)=0$, sin que $f$ tenga un extremo relativo en $a$. Así, por ejemplo, si $f(x)=x^3$, tenemos que $f'(0)=0$, pero la función no tiene un extremo relativo en $x=0$ (de hecho, no tiene extremos relativos).
\end{remark}

\begin{remark}
  Es importante la premisa de que la función sea derivable en el punto en cuestión. Así, por ejemplo, la función $f(x)=|x|$ tiene un mínimo relativo en $x=0$, pero no tiene derivada nula en ese punto, porque no es derivable en él.
\end{remark}

\begin{remark}
  Se podría resumir el teorema diciendo que los extremos relativos se alcanzan siempre en puntos singulares (aunque no todos los puntos singulares son extremos relativos).
\end{remark}

\begin{theorem}
  [Criterio de la primera derivada para los extremos relativos] Sea $c$ un punto singular de $f$ en $(a,b)$, siendo $f$ una función continua en $[a,b]$ y derivable en $(a,b)-\{c\}$.
  \begin{itemize}
  \item Si $f'(x)>0,\forall x\in(a,c)$ y $f'(x)<0,\forall x\in(a,c)$, entonces $f$ tiene un máximo relativo en $c$.
  \item Si $f'(x)<0,\forall x\in(a,c)$ y $f'(x)>0,\forall x\in(a,c)$, entonces $f$ tiene un mínimo relativo en $c$.
  \end{itemize}
\end{theorem}

\begin{theorem}
  [Criterio de la segunda derivada para los extremos relativos] Si $f$ es derivable hasta la segunda derivada en $a$, entonces:
  \begin{itemize}
  \item Si $f'(a)=0$ y $f''(a)<0$, entonces $f$ tiene un máximo relativo en $a$.
  \item Si $f'(a)=0$ y $f''(a)>0$, entonces $f$ tiene un mínimo relativo en $a$.
  \end{itemize}
\end{theorem}

\newpage\section{Curvatura}

\begin{definition}
  [Concavidad y convexidad] Se dice que una función $f$ es cóncava en un intervalo $I$ si para todo $a,b\in I$, el segmento rectilíneo de extremos $\left(a,f(a)\right)$ y $\left(b,f(b)\right)$ tiene todos los puntos por debajo de la gráfica de $f$; se dice que $f$ es convexa cuando dicho segmento queda por encima de la gráfica de $f$.
\end{definition}

\begin{definition}
  [Puntos de inflexión] Se dice que $f$ tiene un punto de inflexión en $c$ si existe un intervalo $(a,b)$ tal que $f$ es cóncava en $(a,c)$ y convexa en $(c,b)$, o viceversa.
\end{definition}

\begin{remark}
  La recta tangente a la gráfica de una función $f$ en un punto en que la función sea cóncava estará siempre por encima de la curva. En los puntos en los que la curva es convexa, la tangente está por debajo de la curva. En un punto de inflexión, la tangente ``corta'' a la curva, es decir, una parte de la tangente está por encima y la otra está por debajo de la curva.
\end{remark}

\begin{figure}
  \centering
  \includegraphics[width=6cm]{curvatura_cropped.pdf}
  \label{fig:curvatura}
  \caption{Posiciones de la tangente según la curvatura.}
\end{figure}


\begin{theorem}
  [Criterio de la segunda derivada para la concavidad] Si $I$ es un intervalo incluido en el dominio de una función $f$:
  \begin{itemize}
  \item Si $f''(x)>0,\;\forall x\in I$, entonces $f$ es convexa en $I$.
  \item Si $f''(x)<0,\;\forall x\in I$, entonces $f$ es cóncava en $I$.
  \end{itemize}
\end{theorem}

\begin{remark}
  Una teorema análogo a este, aplicable a los casos en los que no existe segunda derivada, dice que siendo $f$ derivable, si $f'$ es creciente en $(a,b)$ entonces $f$ es convexa en $(a,b)$, y si $f'$ es decreciente en $(a,b)$ entonces $f$ es cóncava en $(a,b)$.
\end{remark}

\begin{remark}
  Para estudiar los intervalos de concavidad y convexidad hay que estudiar el signo de $f''$, teniendo en cuenta los puntos en los que $f''(x)=0$ y también aquellos en los que no existe $f''(x)$.
\end{remark}

\begin{theorem}
  [Condición necesaria de punto de inflexión] Si $f$ tiene un punto de inflexión en $c$ y existe $f''(c)$, entonces $f''(c)=0$.
\end{theorem}

\begin{remark}
  Es una condición necesaria, pero no suficiente. Así, por ejemplo, $f(x)=x^4$ cumple $f''(0)=0$, pero en $x=0$ no tiene un punto de inflexión, sino un mínimo.
\end{remark}

\begin{figure}
  \centering
  \includegraphics[width=10cm]{segundaderivada_cropped.pdf}
  \caption{Significado geométrico de la segunda derivada.}
  \label{fig:segundaderivada}
\end{figure}

\begin{remark}
  En la figura~\ref{fig:segundaderivada} se puede ver la relación entre la segunda derivada de una función y la forma de la gráfica de dicha función. Aparecen las gráficas de una cierta función $f$ (línea sólida), la de su derivada $f'$ (línea discontinua), y la de su segunda derivada $f''$ (línea de puntos). Obsérvese que:
\begin{itemize}
\item Cuando $f''$ es positiva (por encima del eje), $f$ es convexa. Cuando $f''$ es negativa, $f$ es cóncava.
\item Los puntos de inflexión de $f$ coinciden con raíces de $f''$ (puntos de corte con el eje) y también con máximos o mínimos de $f'$.
\end{itemize}
Además, como la segunda derivada de $f$ es la primera derivada de $f'$, resulta que el signo de $f''$ nos informa del crecimiento de $f'$. Así, vemos que los máximos y mínimos de $f'$ coinciden con puntos de corte de $f''$ con el eje horizontal. También se observa que los puntos de inflexión de $f'$ coinciden con máximos o mínimos de $f''$.
\end{remark}

\begin{remark}
  Si una función es derivable hasta la derivada enésima en $a$,  y se verifica que $f'(a)=f''(a)=\hdots=f^{(n-1)}(a)=0$, y $f^{(n)}\neq0$, entonces:
  \begin{itemize}
  \item Si $n$ es par, $f$ tiene un extremo relativo en $a$ (que será máximo si $f^{(n)}<0$ y mínimo si $f^{(n)}>0$.
  \item Si $n$ es impar, $f$ tiene un punto de inflexión en $a$.
  \end{itemize}
\end{remark}

\begin{remark}
  Para el estudio completo de la gráfica de una función se deben analizar las propiedades siguientes:
  \begin{itemize}
  \item Dominio y continuidad.
  \item Simetrías y periodicidad.
  \item Puntos de corte con los ejes de coordenadas y signo.
  \item Intervalos de crecimiento y decrecimiento, y máximos y mínimos.
  \item Intervalos de concavidad y convexidad, y puntos de inflexión.
  \item Ramas infinitas y asíntotas.
  \end{itemize}

\end{remark}

\begin{remark}
  Hay dos tipos principales de simetrías en las funciones:
  \begin{itemize}
  \item \emph{Simetría par}: $f$ tiene simetría par si $f(-x)=f(x),\ \forall x\in\dom f$. Las gráficas de las funciones pares son simétricas respecto al eje vertical. En $x=0$ han de tener un extremo relativo o una discontinuidad.
  \item \emph{Simpetría impar}: $f$ tiene simetría impar si $f(-x)=-f(x),\ \forall x\in\dom f$. Las gráficas de las funciones impares son simétricas respecto al origen. Si $x=0$ está en el dominio de $f$, entonces ha de ser $f(0)=0$.
  \end{itemize}
\end{remark}

\begin{remark}
  Los puntos de corte con los ejes de coordenadas se calculan así:
  \begin{itemize}
  \item Con el eje vertical: si hay, solo hay uno, y es el punto $\left(0,f(0)\right)$.
  \item Con el eje horizontal (raíces): sus abscisas son las soluciones de la ecuación $f(x)=0$.
  \end{itemize}
\end{remark}

\newpage\section{Problemas de optimización}

\begin{remark}
  En los problemas de optimización se pretende hallar una valor óptimo (maximo o mínimo) de cierta magnitud, que depende de una o más variables. El problema se modela matemáticamente mediante una función (llamada \emph{función objetivo}, que expresa la dependencia de la magnitud que se quiere optimizar respecto de las variables. Se trata de encontrar los valores de las variables para los cuales la función tiene su valor máximo o mínimo. La optimización es un campo muy amplio. En este curso resolveremos solo problemas en los que la función objetivo es una función de una variable, o bien, es una función de dos variables, pero podemos reducirlas a una sola, porque existe entre ellas una relación expresable mediante una ecuación (a veces llamada \emph{ecuación de ligadura}.
\end{remark}

\begin{remark}
  Los máximos o mínimos que queremos hallar en estos problemas serán siempre absolutos. Sin embargo, muchas veces, los valores de las variables estarán restringidos a determinados intervalos abiertos, por lo que el problema se reducirá a encontrar extremos relativos.
\end{remark}

\begin{example}
    Una empresa de productos de limpieza fabrica cajas de cartón con tapa, para comercializar un determinado tipo de detergente. Las cajas son prismas rectos de 9000 $cm^3$ de volumen y base rectangular de largo igual al doble de su anchura. Calcúlense las dimensiones en centímetros (largo, anchura, altura) que ha de tener cada caja para que la superficie de cartón empleada en su fabricación sea mínima.

    \vspace{.5cm}

      Llamaremos $x$ a la anchura de la base, e $y$ a la altura de la caja. La superficie de cartón de una caja será:

      \[S(x,y)=4x^2+2xy+4xy=4x^2+6xy;\ \text{para }x>0,\; y>0\]

      Esta es la \emph{función objetivo} (a minimizar).

  Las variables están ligadas por la condición de que el volumen ha de ser de $9000\ cm^3$:

  \[V(x,y)=2x^2y=9000\]

  Esta es la \emph{ecuación de ligadura}.

  De la ecuación anterior podemos despejar una de las dos variables:

  \[y=\dfrac{9000}{2x^2}=\dfrac{4500}{x^2}\]

  Sustituyendo la expresión obtenida en la función $S(x,y)$, obtenemos una función $f$ que nos da el valor de la superficie de cartón en función de una única variable, la anchura $x$:

  \[f(x)=4x^2+6x\dfrac{4500}{x^2}=4x^2+\dfrac{15000}{x};\ \text{para }x>0\]

  Se trata de minimizar la superficie de cartón, es decir, de hallar el valor mínimo de $f$. Puesto que la función es continua y derivable en su dominio ($x>0$), si tiene un mínimo tendrá que ser un mínimo relativo, y en él la derivada tendrá que ser nula:

  \[f'(x)=8x-\dfrac{15000}{x^2}\]
  \[f'(x)=0 \iff 8x-\dfrac{15000}{x^2}=0 \iff 8x^3=15000 \iff x=\sqrt[3]{\dfrac{15000}{8}}=5\sqrt[3]{15}\]

  Para comprobar que se trata de un mínimo (puesto que la condición utilizada es necesaria pero no suficiente), hallaremos la segunda derivada en ese punto:

  \[f''(x)=8+\dfrac{30000}{x^3};\ f''\left(5\sqrt[3]{15}\right)=8+\dfrac{30000}{125\cdot15}=24>0\]

  Como la segunda derivada es positiva se trata de un mínimo relativo, que, además, ha de ser el mínimo absoluto de la función en $(0,\infty)$, ya que la función es continua en $(0,\infty)$ y no tiene más extremos relativos.

  Así pues, las dimensiones que ha de tener la caja son:
  \begin{itemize}
  \item Anchura: $x=5\sqrt[3]{15}$.
  \item Largo: $2x=10\sqrt[3]{15}$.
  \item Alto: $y=\dfrac{4500}{x^2}=\dfrac{4500}{25\sqrt[3]{225}=12\sqrt[3]{15}}$.
  \end{itemize}

\end{example}

\chapter{Integración}

\newpage\section{Concepto de primitiva}

\begin{definition}
  [Función primitiva] Dada una función $f$, se dice que la función $F$ es una \textbf{función primitiva} (o \emph{antiderivada}) de $f$ si $F'=f$.
\end{definition}

\begin{theorem}
  Si $F$ y $G$ son funciones primitivas de una misma función $f$, entonces la función $F-G$ es una función constante.
\end{theorem}

\begin{remark}
  Es bastante claro que si $F(x)$ es una primitiva de $f$, entonces la función $F(x)+k$, donde $k$ es una constante cualquiera, es también una primitiva de $f$. Por lo tanto, cualquier función que tenga una primitiva, tiene infinitas primitivas.
\end{remark}

\begin{remark}
  El teorema anterior nos dice que, no solo es que al sumar una constante se obtenga otra primitiva, sino que esa es la única manera de obtener otra primitiva. Dicho de otra forma: todas las primitivas de una función se diferencian solo por una constante. La demostración de este teorema implica al teorema del valor medio.
\end{remark}

\begin{remark}
  Se define también el concepto de función primitiva en un intervalo $(a,b)$: una función $F$ es primitiva de otra función $f$ en un intervalo $(a,b)$ si $F'(x)=f'(x),\forall x\in(a,b)$.
\end{remark}

\begin{definition}
  [Integral indefinida] Se llama \textbf{integral indefinida} de una función $f$ al conjunto de todas las primitivas de dicha función. Se representa por:
  \[\int\! f(x) \,\mathrm{d}x\]
\end{definition}

\begin{remark}
  Si $F$ es una primitiva de $f$, se suele escribir:
\[\int\! f(x) \,\mathrm{d}x=F(x)+C\]
siendo $C$ una constante, que se suele denominar \emph{constante de integración}. A la función $f$ se le llama \emph{integrando}. Al proceso de calcular la integral indefinida se le llama \emph{integración} o \emph{antidiferenciación}.
\end{remark}

\begin{remark}
  El nombre, y el símbolo utilizados para representar al conjunto de primitivas de una función están relacionados con un concepto posterior, que es el de integral definida, y con el Teorema Fundamental del Cálculo. Cuando se estudien esos conceptos se entenderá la simbología empleada. Históricamente (y desde el punto de vista lógico) el concepto de integral definida precede al de integral indefinida.
\end{remark}

\begin{remark}
  En el símbolo anterior, la expresión $\,\mathrm{d}x$, leída \emph{diferencial de x}, no tiene ningún significado, aunque es útil para indicar cuál es la variable independiente (y será, por tanto, necesario en cálculo de varias variables). Tiene su origen en el concepto de integral definida. Puede omitirse cuando las funciones son de una sola variable:
\[\int\! f(x) \,\mathrm{d}x \equiv \int\! f(x) \equiv \int\! f\]
\end{remark}

\begin{theorem}
  [Propiedades de la integral indefinida] Dadas dos funciones $f$ y $g$, y una constante $k$, cualesquiera, se verifican las propiedades siguientes:
  \begin{enumerate}
  \item $\displaystyle \int\! \left(f+g\right)=\int\! f + \int\! g$
  \item $\displaystyle \int\! kf = k\int\! f$
  \end{enumerate}
\end{theorem}

\begin{remark}
  Estas propiedades hay que entenderlas en el sentido de que siempre existen primitivas de las incluidas en las integrales indefinidas que intervienen, que verifican las igualdades (evidentemente, la igualdad no puede verificarse para todas las primitivas, pero la diferencia será siempre una constante).
\end{remark}

\begin{remark}
  No nos vamos a ocupar este curso de la existencia de primitivas. La mayoría de las funciones tienen primitivas (son derivadas de alguna otra función). De hecho, todas las funciones continuas tienen primitivas. También muchas funciones no continuas. Los teoremas de existencia de primitivas son complicados, y exceden los objetivos de este curso. No obstante, sí señalaremos que los métodos de obtención de primitivas que vamos a estudiar (métodos de integración) no abarcan a todas las funciones que poseen primitivas, y, además, buscan siempre primitivas que sean funciones elementales. Sin embargo hay funciones elementales (y algunas muy sencillas) cuyas primitivas no son elementales. Así, por ejemplo, la función $f(x)=e^{-x^2}$ tiene primitivas, pero estas no pueden expresarse en términos de funciones elementales, de modo que todos los métodos de integración fracasarán con ella.
\end{remark}

\begin{example}
  Si la derivada de la función $f(x)$ es $f'(x)=x+1$, hallar la función $f$ sabiendo que $f(1)=1$.

La función $f$ es una de las primitivas de $f'$:

\[f(x)=\int\! f'(x) \,\mathrm{d}x=\int\! \left(x+1\right) \,\mathrm{d}x=\int\! x \,\mathrm{d}x+\int\! 1 \,\mathrm{d}x\]

Sabemos que la derivada de $x$ es $1$, luego la segunda de las integrales será $x+C_2$. El resultado de la primera integral sería $x^2$ si el integrando fuese $2x$. Podemos ``introducir'' dicho $2$ en la integral, multiplicando por $2/2$, e introduciendo solo el numerador en la integral aplicando la linealidad de la integral:

\[f(x)=\dfrac{2}{2}\int\! x \,\mathrm{d}x + x + C_2=\dfrac{1}{2}\int\! 2x \,\mathrm{d}x + x + C_2=\dfrac{1}{2}x^2 + C_1 + x + C_2=\dfrac{x^2}{2}+x+C\]

Hemos reunido las dos constantes de integración, $C_1$ y $C_2$, en una sola, $C$.

Hemos obtenido una expresión general para todas las primitivas de $f'$, que se diferencian unas de otras solo por el valor de $C$. Ahora se trata de encontrar el valor que debe tener la constante de integración, $C$, para que la primitiva pase por el punto $(1,1)$, es decir, $f(1)=1$:

\[f(1)=1 \iff \dfrac{1^2}{2}+1+C=1 \iff C=-\dfrac{1}{2}\]

Por lo tanto, la función $f$ es:
\[f(x)=\dfrac{x^2}{2}+x-\dfrac{1}{2}\]
\end{example}

\newpage\section{Cálculo de primitivas (métodos de integración)}

\subsection*{Integrales inmediatas}

\begin{theorem}
  [Integrales inmediatas] Fórmulas de integración inmediata:
  \begin{enumerate}
  \item Potencial: $\displaystyle\int f' \cdot f^n = \frac{f^{n + 1}}{n + 1}$
  
  \item Exponencial: $\displaystyle\int f' \cdot a^f = \frac{a^f}{\ln a}^{}$
  
  \item Logarítmica: $\displaystyle\int \frac{f'}{f} = \ln |f|$
  
  \item Seno y coseno: $\displaystyle\int f' \cdot \cos f = \tmop{sen} f$; $\displaystyle\int f' \cdot
  \tmop{sen} f = - \cos f$
  
  \item Tangente y cotangente: $\displaystyle\int f' \cdot \sec^2 f = \tmop{tg} f$; $\int
  f' \cdot \tmop{cosec}^2 f = - \tmop{cotg} f$
  
  \item Arcoseno: $\displaystyle\int \frac{f'}{\sqrt{1 - f^2}} = \tmop{arcsen} f$
  
  \item Arcotangente: $\displaystyle\int \frac{f'}{1 + f^2} = \tmop{arctg} f$
  
  \end{enumerate}
\end{theorem}

\begin{remark}
  Las fórmulas anteriores, llamadas \emph{integrales inmediatas}, se deducen directamente de las fórmulas de derivación correspondientes.
\end{remark}

\begin{remark}
  Algunas identidades que pueden ser útiles para trasformar una integral en inmediata:
  \begin{itemize}
  \item $\sen^2x+\cos^2x=1,\hspace{1cm}1+\tan^2x=\dfrac{1}{\cos^2x},\hspace{1cm}1+\cot^2x=\dfrac{1}{\sen^2x}$
  \item $\sen 2x=2\sen x\cos x,\hspace{1cm}\cos 2x=\cos^2x-\sen^2x$
  \item $\sen^2x=\dfrac{1-\cos 2x}{2},\hspace{1cm}\cos^2x=\dfrac{1+\cos 2x}{2}$
  \item $\sen(x+y)=\sen x\cos y+\cos x\sen y,\hspace{1cm}\cos(x+y)=\cos x\cos y-\sen x\sen y$
  \item $\ln(xy)=\ln x+ \ln y,\hspace{1cm}\ln\left(\dfrac{x}{y}\right)=\ln x-\ln y,\hspace{1cm}\ln x^n=n\ln x$
  \end{itemize}
\end{remark}

\begin{example} Integrales inmediatas:

  \begin{enumerate}
  \item Potencial:

  \[\int x \sqrt{1 - x^2} d x = \int \frac{- 1}{2} \cdot ( - 2 ) x \sqrt{1 - x^2} d x = \frac{- 1}{2} \int - 2 x ( 1 - x^2 )^{\frac{1}{2}} d x = \frac{-
  1}{2} \cdot \frac{( 1 - x^2 )^{\frac{1}{2} + 1}}{\frac{1}{2} + 1} = \frac{-1}{3} ( 1 - x^2 )^{\frac{3}{2}}\]

  \item Exponencial:

  \[\int \frac{e^{\sqrt{x}}}{\sqrt{x}} d x = 2 \int \frac{1}{2 \sqrt{x}} e^{\sqrt{x}} d x = 2 e^{\sqrt{x}}\]
  
  \item Logarítmica:

  \[\int \frac{\tmop{sen} x}{2 - \cos x} d x = \ln |2 - \cos x| = \ln ( 2 - \cos x )\]
  
  \item Seno y coseno:

  \[\int e^x \cos e^x d x = \tmop{sen} e^x\]
  \[\int \tmop{sen} 2 x d x = \frac{1}{2} \int 2 \tmop{sen} 2 x d x = - \frac{1}{2} \cos 2 x\]
  
  \item Tangente y cotangente:

  \[\int \tmop{tg}^2 x d x = \int ( \sec^2 x - 1 ) d x = \int \sec^2 x d x - \int 1 d x = \tmop{tg} x - x\]
  
  \item Arcoseno:

  \[\int \frac{e^x}{\sqrt{1 - e^{2 x}}} d x = \int \frac{e^x}{\sqrt{1 - ( e^x )^2}} d x = \tmop{arcsen} e^x\]
  
  \item Arcotangente:

  \[\int \frac{d x}{a^2 + x^2} = \int \frac{1}{a^2 + x^2} d x = \int \frac{\frac{1}{a^2}}{\frac{a^2}{a^2} + \frac{x^2}{a^2}} d x = \frac{1}{a}
  \int \frac{\frac{1}{a}}{1 + \left( \frac{x}{a} \right)^2} d x = \frac{1}{a} \tmop{arctg} \frac{x}{a}\]

  \end{enumerate}
\end{example}

\subsection*{Integración por sustitución}

\begin{theorem}
  Dada una función $g$, derivable y con recorrido $I$, y una función $f$ definida en $I$, siendo $F$ una primitiva de $f$ en $I$, se verifica:
\[\int\!f\left[g(x)\right]g'(x)\,\mathrm{d}x=F[g(x)]+C\]
\end{theorem}

\begin{remark}
  Habitualmente, este teorema se expresa del siguiente modo. Se realiza la \emph{sustitución} o \emph{cambio de variable} $u=g(x)$, y se escribe:
\[\int\!f\left[g(x)\right]g'(x)\,\mathrm{d}x=\int\!f(u)\,\mathrm{d}u=F(u)+C=F\left(g(x)\right)+C\]
\end{remark}

\begin{remark}
  Este teorema es una consecuencia inmediata de la regla de la cadena.
\end{remark}

\begin{remark}
  El teorema se puede aplicar de dos formas, según cuál de las dos integrales involucradas sea más fácil de calcular:
  \begin{itemize}
  \item Tomando $g(x)=u$, transformar la integral $\displaystyle\int\! f[g(x)]g'(x)\,\mathrm{d}x$ en $\displaystyle \int \! f(u)\,\mathrm{d}u$, calcular esta segunda integral, y luego deshacer el cambio de variable para obtener la primera.
  \item Tomando $x=g(u)$, transformar la integral $\displaystyle \int \! f(x) \,\mathrm{d}x$ en $\int\! f[g(u)]g'(u)\,\mathrm{d}u$, calcular esta integral, y luego deshacer el cambio de variable para obtener la primera.
  \end{itemize}
\end{remark}

\begin{remark}
  Sustituciones frecuentes:
  \begin{itemize}
  \item Si aparece $e^x$ y la integral no es inmediata, el cambio $t=e^x$ puede funcionar.
  \item Si aparecen varias raíces de la misma expresión, como $\sqrt{1+x}$, $\sqrt[3]{1+x}$ y $\sqrt[4]{1+x}$, probar el cambio $1+x=t^{12}$, que transforma todas las raíces en potencias enteras positivas.
  \item Si aparece $\sqrt{1-x^2}$, probar el cambio $x=\sen t$, y aplicar la identidad $\cos t=\sqrt{1-\sen^2t}$.
  \item Si aparece $\sqrt{1+x^2}$, probar el cambio $x=\tg t$, y aplicar la identidad $1+\tg^2t=\sec^2t$.
  \item Para integrales racionales en $\sen x$ y $\cos x$, si no se han podido resolver por otros métodos, hay una sustitución que funciona siempre: $t=\tg\left(x/2\right)$. Con esta sustitución resulta:
    \[\sen x=\dfrac{2t}{1+t^2},\hspace{1cm}\cos x=\dfrac{1-t^2}{1+t^2},\hspace{1cm}\mathrm{d}x=\dfrac{2}{1+t^2}\mathrm{d}t\]
  \end{itemize}

\end{remark}

\begin{example}
  Calcular
  \[\int \! \dfrac{e^{2x}}{\sqrt{e^x+1}}\,\mathrm{d}x\]
  Utilizaremos el método de sustitución o cambio de variable según el primer esquema:
    \begin{enumerate}
    \item Buscar una sustitución conveniente: $u = g ( x )$.
    
    \[u = \sqrt{e^x + 1}\]
    
    \item Expresar $x$ en función de $u$: $x = g^{- 1} ( u )$.
    
    \[u = \sqrt{e^x + 1} \Rightarrow u^2 = e^x + 1 \Rightarrow e^x = u^2 - 1 \Rightarrow x = \ln ( u^2 - 1 )\]
    
    \item Expresar $\mathrm{d}x$ en función de $\mathrm{d}u$ (derivando la expresión anterior): $\mathrm{d}x=(g^{- 1})'(u)\mathrm{d}u$
    
    \[\mathrm{d}x=\dfrac{2u}{u^2-1}\mathrm{d}u\]
    
    \item Sustituir $x$ y $\mathrm{d}x$ por las expresiones anteriores (llegados a este paso sólo debería aparecer $u$ en la integral, y no $x$) e integrar
    en la ``variable'' $u$.
    
    \begin{eqnarray*}
      \int\!\dfrac{e^{2 x}}{\sqrt{e^x + 1}}\,\mathrm{d}x & = & \int\!\dfrac{e^{2 \ln( u^2-1)}}{u}\cdot\dfrac{2u}{u^2-1}\mathrm{d}u \\
      & = & \int\!\dfrac{e^{\ln (u^2-1)^2}}{u}\cdot\dfrac{2u}{u^2-1}\,\mathrm{d}u \\
      & = & \int\! \dfrac{( u^2 - 1 )^2}{u} \cdot \dfrac{2 u}{u^2 - 1} \,\mathrm{d} u \\
      & = & \int\! 2 (u^2 - 1 ) \,\mathrm{d} u \\
      & = & \dfrac{2 u^3}{3} - 2 u + C
    \end{eqnarray*}
    
    \item Sustituir de nuevo $u$ por $g ( x )$.
    
    \[\int\! \dfrac{e^{2 x}}{\sqrt{e^x + 1}} \,\mathrm{d} x = \dfrac{2 u^3}{3} - 2 u + C = \dfrac{2}{3} \sqrt{( e^x + 1 )^3} - 2 \sqrt{e^x + 1}+C\]
  \end{enumerate}
\end{example}

\begin{example}
  Calcular la integral:
  \[\int\! \sqrt{1-x^2}\,\mathrm{d}x\]
  Utilizaremos el método de sustitución según el segundo esquema.
  \begin{enumerate}
  \item Buscar una sustitución conveniente: $x=g(u)$.
    \[x=\sen u\]
  \item Expresar $\mathrm{d}x$ en función de $u$: $\mathrm{d}x=g'(u)\mathrm{d}u$.
    \[\mathrm{d}x=\cos u\mathrm{d}u\]
  \item Sustituir $x$ por $g(u)$, y $\mathrm{d}x$ por la expresión obtenida en el paso anterior (llegados a este paso, en el integrando solo debería aparecer $u$, y no $x$), e integrar:
    \begin{eqnarray*}
      \int\!\sqrt{1-x^2}\,\mathrm{d}x & = & \int\!\sqrt{1-\sen^2u}\cos u\,\mathrm{d}u \\
      & = & \int\!\cos^2u\,\mathrm{d}u \\
      & = & \int\!\dfrac{1-\cos 2u}{2}\,\mathrm{d}u \\
      & = & \dfrac{1}{2}u+\dfrac{1}{4}\sen 2u \\
      & = & \dfrac{1}{2}u+\dfrac{1}{2}\sen u\cos u
    \end{eqnarray*}
  \item Deshacer el cambio (sustituir $u$ por $g^{-1}(x)$).
    \[x=\sen u \Rightarrow u=\text{arcsen }x\]
    \[\int\!\sqrt{1-x^2}\,\mathrm{d}x = \dfrac{1}{2}\text{arcsen }x+\dfrac{1}{2}x\sqrt{1-x^2}\]
  \end{enumerate}
\end{example}

\subsection*{Integración por partes}

\begin{theorem}
  Dadas dos funciones derivables $f$ y $g$, se verifica:
  \[\int\!f(x)\cdot g'(x)\,\mathrm{d}x=f(x)\cdot g(x)-\int\!f'(x)\cdot g(x)\,\mathrm{d}x\]
\end{theorem}

\begin{remark}
  Este teorema es una consecuencia inmediata de la fórmula de la derivada de un producto.
\end{remark}

\begin{remark}
  Este teorema se puede expresar también del siguiente modo:
  \[\int\!u\mathrm{d}v = uv-\int\!v\mathrm{d}u\]
  Simplemente, se está llamando $u=f(x)$ y $v=g(x)$, e identificando $\mathrm{d}u=u'(x)\mathrm{d}x$ y $\mathrm{d}v=v'(x)\mathrm{d}x$.
\end{remark}

\begin{remark}
  La aplicación del método exige identificar (o elegir) qué parte del integrando es $f(x)$ (o $u$) y qué parte es $g'(x)$ (o $\mathrm{d}v$). Al identificar (o elegir) esas partes del integrando, conviene tener en cuenta que:
  \begin{itemize}
  \item Hay que calcular $g(x)$ a partir de $g'(x)$ (o $v$ a partir de $\mathrm{d}v$), es decir, hay que hallar $g(x)=\int\!g'(x)\,\mathrm{d}x$. Por tanto, hay que elegir $g'$ de modo que sepamos cómo calcular su integral.
  \item La integral que resulta, $\int\!f'g$ (o bien, $\int v\mathrm{d}u$), debe ser más sencilla que la que queremos calcular. En general, conviene que $f'$ sea más simple que $f$.
  \end{itemize}
\end{remark}

\begin{remark}
  La constante de integración elegida al hallar $g(x)$ a partir de $g'(x)$ quedará absorbida por la constante de integración de la segunda integral que hay que resolver una vez aplicada la fórmula, por lo que al calcular $g(x)$ solemos tomar constante de integración nula.
\end{remark}

\begin{example}
  Calcular la integral
  \[\int\!x e^{3x}\,\mathrm{d}x\]

    Tomamos:

    \[f ( x ) = x ; g' ( x ) = e^{3 x}\]
    
    con lo que tenemos:

    \[f' ( x ) = 1 ; g ( x ) = \frac{1}{3} e^{3 x}\]
    
    Aplicando la fórmula:
    \[\int x e^{3 x} d x = x \cdot \frac{1}{3} e^{3 x} - \int 1 \cdot \frac{1}{3} e^{3 x} d x = \frac{1}{3} x e^{3 x} - \frac{1}{9} e^{3 x}\]
\end{example}

\begin{example}
  Calcular la integral
  \[\int\!\ln x\,\mathrm{d}x\]

    Tomamos: 
    \[f ( x ) = \ln x ; g' ( x ) = 1\]
    
    con lo que tenemos:
    \[f' ( x ) = \frac{1}{x} ; g ( x ) = x\]
    
    Aplicando la fórmula:
    \[\int \ln x d x = x \ln x - \int \frac{1}{x} \cdot x d x = x \ln x - x\]
\end{example}

\begin{example}
  Calcular:
\[\int\!e^{ax}\sen bx\,\mathrm{d}x\]

      Tomamos:
      \[f ( x ) = \tmop{sen} b x ; g' ( x ) = e^{a x}\]
    
    con lo que tenemos:
    \[f' ( x ) = b \cos b x ; g ( x ) = \frac{1}{a} e^{ax}\]
    
    Aplicando la fórmula:
    \[\int e^{a x} \tmop{sen} b x d x = \frac{1}{a} e^{ax} \tmop{sen} b x - \frac{b}{a} \int e^{a x} \cos b x d x\]
    
    En la segunda integral, volvemos a aplicar integración por partes
    haciendo:
    \[f ( x ) = \cos b x \Rightarrow f' ( x ) = - b \tmop{sen} b x ; g' ( x ) = e^{a x} \Rightarrow g ( x ) = \frac{1}{a} e^{a x}\]
    
    \[\int e^{a x} \tmop{sen} b x d x = \frac{1}{a} e^{a x} \tmop{sen} b x - \frac{b}{a} \left( \frac{1}{a} e^{a x} \cos b x - \int \frac{- b}{a} e^{a
    x} \tmop{sen} b x d x \right) = \frac{1}{a} e^{a x} \tmop{sen} b x - \frac{b}{a^2} e^{a x} \cos b x - \frac{b^2}{a^2} \int e^{a x} \tmop{sen} b x d x\]
    
    Llamando $\displaystyle I = \int e^{a x} \tmop{sen} b x d x$, lo anterior se puede
    escribir como una ecuación:
    
    \[I = \frac{1}{a} e^{a x} \tmop{sen} b x - \frac{b}{a^2} e^{a x} \cos b x - \frac{b^2}{a^2} \cdot I\]
    
    Despejando $I$, se obtiene:
    
    \[I = \int e^{a x} \tmop{sen} b x d x = \frac{e^{a x}}{a^2 + b^2} ( a \tmop{sen} b x - b \cos b x ) \]

\end{example}

\subsection*{Integración por descomposición en fracciones simples}

\begin{theorem}
  Sea $R(x)=\dfrac{P(x)}{Q(x)}$ una función racional propia (con el grado del numerador menor que el del denominador), siendo la factorización del denominador:
\[Q(x)=a(x-r_1)^{p_1}\cdots (x-r_k)^{p_k}(x^2+m_1x+n_1)^{q_1}\cdots(x^2+m_jx+n_j)^{q_j}\]
Dicha función racional puede expresarse como la siguiente suma de fracciones algebraicas (\emph{fracciones simples}):
\begin{eqnarray*}
R(x) & = & \dfrac{A_{1,1}}{x-r_1} + \cdots + \dfrac{A_{1,p_1}}{(x-r_1)^{p_1}} + \cdots + \dfrac{A_{k,1}}{x-r_k} + \cdots + \dfrac{A_{k,p_k}}{(x-r_k)^{p_k}} + \cdots \\ 
& & + \dfrac{B_{1,1}x+C_{1,1}}{x^2+m_1x+n_1} + \cdots + \dfrac{B_{1,q_1}}{(x^2+m_1x+n_1)^{q_1}} + \cdots + \dfrac{B_{j,1}x+C_{j,1}}{x^2+m_jx+n_j} + \cdots + \dfrac{B_{j,q_j}x+C_{j,q_j}}{(x^2+m_jx+n_j)^{q_j}}
\end{eqnarray*}
\end{theorem}

\begin{remark}
  La factorización del denominador puede contener dos tipos de factores (además de un factor constante): factores de primer grado, $x-r_i$, y factores de segundo grado irreducibles, $x^2+m_jx+n_j$. Cada factor puede, además, aparecer repetido cierto número de veces (\emph{grado de multiplicidad}): $(x-r_i)^{p_i}$; $(x^2+m_jx+n_j)^{q_j}$.

  Por cada factor se habrán de escribir tantas fracciones simples como veces esté repetido dicho factor, teniendo cada una de ellas como denominador al factor correspondiente elevado a un exponente diferente entre $1$ y el grado de multiplicidad del factor. Por ejemplo, si el denominador tiene un factor $(x-5)^3$, habrá que escribir tres fracciones simples correspondientes a ese factor: una con denominador $x-5$, otra con denominador $(x-5)^2$ y otra con denominador $(x-5)^3$.

  Las fracciones simples correspondientes a los factores de primer grado llevan como numerador una constante.

  Las fracciones simples correspondientes a los factores de segundo grado llevan como numerador un polinomio de primer grado.
\end{remark}

\begin{remark}
  Si la fracción es impropia (grado del numerador mayor o igual que el del denominador) se podrá descomponer en la suma de un polinomio y una fracción propia, mediante división euclídea (dividendo entre divisor igual a cociente más resto entre divisor):
\[\dfrac{D(x)}{d(x)}=P(x)+\dfrac{r(x)}{d(x)}\]
\end{remark}

\begin{remark}
  Una vez descompuesta la fracción en suma de un polinomio y una suma de fracciones simples, se aplica la linealidad de la integral para integrar cada fracción simple por separado. Las fracciones simples se llaman así porque sus integrales son ``simples'' (inmediatas). En concreto, podemos encontrar cuatro tipos de fracciones simples, y sus integrales son las siguientes:
  \begin{enumerate}
  \item Factores de primer grado con exponente $1$. Integral logarítmica:
    \[\int\!\dfrac{A}{x-r}\;\mathrm{d}x=A\ln |x-r|\]
  \item Factores de primer grado con exponente mayor que $1$. Integral potencial:
    \[\int\!\dfrac{A}{(x-r)^p}\;\mathrm{d}x=\dfrac{A}{(-p+1)(x-r)^{p-1}}\]
  \item Factores de segundo grado con exponente $1$. Integral logarítmica más arcotangente. En el ejemplo siguiente se indica cómo resolver este tipo de integrales.
  \item Factores de segundo grado con exponente mayor que $1$. No las estudiaremos este curso.
  \end{enumerate}
\end{remark}

\begin{example} Calcular

\[\int\!  \dfrac{x^4 + x^3 + 4 x^2 - 3 x + 6}{x^4 - x^3 - x + 1}\,\mathrm{d}x\]
  \begin{enumerate}
    \item Mediante división de polinomios, obtener una fracción con grado del
    numerador menor que grado del denominador:
    
    \[\frac{x^4 + x^3 + 4 x^2 - 3 x + 6}{x^4 - x^3 - x + 1} = 1 + \frac{2 x^3 + 4 x^2 - 2 x + 5}{x^4 - x^3 - x + 1}\]
    
    \item Factorizar el denominador:

      \[x^4 - x^3 - x + 1 = ( x - 1 )^2 ( x^2 + x + 1 )\]
    
    \item Escribir la ``descomposición en fracciones simples'':
    
    \[\frac{2 x^3 + 4 x^2 - 2 x + 5}{x^4 - x^3 - x + 1} = \frac{a}{x - 1} + \frac{b}{( x - 1 )^2} + \frac{c x + d}{x^2 + x + 1}\]
    
    \item Utilizando como mínimo denominador común la factorización del paso
    b, realizar la suma de fracciones de la derecha:
    
    \begin{eqnarray*}
      \frac{a}{x - 1} + \frac{b}{( x - 1 )^2} + \frac{c x + d}{x^2 + x + 1} & = & \frac{a ( x - 1 ) ( x^2 + x + 1 ) + b ( x^2 + x + 1 ) + ( c x + d ) ( x - 1 )^2}{( x - 1 )^2 ( x^2 + x + 1 )} \\
      & = & \frac{( a + c ) x^3 + ( b - 2 c + d ) x^2 + ( b + c - 2 d ) x + ( - a + b + d )}{( x - 1 )^2 ( x^2 + x + 1 )}
    \end{eqnarray*}
    
    \item Igualar los numeradores y resolver el sistema obtenido:
    
    \[\left\{\begin{array}{l}
      a + c = 2\\
      b - 2 c + d = 4\\
      b + c - 2 d = - 2\\
      - a + b + d = 5
    \end{array}\right. \Leftrightarrow \left\{\begin{array}{l}
      a = 1\\
      b = 3\\
      c = 1\\
      d = 3
    \end{array}\right.\]
    
    \item Resolver cada una de las integrales de las fracciones simples
    obtenidas:
    
    \[\int \frac{x^4 + x^3 + 4 x^2 - 3 x + 6}{x^4 - x^3 - x + 1} d x = \int \left( 1 + \frac{1}{x - 1} + \frac{3}{( x - 1 )^2} + \frac{x + 3}{x^2 + x + 1} \right) d x\]
    
    \[\int 1 d x = x ; \int \frac{1}{x - 1} d x = \ln |x - 1| ; \int \frac{3}{( x - 1 )^2} d x = \frac{- 3}{x - 1}\]
    
    La cuarta integral se descompondrá en otras dos, de modo que en la primera, el numerador sea exactamente la derivada del denominador, para que sea inmediata de tipo logarítmico, y la segunda se reescribirá ``completando el cuadrado'' para que sea de tipo arcotangente:
    
    \begin{eqnarray*}
      \int \frac{x + 3}{x^2 + x + 1} d x & = & \int \frac{\frac{1}{2} ( 2 x + 1 ) + \frac{5}{2}}{x^2 + x + 1} d x \\
      & = & \frac{1}{2} \int \frac{2 x + 1}{x^2 + x + 1} d x + \int \frac{\frac{5}{2}}{x^2 + x + 1} d x \\
      & = & \frac{1}{2} \ln |x^2 + x + 1| + \frac{5}{2} \int \frac{1}{\left( x + \frac{1}{2} \right)^2 + \frac{3}{4}} d x \\
      & = & \frac{1}{2} \ln |x^2 + x + 1| + \frac{5}{2} \int \frac{\frac{4}{3}}{\left( \frac{2 x + 1}{\sqrt{3}} \right)^2 + 1} d x \\
      & = & \frac{1}{2} \ln |x^2 + x + 1| + \frac{5}{\sqrt{3}} \tmop{arctg} \left(\frac{2 x + 1}{\sqrt{3}} \right)
    \end{eqnarray*}
    
    Juntando todo:
    
    \[I = x + \ln |x - 1| - \frac{3}{x - 1} + \frac{1}{2} \ln |x^2 + x + 1| + \frac{5}{\sqrt{3}} \tmop{arctg} \left( \frac{2 x + 1}{\sqrt{3}} \right)\]
  \end{enumerate}

\end{example}

\newpage\section{Concepto de integral definida}

\begin{definition}
    Dada una función $f ( x )$ y un intervalo $[ a, b ]$, se definen:
  \begin{itemize}
    \item partición de $[ a, b ]$ es un subconjunto de $[ a, b ]$ de la forma
    $P = \{ t_i / i = 0 \ldots n, t_0 = a, t_n = b \}$;
    
    \item suma superior de $f$ sobre una partición $P$: $U ( f, P ) =
    \underset{i = 1}{\overset{n}{\sum}} M_i \cdot ( t_i - t_{i - 1} )$, siendo
    $M_i = \sup \{ f ( x ) / t_i \leqslant x \leqslant t_{i - 1} \}$;
    
    \item suma inferior de $f$ sobre una partición $P$: $L ( f, P ) =
    \underset{i = 1}{\overset{n}{\sum}} m_i \cdot ( t_i - t_{i - 1} )$, siendo
    $m_i = \inf \{ f ( x ) / t_i \leqslant x \leqslant t_{i - 1} \}$.
  \end{itemize}
  Se dice que {\tmstrong{$f ( x )$ es integrable sobre $[ a, b ]$}} si existe
  un único número $I$ que cumpla $L ( f, P ) \leqslant I \leqslant U ( f, P )$
  para toda partición $P$ de $[ a, b ]$. A dicho número se le llama
  {\tmstrong{integral de $f$ sobre $[ a, b ]$}}, y se representa por:
  
    \[I = \int_a^b f ( x ) d x\]
  
  También se define:

    \[\int_b^a f ( x ) d x = - \int_a^b f ( x ) d x\]
  
  A esta integral se le llama también {\tmstrong{integral definida}} para
  distinguirla de la indefinida. Al intervalo $[ a, b ]$ se le llama
  {\tmstrong{intervalo de integración}}. A los extremos de dicho intervalo,
  $a$ y $b$, se les llama {\tmstrong{límites de integración}}. A la función $f
  ( x )$ se le llama {\tmstrong{integrando}}.
\end{definition}

\begin{figure}
  \centering
  \includegraphics[width=15cm]{sumasrieman_cropped.pdf}
  \caption{Sumas inferior (izquierda) y superior (derecha) para una partición}
\end{figure}

\begin{remark}
  La variable utilizada dentro de la integral es una variable \emph{muda}. Se puede utilizar cualquier letra, e incluso no escribirla. Los tres símbolos siguientes representan lo mismo (el mismo número):
\[\int_a^b\! f(x)\,\mathrm{d}x=\int_a^b\!f(t)\,\mathrm{d}t=\int_a^b\!f\]
\end{remark}

\begin{remark}
  Esta definición corresponde a la \emph{integral de Riemann}. Posteriormente se han desarrollado otros conceptos de integral más generales, que incluyen a la de Riemann, como la \emph{integral de Lebesgue} o la \emph{integral de Henstock}.
\end{remark}

\begin{remark}
  La definición de la integral está estrechamente relacionada con el área que la gráfica de $f$ delimita con el eje, pero el concepto es más general: tiene aplicaciones que no son geométricas. Se trata, en general, de una herramienta para calcular \emph{sumas de infinitos sumandos infinitamente pequeños}.
\end{remark}

\begin{theorem}
  [Propiedades de la integral] Las integrales definidas verifican las siguientes propiedades:
  \begin{enumerate}
    \item $\displaystyle\int_a^b k \cdot f ( x ) d x = k \cdot \int_a^b f ( x ) d x$
    
    \item $\displaystyle\int_a^b [ f ( x ) + g ( x ) ] d x = \int_a^b f ( x ) d x + \int_a^b g ( x ) d x$
    
    \item $\displaystyle\int_a^b f ( x ) d x = \int_a^c f ( x ) d x + \int_c^b f ( x ) d x, \tmop{para} \tmop{todo} c \in [ a, b ]$
    
    \item $\displaystyle\int_a^a f ( x ) d x = 0$
    
    \item $\displaystyle\int_a^b f ( x ) d x = \int_{a + c}^{b + c} f ( x - c ) d x$
    
    \item $\displaystyle\int_a^b f ( x ) d x = k \int_{a / k}^{b / k} f ( k x ) d x$
  \end{enumerate}
\end{theorem}

\newpage\section{Teorema Fundamental del Cálculo}

\begin{theorem}
  [Teorema Fundamental del Cálculo] Si $f ( x )$ es una función continua en un intervalo $I$, con $a\in I$, la función $F ( x )$ definida por:
  
  \[F ( x ) = \int_a^x f ( t ) d t\]
  
\noindent es una función primitiva de $f ( x )$ en el interior de $I$, es decir: $F' ( x ) = f ( x ), \forall x \in \tmop{int}(I)$.
\end{theorem}

\begin{remark}
  Lo que dice este teorema es que la integral (área) y la derivada son ``inversas''.
\end{remark}

\begin{remark}
  La función $F$ puede no ser elemental. Tal es el caso de $F(x)=\frac{2}{\sqrt{\pi}}\int_0^x e^{-t^2} d t$. Puesto que $f(x)=e^{-x^2}$ es continua, la función $F(x)$ es una primitiva de $f$ (por tanto, es derivable, y, por tanto, también continua). Sin embargo, está demostrado que no es una función elemental (es decir, no podrá expresarse como una combinación de funciones algebraicas, logarítmicas,  exponenciales y trigonométricas, mediante suma, producto, cociente y composición). Dicho de otra forma: no existe una ``fórmula'' para la función $F(x)$ (que no sea la propia integral). Pero eso no significa que no se puedan calcular sus valores: son las áreas bajo la curva $y=\frac{2}{\sqrt{\pi}}e^{-x^2}$. Esta función $F(x)$ tiene mucha importancia en estadística, y se llama \emph{función error}. Hay bastantes funciones importantes no elementales definidas mediante integrales.
\end{remark}

\begin{example}
  Se considera la función definida por:
  \[F(x)=\int_0^x \sqrt{t^3+1} d t\]
  Se pide hallar $F'(1)$.

  Sea $f(x)=\sqrt{x^3+1}$. La función $f$ es continua en $\mathbb{R}$. Por lo tanto, según el Teorema Fundamental del Cálculo, $F$ es derivable, y su derivada en $(0,\infty)$, viene dada por:

  \[F'(x) = f(x)\]

  Por lo tanto,

  \[F'(1) = f(1) = \sqrt{1^3+1} = \sqrt{2}\]
\end{example}

\begin{theorem}
  [Regla de Barrow] Sea una función $f ( x )$ integrable sobre $[ a, b ]$. Si existe una función $F$ continua en $[a,b]$, que sea primitiva de $f$ en $(a,b)$ (es decir, tal que $F'(x)=f(x),\forall x\in(a,b)$), entonces:
  
  \[\int_a^b f ( x ) d x = F ( b ) - F ( a )\]
\end{theorem}

\begin{remark}
  Este teorema recibe también el nombre de Segundo Teorema Fundamental del Cálculo.
\end{remark}

\begin{remark}
  Si $f$ es continua, entonces la existencia de una primitiva continua está garantizada por el Teorema Fundamental del Cálculo. De modo que la regla de Barrow se enuncia a veces diciendo que si $f$ es continua, entonces $\int_a^b f=F(b)-F(a)$, siendo $F$ una primitiva cualquiera de $f$.
\end{remark}

\begin{example}
  Calcular $\displaystyle\int_{-8}^3\!\sqrt{|x|+1}\,\mathrm{d}x$.

  La función integrando es, en realidad, una función definida a trozos:

\[f(x)=\sqrt{|x|+1}=\left\{\begin{array}{ll}\sqrt{-x+1}&\text{si }x<0\\ \sqrt{x+1}&\text{si }x\geq0\end{array}\right.\]

Aplicando la propiedad de aditividad sobre el intervalo de integración, podemos dividir la integral en dos integrales:

\begin{eqnarray*}
\int_{-8}^3f(x)\,\mathrm{d}x & = & \int_{-8}^0\!f(x)\,\mathrm{d}x+\int_0^3\!f(x)\,\mathrm{d}x \\
& = & \int_{-8}^0\!\sqrt{-x+1}\,\mathrm{d}x + \int_0^3\!\sqrt{x+1}\,\mathrm{d}x \\
& = & \left[\dfrac{-2}{3}\sqrt{(-x+1)^3}\right]_{-8}^0 + \left[\dfrac{2}{3}\sqrt{(x+1)^3}\right]_0^3 \\
& = & \dfrac{2}{3}\left(-\sqrt{1} + \sqrt{9^3} + \sqrt{4^3} - \sqrt{1} \right) \\
& = & \dfrac{2}{3}\left(-1+27+8-1\right) \\
& = & 22
\end{eqnarray*}
\end{example}

\begin{example}
  Dada la función $\displaystyle F(X)=\int_{\sen x}^{5x}\!\sqrt{t^2+1}\,\mathrm{d}t$, hallar $F'(x)$.

  Por la aditividad sobre el intervalo de integración, podemos escribir:

  \[F(x)=\int_{\sen x}^0\!\sqrt{t^2+1}\,\mathrm{d}t + \int_0^{5x}\!\sqrt{t^2+1}\,\mathrm{d}t = -\int_0^{\sen x}\!\sqrt{t^2+1}\,\mathrm{d}x + \int_0^{5x}\!\sqrt{t^2+1}\,\mathrm{d}t\]

  Llamemos:

  \[G(x)=\int_0^x\!\sqrt{t^2+1}\,\mathrm{d}t\]

  De modo que,

  \[F(x)=G(5x)-G(\sen x)\]

  Luego, por la regla de la cadena:

  \[F'(x)=5G'(5x)-(\cos x)G'(\sen x)\]

  Según el teorema fundamental del cálculo, dado que el integrando de $G(x)$ es una función continua en $\mathbb{R}$, $G(x)$ es una primitiva de dicho integrando, luego:

  \[G'(x)=\sqrt{x^2+1}\]

  Sustituyendo en la expresión obtenida para $F'(x)$, tenemos que:

  \[F'(x)=5G'(5x)-(\cos x)G'(\sen x)=5\sqrt{25x^2+1}-(\cos x)\sqrt{\sen^2x+1}\]
\end{example}

\newpage\section{Aplicaciones de la integral definida}

\begin{theorem}
  [Cálculo de áreas] El área delimitada por una función f(x) y el eje OX entre dos abscisas $a < b$, tales que $f ( x ) \geqslant 0, \forall x \in (a,b)$, viene dada por: $A = \displaystyle\int_a^b |f ( x )| d x$.
\end{theorem}

\begin{remark}
  Es bastante sencillo deducir del teorema anterior que el área del recinto plano acotado limitado por las gráficas de dos funciones $f$ y $g$ entre $x=a$ y $x=b$ vendrá dada por $\displaystyle\int_a^b\!|f(x)-g(x)|\,\mathrm{d}x$.
\end{remark}

\begin{example}
  Hallar el área del recinto plano acotado limitado por las gráficas de las funciones $f(x)=x^2-4x$ y $g(x)=2x-5$.

El recinto se puede ver en la ilustración siguiente:

\begin{center}
\includegraphics[width=8cm]{ejemploarea_cropped.pdf}
\end{center}

Los puntos en los que se cortan la recta y la parábola, que serán los límites de integración, son las soluciones de la ecuación:
\[f(x)=g(x) \iff x^2-4x=2x-5 \iff x^2-6x+5=0 \iff x\in\{1,5\}\]

Dado que la recta se encuentra por encima de la parábola, el área vendrá dada por:
\[A = \int_1^5\![g(x)-f(x)]\,\mathrm{d}x = \int_1^5\!(2x-5-(x^2-4x))\,\mathrm{d}x = \int_1^5\!(-x^2+6x-5)\,\mathrm{d}x = \left[\dfrac{-x^3}{3}+3x^2-5x\right]_1^5 = \dfrac{32}{3}\]
\end{example}

\begin{theorem}
  [Secciones transversales] Sea $A(x)$ una función cuyo valor en $x=x_0$ es el área de una sección transversal de un sólido por un plano perpendicular al eje $OX$ en $x=x_0$. Si $A(x)$ es integrable el volumen de dicho sólido, vendrá dado por:
\[V=\int_a^b\!A(x)\,\mathrm{d}x\]
siendo $a$ la abscisa del punto del sólido situado más a la izquierda, y $b$ la del punto situado más a la derecha.
\end{theorem}

\begin{figure}
  \centering
  \includegraphics[width=10cm]{seccionestransversales_cropped.pdf}
  \caption{Cálculo de volúmenes por secciones transversales.}
\end{figure}

\begin{example}
  Hallar el volumen común a dos esferas de igual radio, $r$, si el centro de cada una se encuentra en la superficie de la otra.

  Situando el eje de $OX$ sobre la recta que une ambos centros, y el origen de coordenadas en el punto medio entre ellos, es claro que todas las secciones transversales del volumen pedido son círculos cuyo centro está en el eje $OX$, y cuyo radio, $R(x)$, verifica la siguiente ecuación (la distancia entre los centros es $r$):
\[\left(\dfrac{r}{2}+x\right)^2+\left(R(x)\right)^2=r^2 \iff R(x)=\sqrt{r^2-\left(\dfrac{r}{2}+x\right)^2}\]

El área de las secciones transversales vendrá dada por:
\[A(x)=\pi \left(R(x)\right)^2=\pi\left[r^2-\left(\dfrac{r}{2}+x\right)^2\right]\]

El volumen pedido será:
\[\int_{-r/2}^{r/2}A(x)\,\mathrm{d}x = \int_{-r/2}^{r/2}\!\pi\left[r^2-\left(\dfrac{r}{2}+x\right)^2\right]\,\mathrm{d}x = \left[\pi\left(r^2x-\dfrac{1}{3}\left(\dfrac{r}{2}+x\right)^3\right)\right]_{-r/2}^{r/2} = \dfrac{2\pi r^3}{3}\]
\end{example}

\begin{definition}
  [Sólido de revolución] Es un cuerpo geométrico generado al girar una región plana alrededor de un eje.
\end{definition}

\begin{figure}
  \centering
  \includegraphics[width=10cm]{solidorevolucion_cropped.pdf}
  \caption{Sólido de revolución}
\end{figure}

\begin{example}
  Un cono es un sólido de revolución generado al girar un triángulo rectángulo alrededor de uno de sus catetos.

  Un cilindro es un sólido de revolución generado al girar un rectángulo alrededor de uno de sus lados.

  Se obtiene también un sólido de revolución al girar alrededor del eje de abscisas la región plana delimitada por la gráfica de una función $f$, el eje de absicsas y las rectas $x=a$ y $x=b$.
\end{example}

\begin{theorem}
  [Cálculo de volúmenes: método del disco] El volumen del sólido de revolución obtenido al girar en torno al eje $OX$ la región plana deliimitada por la gráfica de la función $f$, el eje de abscisas y las rectas $x=1$, $x=b$, viene dado por:
\[V=\int_a^b\!\pi\left(f(x)\right)^2\,\mathrm{d}x\]
\end{theorem}

\begin{figure}
  \centering
  \includegraphics[width=18cm]{disco_cropped.pdf}
  \caption{Cálculo de volúmenes: método del disco}
\end{figure}

\begin{remark}
  La fórmula anterior se deduce dividiendo el volumen en cilindros de altura $\mathrm{d}x$, con el eje en el eje de abscisas, de modo que su radio es $f(x)$.
\end{remark}

\begin{remark}
  También se puede aplicar al cálculo de volúmenes engendrados al girar un recinto plano en torno al eje vertical: habría que utilizar la función inversa de $f$, de modo que $x=f^{-1}(y)$, y realizar la integral en la variable $y$, entre $f^{-1}(a)$ y $f^{-1}(b)$.
\end{remark}

\begin{remark}
  Para calcular el volumen generado por un recinto delimitado por dos curvas, habría que restar el volumen generado por la curva inferior del volumen generado por la curva superior, resultando:
\[V=\int_a^b\!\pi\left[\left(f(x)\right)^2-\left(g(x)\right)^2\right]\,\mathrm{d}x\]
\end{remark}

\begin{example}
  Hallar el volumen del sólido de revolución obtenido al rotar sobre el eje OX la región limitada por la curva $y=x^2$ y las rectas $y=\frac{x}{2}$, $x=1$ y $x=2$.

  \begin{center}\includegraphics[width=8cm]{discoejemplo_cropped.pdf}\end{center}

  Tendremos que restar al volumen generado por la parábola, el ``hueco'' interior generado por la recta $y=x/2$:

  \begin{center}\includegraphics[width=8cm]{discoejemplo2_cropped.pdf}\end{center}

  Aplicaremos el método del disco:

  \begin{eqnarray*}V & = & \int_1^2\pi\left[f^2(x)-g^2(x)\right] dx \\
    & = & \int_1^2\pi\left[(x^2)^2-\left(\dfrac{x}{2}\right)^2\right] dx \\
    & = & \pi\left[\dfrac{x^5}{5}-\dfrac{x^3}{12}\right]_1^2 \\
    & = & \pi\left(\dfrac{32}{5}-\dfrac{2}{3}-\dfrac{1}{5}+\dfrac{1}{12}\right) \\
    & = & \dfrac{337\pi}{60}
  \end{eqnarray*}
\end{example}

\begin{theorem}
  [Cálculo de volúmenes: método de la cáscara] El volumen del sólido de revolución generado al girar en torno al eje vertical el recinto delimitado por la gráfica de la función $f$, el eje horizontal y las rectas $x=a\geq0$, $x=b>a$, viene dado por:
\[V=\int_a^b\!2\pi x|f(x)|\,\mathrm{d}x\]
\end{theorem}

\begin{figure}
  \centering
  \includegraphics[width=18cm]{cascara_cropped.pdf}
  \caption{Cálculo de volúmenes: método de la cáscara}
\end{figure}

\begin{remark}
  La fórmula anterior se obtiene dividiendo el volumen en ``cáscaras'' cilíndricas de grosor $\mathrm{d}x$, cuyo eje es el eje vertical, de modo que su radio interior es $x$, su radio exterior es $x+\mathrm{d}x$, y su altura es $f(x)$.
\end{remark}

\begin{remark}
  Al igual que en el método del disco, es posible aplicar la fórmula a volúmenes engendrados girando en torno al eje horizontal, intercambiando $x$ por $y$, y utilizando la función inversa $x=f^{-1}(y)$. También se puede aplicar a recintos delimitados por dos funciones, utilizando la diferencia de ambas.
\end{remark}

\begin{example}
  Hallar el volumen generado al rotar alrededor del eje OY la región comprendida entre la parábola $y=x^2-4x$, la recta $y=x+2$ y las rectas $x=1$ y $x=3$.

  \begin{center}
    \includegraphics[width=8cm]{cascaraejemplo1_cropped.pdf}\includegraphics[width=8cm]{cascaraejemplo2_cropped.pdf}
  \end{center}

  Utilizaremos el método de la cáscara. Si llamamos, $g(x)=x^2-4x$ y $f(x)=x+2$, tenemos que:

  \begin{eqnarray*} V & = & \int_1^3 2\pi x\left[f(x)-g(x)\right] dx \\
    & = & \int_1^3 2\pi x\left[x+2-(x^2-4x)\right] dx \\
    & = & \int_1^3 2\pi (-x^3+5x^2+2x) dx\\
    & = & 2\pi\left[-\dfrac{x^4}{4}+\dfrac{5x^3}{3}+x^2\right]_1^3\\
    & = & \dfrac{188\pi}{3}
  \end{eqnarray*}

\end{example}

\part{Estadística}

\chapter{Probabilidad}

\newpage\section{Modelos de probabilidad}

\begin{definition}
  [Experimento aleatorio] Un experimento aleatorio es un experimento cuyo resultado no se puede predecir.
\end{definition}

\begin{remark}
  Un ``experimento'' es un proceso de observación de una característica de la realidad, realizado bajo condiciones controladas. Cuando se realiza el experimento, se obtiene un resultado (se observa un cierto ``valor'' de dicha característica). Un experimento se puede, al menos teóricamente, realizar muchas veces. La estadística nos servirá para responder a preguntas sobre las observaciones no realizadas todavía utilizando la información que tengamos del experimento (condiciones de realización, resultados de otras realizaciones, leyes físicas aplicables, etc.).
\end{remark}

\begin{remark}
  La aleatoriedad de una característica se refiere a nuestra capacidad para conocer los valores que tiene o que tendrá, no a la característica misma. Por tanto, un mismo fenómeno puede ser aleatorio para una persona y no serlo para otra.
\end{remark}

\begin{definition}
  [Modelo de probabilidad] Un modelo de probabilidad está formado por:
  \begin{itemize}
  \item Un espacio muestral.
  \item Una ley de probabilidad.
  \end{itemize}

\end{definition}

\begin{remark}
  Los modelos de probabilidad son una descripción matemática de los experimentos o fenómenos aleatorios. En los siguientes apartados estudiaremos sus elementos detalladamente. Ahora damos solo una descripción aproximada:
  \begin{itemize}
  \item Espacio muestral: describe todos los posibles resultados.
  \item Ley de probabilidad: mide el grado de incertidumbre de cada uno de los resultados del espacio muestral.
  \end{itemize}
\end{remark}

\newpage\section{Espacio muestral}

\begin{definition}
  [Espacio muestral] Es el conjunto de todos los resultados posibles de un experimento aleatorio. Se representa mediante la letra $E$, o también con $\Omega$.
\end{definition}

\begin{remark}
  Los conceptos básicos relativos a la probabilidad se definen utilizando conjuntos. Por esa razón, conviene conocer las ideas y la simbología básica de la teoría de conjuntos. En un anexo pueden encontrarse los conocimientos que van a ser necesarios para entender estos apuntes.
\end{remark}

\begin{remark}
  Como ya hemos observado, siempre que se realiza el experimento aleatorio se obtiene un resultado (si no se obtiene un resultado no se considera realizado el experimento).
\end{remark}

\begin{remark}
  Aparentemente, podemos asociar distintos espacios muestrales a un mismo experimento. Consideremos, por ejemplo, el experimento que consiste en lanzar un dado al aire. Podríamos decir que su espacio muestral es $E=\{1,2,3,4,5,6\}$. Pero también podríamos decir que hay dos resultados posibles, que el número sea par o impar, y entonces el espacio muestral sería $E=\{\text{Par, Impar}\}$. En realidad se trata de dos experimentos ligeramente distintos. Recuérdese que un experimento es un proceso de observación de una característica. En el primer caso la característica observada es el valor del número que queda en la cara superior al posarse en el suelo un dado lanzado desde cierta altura. En el segundo, la característica observada es la paridad de dicho número en lugar de su valor.
\end{remark}

\begin{definition}
  [Tipos de espacios muestrales] Los espacios muestrales pueden ser de dos tipos:
  \begin{itemize}
  \item Discretos: finitos o infinitos numerables.
  \item Continuos: infinitos no numerables.
  \end{itemize}
\end{definition}

\begin{example}
  Ejemplos de espacios muestrales discretos:
  \begin{itemize}
  \item Lanzar un dado al aire, y observar el número que queda en la cara superior: $E=\{1,2,3,4,5,6\}$.
  \item Extraer, al azar, una carta de una baraja española y observar su palo: $E=\{\text{Bastos, Copas, Espadas, Oros}\}$.
  \item Escoger un tornillo fabricado por una máquina y observar si es o no defectuoso: $E=\{\text{Defectuoso, No defectuoso}\}$.
  \item Encender un móvil e introducir un código PIN al azar y ver si coincide con el del teléfono: $E=\{\text{Acierto, Fallo}\}$.
  \item Lanzar una moneda al aire hasta que salga una cara, y contar el número lanzamientos: $E=[1,\infty)\cap\mathbb{N}$.
  \end{itemize}
  Ejemplos de espacios muestrales continuos:
  \begin{itemize}
  \item Elegir al azar un bebé recién nacido y medir su peso: $E=(0,\infty)$.
  \item Lanzar un dardo a una diana y medir la distancia del punto de impacto al centro de la diana: $E=[0,R]$, siendo $R$ el radio de la diana.
  \item Medir la temperatura máxima en un día cualquiera en un cierto lugar: $E=(-273,\infty)$, en grados centígrados.
  \end{itemize}

  En todos los casos en que se añade ``al azar'', en los ejemplos anteriores, se refiere a que el experimento ha de realizarse de manera que no se pueda predecir el resultado. Por ejemplo, si extraigo una carta de una baraja con las cartas boca arriba y los ojos abiertos, puedo predecir qué carta voy a extraer, y el experimento no es aleatorio. En algunos casos no es necesario indicar que la observación se realiza ``al azar'', porque es imposible hacerlo de otra manera: la temperatura máxima de un día es imposible (hoy por hoy) predecirla con plena certeza antes de medirla.
\end{example}

\begin{definition}
  [Suceso] En un experimento aleatorio, se llama suceso a cualquier subconjunto del espacio muestral.
\end{definition}

\begin{remark}
  Los sucesos suelen representarse con una letra mayúscula.
\end{remark}

\begin{remark}
  La definición anterior no es del todo exacta. Algunos subconjuntos de algunos espacios muestrales infinitos no numerables no son sucesos. Pero se trata de casos completamente patológicos, con los que no vamos a encontrarnos en este curso, por lo que podemos olvidar este detalle técnico.
\end{remark}

\begin{example}
  En el experimento aleatorio consistente en lanzar dos dados al aire, algunos sucesos son los siguientes:
  \begin{itemize}
  \item Obtener al menos un 6: $A=\{16,26,36,46,56,61,62,63,64,65,66\}$.
  \item Obtener una suma igual a 10: $B=\{46,55,64\}$.
  \item Obtener una suma igual a 7: $C=\{16,25,34,43,52,61\}$.
  \item Obtener dos números iguales: $D=\{11,22,33,44,55,66\}$.
  \item Obtener exactamente un 6: $F=\{16,26,36,46,56,61,62,63,64,65\}$.
  \item No obtener ningún número par: $G=\{11,13,15,31,33,35,51,53,55\}$.
  \item Obtener dos números primos entre sí: $H=\{23,25,32,34,35,43,45,52,53,54,56,65\}$.
  \item Obtener una suma menor de 5: $I=\{11,12,13,21,22,31\}$.
  \end{itemize}
\end{example}

\begin{remark}
  Es importante distinguir entre resultados y sucesos. Los sucesos están formados por resultados. De un suceso se dice que sucede en una realización del experimento (o bien, que ocurre, o que se verifica), cuando el resultado obtenido en dicha realización es uno de los que forman el suceso. Así, por ejemplo, si lanzamos dos dados y obtenemos $11$, de los sucesos del ejemplo anterior habrán ocurrido los sucesos $D$, $G$ e $I$, pero no se habrán verificado los sucesos $A$, $B$, $C$, $E$ ni $H$. Por tanto, en una realización del experimento siempre se obtiene un único \emph{resultado}, pero se pueden verificar simultáneamente varios \emph{sucesos}.
\end{remark}

\begin{remark}
  De los resultados que pertenecen a un suceso se dice que son ``favorables'' a dicho suceso.
\end{remark}

\begin{definition}
  [Suceso elemental] Suceso formado por un único elemento.
\end{definition}

\begin{remark}
  A los sucesos formados por más de un elemento se les suele llamar compuestos.
\end{remark}

\begin{definition}
  [Suceso seguro] Suceso que se verifica en todas las realizaciones del experimento. Coincide necesariamente con el espacio muestral.
\end{definition}

\begin{definition}
  [Suceso imposible] Suceso que no se verifica nunca. Coincide necesariamente con el conjunto vacío.
\end{definition}

\begin{definition}
  [Espacio de sucesos] Es el conjunto de todos los sucesos de un experimento aleatorio. Se representa por $\mathcal{E}$.
\end{definition}

\begin{remark}
  Si un experimento aleatorio tiene un espacio muestral finito con $N$ elementos (resultados posibles), entonces el espacio de sucesos estará formado por $2^N$ sucesos.
\end{remark}

\begin{example}
  Sea el experimento aleatorio que consiste en lanzar dos monedas al aire. Su espacio muestral es:
  \[\Omega=\{CC,CX,XC,XX\}\]
  Su espacio de sucesos será:
  \begin{eqnarray*}\mathcal{E}&=&\{\emptyset,\{CC\},\{CX\},\{XC\},\{XX\},\\
    &&\{CC,CX\},\{CC,XC\},\{CC,XX\},\{CX,XC\},\{CX,XX\},\{XC,XX\},\\
    &&\{CC,CX,XC\},\{CC,CX,XX\},\{CC,XC,XX\},\{CX,XC,XX\},\{CC,CX,XC,XX\}\}
  \end{eqnarray*}
\end{example}

\newpage\section{Álgebra de sucesos}

\begin{definition}
  [Unión] La unión de dos sucesos $A$ y $B$, se representa por $A\cup B$, y es el suceso que se verifica siempre que lo hacen $A$ o $B$, o ambos.
\end{definition}

\begin{center}\includegraphics[width=6cm]{union_cropped.pdf}\end{center}

\begin{remark}
  La unión de $A$ y $B$ está formada por todos los elementos de $A$ y todos los elementos de $B$ y ninguno más:
  \[A \cup B = \{x\in\Omega:x\in A \vee x\in B\}\]
\end{remark}

\begin{example}
  En el experimento consistente en lanzar dos dados, se consideran los sucesos $A$, ``obtener al menos un 6'', y $B$, ``sumar 10''. La unión de dichos sucesos será el suceso $A\cup B$, ``obtener al menos un 6 o sumar 10''. Es decir:
  \[A=\{16,26,36,46,56,66,61,62,63,64,65\}\]
  \[B=\{46,55,64\}\]
  \[A\cup B=\{16,26,36,46,56,66,61,62,63,64,65,55\}\]
\end{example}

\begin{definition}
  [Intersección] La intersección de dos sucesos $A$ y $B$, que se representa por $A\cap B$, es el suceso que se verifica cuando ocurren simultáneamente los sucesos $A$ y $B$.
\end{definition}

\begin{center}\includegraphics[width=6cm]{interseccion_cropped.pdf}\end{center}

\begin{remark}
  La intersección de $A$ y $B$ está formada por los elementos comunes a $A$ y $B$:
  \[A \cap B = \{x\in E: x \in A \wedge x \in B\}\]
\end{remark}

\begin{example}
  Con los mismos sucesos del ejemplo anterior, la intersección de $A$ y $B$ sería el suceso ``obtener al menos un 6 y sumar 10'':
  \[A \cap B = \{46,64\}\]
\end{example}

\begin{definition}
  [Sucesos incompatibles] Dos sucesos $A$ y $B$ son incompatibles o mutuamente excluyentes si nunca pueden ocurrir a la vez, es decir, si $A \cap B = \emptyset$ (no tienen elementos comunes). En caso contrario, se dice que son compatibles.
\end{definition}

\begin{example}
  En el lanzamiento de dos dados, los sucesos ``obtener una suma igual a 7'', $C=\{16,61,25,52,34,43\}$, y ``obtener dos números iguales'', $D=\{11,22,33,44,55,66\}$, son incompatibles, ya que no se puede obtener una suma igual a 7 con dos números iguales. Efectivamente, los conjuntos $C$ y $D$ no tienen elementos comunes, es decir, $C\cap D=\emptyset$. Sin embargo, $A$, ``obtener al menos un 6'', y $D$, ``obtener dos números iguales'', sí son compatibles ya que $A \cap D = \{66\} \neq \emptyset$.
\end{example}

\begin{definition}
  [Diferencia] La diferencia entre $A$ y $B$, que se representa por $A-B$ o por $A\setminus B$, es el suceso que se realiza cuando se verifica $A$ y no se verifica $B$.
\end{definition}

\begin{center}\includegraphics[width=6cm]{diferencia_cropped.pdf}\end{center}

\begin{remark}
  La diferencia $A-B$ está formada por los elementos de $A$ que no pertenecen a $B$:
  \[A - B = \{x \in E : x \in A x \notin B\}\]
\end{remark}

\begin{example}
  Con los mismos sucesos del ejemplo anterior, la diferencia $A-D$ sería el suceso ``obtener al menos un 6 pero no dos números iguales'', y la diferencia $D-A$ sería ``obtener dos números iguales pero sin ningún 6'':
  \[A-B=\{16,26,36,46,56,61,62,63,64,65\}\]
  \[B-A=\{11,22,33,44,55\}\]
\end{example}

\begin{definition}
  [Suceso contrario o complementario] Se llama suceso contrario de un suceso $A$, y se representa por $\overline{A}$ o por $A^C$, al suceso que se verifica siempre que no se verifica el suceso $A$.
\end{definition}

\begin{center}\includegraphics[width=6cm]{contrario_cropped.pdf}\end{center}

\begin{remark}
  El suceso contrario de $A$ contiene a todos los elementos del espacio muestral que no pertenecen a $A$, es decir:
  \[\overline{A} = E - A\]
  También se podría definir como el suceso que verifica las dos condiciones siguientes:
  \[A \cup \overline{A} = E\]
  \[A \cap \overline{A} = \emptyset\]
\end{remark}

\begin{remark}
  Se podía haber definido la diferencia a partir del suceso contrario, de este modo:
  \[A - B = A \cap \overline{B}\]
\end{remark}

\begin{example}
  En el experimento consistente en lanzar tres monedas al aire, se considera el suceso
  \[A=\{CCX,CXC,XCC,CCC\},\]
  ``obtener al menos dos caras''. Su contrario es ``obtener menos de dos caras'':
  \[\overline{A}=\{XXX,XXC,XCX,CXX\}\]
\end{example}

\begin{theorem}
  [Propiedades de las operaciones con sucesos] Dados tres sucesos $A$, $B$ y $C$ cualesquiera de un espacio muestral $\Omega$, se verifica:
  \begin{enumerate}
  \item Propiedad asociativa de la unión y de la intersección:
    \[A \cup (B \cup C) = (A \cup B) \cup C\]
    \[A \cap (B \cap C) = (A \cap B) \cap C\]
  \item Propiedad conmutativa de la unión y de la intersección:
    \[A \cup B = B \cup A\]
    \[A \cap B = B \cap A\]
  \item Distributiva de la unión respecto a la intersección, y de la intersección respecto a la unión:
    \[A \cup (B \cap C) = (A \cup B) \cap (A \cup C)\]
    \[A \cap (B \cup C) = (A \cap B) \cup (A \cap C)\]
  \item Sucesos complementarios:
    \[\overline{\overline{A}} = A\]
    \[A \cup \overline{A} = E\]
    \[A \cap \overline{A} = \emptyset\]
    \[B = (B \cap A) \cup (B \cap \overline{A})\]
  \item Simplificación:
    \[A \cup (A \cap B) = A\]
    \[A \cap (A \cup B) = A\]
  \end{enumerate}
\end{theorem}

\begin{center}\includegraphics[width=6cm]{probabilidadtotal_cropped.pdf}\end{center}

\begin{theorem}
  [Leyes de De Morgan] Dados dos sucesos cualesquiera, $A$ y $B$, de un espacio muestral, se verifican:
  \[\overline{A \cup B} = \overline{A} \cap \overline{B}\]
  \[\overline{A \cap B} = \overline{A} \cup \overline{B}\]
\end{theorem}

\begin{example}

  Se considera el experimento consistente en escoger al azar un niño madrileño de entre 9 y 12 años, y anotar si es diestro o zurdo, y si es moreno, o rubio. Sean $Z$ el suceso ``ser zurdo'', y $R$ el suceso ``ser rubio''. Lo que dicen las leyes de Morgan es:
  \begin{itemize}
  \item Lo contrario de ``ser zurdo y rubio'' es ``no ser zurdo o no ser rubio'': $\overline{Z\cap R}=\overline{Z}\cup\overline{R}$.
  \item Lo contrario de ``ser zurdo o rubio'' es ``no ser ni rubio ni zurdo'': $\overline{Z\cup R}=\overline{Z}\cap\overline{R}$.
  \end{itemize}
  Piénsese así: si en una clase le decimos a todos los que sean zurdos y rubios que salgan, los alumnos que queden en el aula tienen que ser o bien diestros o bien morenos (los zurdos que queden serán morenos, y los rubios que queden serán diestros, aunque también pueden quedar niños que sean diestros y morenos). Si en esa misma clase, decimos que salgan los que sean zurdos, y luego decimos que salgan los que sean rubios (podríamos dar una sola orden de que salgan los que sean zurdos o rubios, pero entonces quizá alguno que sea zurdo y rubio no salga), entonces en la clase no quedará ningún rubio ni tampoco ningún zurdo, es decir, serán todos morenos y diestros.
\end{example}

\begin{definition}
  [Sistema completo de sucesos] Se dice que un conjunto de sucesos no vacíos de un espacio muestral $\Omega$, $P=\{S_1,\hdots,S_n\}$, es un sistema completo de sucesos, o también una partición del espacio muestral, si se verifica que:
  \begin{itemize}
  \item los sucesos de $P$ son incompatibles dos a dos: $\forall\; S_i,\,S_j \in P,\;S_i \cap S_j = \emptyset$;
  \item la unión de todos los sucesos de $P$ es el espacio muestral: $S_1 \cup S_2 \cup \cdots \cup S_n = \Omega$.
  \end{itemize}
\end{definition}

\begin{remark}
  Un suceso (que no sea ni seguro ni imposible) y su contrario siempre forman una partición del espacio muestral.
\end{remark}

\begin{example}
  Se lanza una moneda tres veces, anotando en cada lanzamiento si se obtuvo cara o cruz. El espacio muestral de este experimento es: $\Omega = \{CCC,CCX,CXC,XCC,CXX,XCX,XXC,XXX\}$. Los sucesos:
  \begin{eqnarray*}
    S_0&=&\{XXX\}\\
    S_1&=&\{CXX,XCX,XXC\}\\
    S_2&=&\{CCX,CXC,XCC\}\\
    S_3&=&\{CCC\}
  \end{eqnarray*}
forman una partición del espacio muestral. Podría decirse que se ha dividido el espacio muestral en tres casos: no obtener ninguna cara, obtener una cara, obtener dos caras y obtener tres caras.
\end{example}

\begin{remark}
  Todas las operaciones definidas aquí son idénticas a las operaciones entre conjuntos que se definen en teoría de conjuntos, como se puede ver en el anexo sobre dicha teoría. Al fin y al cabo, los sucesos son conjuntos.
\end{remark}

\newpage\section{Probabilidad}

\begin{definition}
  [Frecuencia de un suceso] Se llama frecuencia absoluta de un suceso $S$ en un conjunto de repeticiones de un experimento aleatorio al número de veces que se verifica. Se representa por $f(S)$. Se llama frecuencia relativa de un suceso $S$ en un conjunto de $n$ repeticiones de un experimento aleatorio al cociente entre su frecuencia absoluta y el número de repeticiones del experimento. Se representa por $fr(S)$.
  \[fr(S)=\dfrac{f(S)}{n}\]
\end{definition}

\begin{definition}
  [Probabilidad de un suceso] La probabilidad de un suceso es el límite al que tiende la frecuencia relativa del mismo cuando el número de repeticiones del experimento aleatorio tiende a infinito.
  \[P(S) = \limite{n}{\infty}{fr(S)}\]
\end{definition}

\begin{remark}
  El uso de esta definición supone que es posible repetir el experimento (al menos, conceptualmente), y también que la frecuencia relativa de todos los sucesos tiende a un valor fijo cuando el número de repeticiones del experimento tiende a infinito.
\end{remark}

\begin{remark}
  Según esta definición, la probabilidad de un suceso es siempre un número comprendido entre 0 y 1 (la frecuencia absoluta siempre es menor o igual que el número de repeticiones del experimento). Las probabilidades pueden expresarse en forma de fracciones, en forma decimal o como porcentajes. Así, por ejemplo, es lo mismo decir que la probabilidad de un suceso es $2/5$, que decir que es igual a $0,4$ y que es del $40\%$.
\end{remark}

\begin{remark}
  El problema de determinar la probabilidad de un suceso sigue abierto. Ya sabemos que tiene que ser igual al límite de su frecuencia relativa cuando el número de repeticiones del experimento tiende a infinito. Pero, ¿cómo determinar ese límite? Hay dos maneras de determinar en concreto una probabilidad:
  \begin{itemize}
  \item A priori (teóricamente): razonando a partir del conocimiento que tenemos del experimento. Así, por ejemplo, podemos determinar la probabilidad de obtener un 6 en el lanzamiento de un dado. Supongamos que el dado es un cubo perfectamente simétrico (esto en realidad es imposible porque las caras deben ser distinguibles). Las leyes de la física son también ``simétricas'', en el sentido de que no distinguen direcciones en el espacio (al menos, así es en la Física newtoniana). Por tanto, las únicas condiciones que pueden influir en el resultado son la posición inicial del dado y su movimiento de giro al ser lanzado. Es razonable suponer que esas condiciones se repetirán con igual frecuencia en una infinidad de lanzamientos, puesto que el único factor que podría hacer más frecuente una posición o giro que otros es el propio dado, al que hemos supuesto simétrico. Si, por ejemplo, un dado tuviese cierta tendencia a ser cogido con el 6 hacia arriba, no sería simétrico. Por lo tanto, es razonable suponer, por simetría, que los seis resultados posibles son igualmente probables. Puesto que las frecuencias relativas de los seis resultados posibles del experimento siempre suman 1, y puesto que sus límites en el infinito tienen que ser iguales, el límite en el infinito de la frecuencia relativa del 6 ha de ser $1/6$. Por tanto, la probabilidad de obtener un 6 ha de ser $1/6$. En la práctica, son muy pocas, y muy poco útiles, las probabilidades que podemos calcular de este modo.
  \item A posteriori (experimentalmente): por ejemplo, si queremos calcular la probabilidad de obtener un 6 en el lanzamiento de un dado, podemos lanzar el dado muchas veces y anotar el número de veces que sale un 6, calcular la frecuencia relativa, y suponer que la probabilidad será aproximadamente igual a dicha frecuencia relativa puesto que hemos lanzado muchas veces el dado. Por ejemplo, si lanzamos el dado 10000 veces y hemos obtenido 1613 veces un 6, podremos decir que la probabilidad de obtener un 6 es ``aproximadamente'' igual a $0,1613$. Este es el método habitual de asignar probabilidades en la realidad. Este segundo método parece menos preciso que el anterior. Desde luego lo es en el caso de que quiera medir la probabilidad de obtener un 6 con un dado ``perfectamente equilibrado'', pero no lo es para un dado concreto (que nunca estará ``perfectamente equilibrado''). La probabilidad teórica del 6 en mi dado es de $1/6=0,1666\hdots$, mientras que la experimental era $0,1613$, pero ¿quién me dice que mi dado no esté un poco desequilibrado de modo que el 6 es un poco menos probable de lo que ``debiera''?
  \end{itemize}
\end{remark}

\begin{remark}
  Otra manera de definir la probabilidad de un suceso es la \emph{definición axiomática}: Sea $\Omega$ el espacio muestral de un experimento aleatorio. Se llama \emph{distribución de probabilidad} a cualquier función que asocie a cada suceso $S$ del espacio muestral un número real, que llamaremos probabilidad de $S$, y representaremos por $P(S)$, de modo que se verifiquen las propiedades siguientes:
  \begin{enumerate}
  \item $P(S) \geq 0 \; \forall \; S \in \mathcal{E}$ (la probabilidad es un número positivo o nulo);
  \item $P(\Omega) = 1$ (la probabilidad del suceso seguro es 1);
  \item $S \cap T = \emptyset \Rightarrow P(S \cup T) = P(S) + P(T)$.
  \end{enumerate}

  Esta definición se llama axiomática porque define la probabilidad suponiendo que ha de cumplir unas propiedades (llamados axiomas, porque se toman como punto de partida: se supone que se han de cumplir pero no se da ninguna justificación para ello). Se debe al matemático ruso Kolmogorov (1933).

  Esta definición no nos dice cómo hallar una probabilidad concreta. Se supone que, de alguna manera, se han asignado probabilidades a los sucesos, cumpliendo los axiomas, por supuesto, pero sin importarnos si realmente esas probabilidades asignadas responden al concepto intuitivo que tenemos de probabilidad. De hecho, esta definición permitiría asignar distintas probabilidades a un mismo suceso (en distribuciones de probabilidad distintas, claro). Por esta razón, consideraremos que un experimento aleatorio queda completamente definido cuando se definen su espacio muestral y una distribución de probabilidad concreta sobre el espacio de sucesos del mismo.

  El caso es que si las probabilidades asignadas cumplen los axiomas, entonces podemos asegurar que las herramientas de cálculo de probabilidades que desarrollaremos a continuación funcionan. Dicho de otro modo, esta definición ``aisla'' el problema de asignar probabilidades a los sucesos elementales del resto de problemas de cálculo de probabilidades. Si algo falla es porque las probabilidades asignadas no son correctas.

  Finalmente, cabría observar que es posible demostrar que la probabilidad de que el límite de la frecuencia relativa de un suceso cuando el número de repeticiones del experimento tiende a infinito sea igual a su probabilidad es del $100\%$ siempre que las probabilidades se hayan asignado cumpliendo los axiomas de Kolmogorov. Esta afirmación se llama \emph{Ley de los Grandes Números}.
\end{remark}

\begin{theorem}
  [Propiedades de la probabilidad] Para cualquier experimento aleatorio con espacio muestral $\Omega$ y espacio de sucesos $\mathcal{E}$, en el que se ha definido un distribución (asignación) de probabilidades $P$, se verifican las propiedades siguientes:
  \begin{enumerate}
  \item La probabilidad de un suceso es un número no negativo:
    $$\forall \; S \in \mathcal{E} \; , \; P(S) \geq 0.$$
  \item La probabilidad del suceso seguro es 1:
    $$P(\Omega) = 1.$$
  \item Probabilidad de la unión de sucesos incompatibles:
    $$A \cap B = \emptyset \Rightarrow P(A \cup B) = P(A) + P(B).$$
  \item La probabilidad del suceso imposible es nula:
    $$P(\emptyset)=0.$$
  \item Probabilidad del suceso contrario:
    $$P(\overline{S})=1-P(S).$$
  \item La probabilidad de un suceso es siempre menor o igual que 1:
    $$\forall \; S \in \mathcal{E} \;,\; 0 \leq P(S) \leq 1.$$
  \item Si $A \subset B$, entonces $P(A) \leq P(B)$.
  \item Probabilidad de la unión de dos sucesos:
    $$\forall \; A,B \in \mathcal{E} \;,\; P(A \cup B) = P(A) + P(B) - P(A \cap B).$$
  \item Probabilidad de la unión de tres sucesos:
    $$\forall \; A,B,C \in \mathcal{E} \;,\; P(A \cup B \cup C) = P(A) + P(B) + P(C) - P(A \cap B) - P(A \cap C) - P(B \cap C) + P(A \cap B \cap C).$$
  \end{enumerate}
\end{theorem}

\begin{remark}
  Las tres primeras propiedades son los axiomas de Kolmogorov, y son fácilmente deducibles de la definición de la probabilidad como frecuencia. El resto de las propiedades pueden deducirse de los axiomas.
\end{remark}

\begin{theorem}
  [Regla de Laplace] En un experimento aleatorio con un espacio muestral finito formado por resultados equiprobables, la probabilidad de un suceso es igual al cociente entre el número de resultados favorables a dicho suceso y el número total de resultados posibles (es decir, el cociente entre el número de elementos del suceso y el número de elementos del espacio muestral):
  \[P(S)=\dfrac{\text{Número de casos favorables a S}}{\text{Número de casos posibles}}=\dfrac{\text{Card }S}{\text{Card }\Omega}\]
\end{theorem}

\begin{remark}
  Esta \emph{regla} se deduce de manera trivial de las propiedades de la probabilidad antes enunciadas.
\end{remark}

\begin{example}
  Se lanzan tres monedas equilibradas al aire. Hallar la probabilidad de obtener al menos una cara.

  El espacio muestral de este experimento sería:
  \[\Omega=\{CCC,CCX,CXC,XCC,CXX,XCX,XXC,XXX\}\]
  El suceso cuya probabilidad se pide es:
  \[S=\{CCC,CCX,CXC,XCC,CXX,XCX,XXC\}\]
  Parece lógico suponer que los resultados del experimento son todos igual de probables, por lo que podemos aplicar la Regla de Laplace para calcular la probabilidad de $S$:
  \[P(S)=\dfrac{\text{Casos favorables a }S}{\text{Casos posibles}}=\dfrac{7}{8}\]
  Podíamos haber resuelto este ejercicio de otro modo. Observamos que el suceso cuya probabilidad nos piden es el contrario de no obtener ninguna cara:
  \[\overline{S}=\{XXX\}\]
  Aplicando la Regla de Laplace podemos afirmar que la probabilidad de este suceso es $1/8$, puesto que es un suceso elemental. Utilizando la ``fórmula'' de la probabilidad del suceso contrario:
  \[P(S)=1-P(\overline{S})=1-\dfrac{1}{8}=\dfrac{7}{8}\]
  La ventaja de este segundo método es que la probabilidad del suceso contrario era más fácil de calcular que la del suceso $S$.

  ¿Qué habría pasado si hubiéramos tomado como espacio muestral el número de caras obtenidas, $\Omega=\{0,1,2,3\}$? Parece más sencillo. El suceso cuya probabilidad nos piden es $S=\{1,2,3\}$. Aplicando la Regla de Laplace obtendríamos $P(S)=3/4$, ya que $S$ contiene 3 resultados y hay 4 resultados posibles. Resulta que la probabilidad obtenida no es la misma que obtuvimos antes. La experiencia dice que la probabilidad correcta es la anterior. ¿Dónde está el error de este cálculo? No es que el espacio muestral sea incorrecto. Lo que ocurre es que este espacio muestral no es equiprobable (la probabilidad de obtener 3 caras, por ejemplo, es menor que la de obtener una cara) y, por tanto, no podemos aplicar la Regla de Laplace. Conviene tener esto en cuenta a la hora de ``elegir'' el espacio muestral con el que vamos a trabajar.
\end{example}

\begin{remark}
  Un \emph{espacio de probabilidad}, también llamado \emph{modelo de probabilidad}, queda constituido por un espacio muestral, un espacio de sucesos y una distribución de probabilidad sobre dicho espacio de sucesos. Cuando queremos estudiar un fenómeno aleatorio debemos construir para él un espacio de probabilidad. El modelo matemático no está completo hasta que no hemos definido sus tres elementos.
\end{remark}

\newpage\section{Probabilidad condicionada}

\begin{definition}
  [Probabilidad condicionada] Dados dos sucesos $A$ y $B$ de un experimento aleatorio, con $P(B)>0$, se llama probabilidad de $A$ condicionado a $B$, y se representa por $P(A\mid B)$, a la probabilidad de que se verifique el suceso $A$ con la condición de que se haya verificado el suceso $B$; es  decir:

  \[P(A\mid B)=\dfrac{P(A \cap B)}{P(B)}\]
\end{definition}

\begin{remark}
  Las probabilidades sirven para hacer razonamientos sobre el resultado de un experimento cuando dicho resultado es desconocido. La probabilidad condicionada permite razonar cuando se tiene cierta información parcial sobre el resultado del experimento. Por ejemplo, supongamos que se lanzan dos dados al aire y nos preguntan por la probabilidad de obtener dos números iguales. Si no sabemos nada sobre el resultado, diremos que la probabilidad de $A=\{\text{``obtener dos números iguales''}\}=\{11,22,33,44,55,66\}$ es $P(A)=6/36=1/6$. Supongamos ahora que sí que sabemos algo sobre el resultado: nos dicen que la suma obtenida es un número primo. Ahora, sabemos más, por lo que podemos precisar más la respuesta. Llamemos $B$ al suceso ``Obtener como suma un número primo'', $B=\{11,12,21,14,41,23,32,34,43,56,65\}$. Si se ha obtenido una suma prima, es porque el resultado es alguno de los de $B$. La probabilidad de que el resultado esté también en $A$ es $P(A\mid B)=1/11$, porque en $B$ solo hay un resultado con los números iguales de un total de 11 resultados. Si los casos posibles son solo los de $B$, entonces solo queda un resultado favorable a $A$. Si sorprende que la información sobre el resultado cambie las probabilidades es porque no se ha entendido bien que el azar depende de nuestro desconocimiento del experimento, más que del experimento mismo.
\end{remark}

\begin{remark}
  La probabilidad condicionada es en sí misma una probabilidad. Es la probabilidad que se obtendría restringiendo el espacio muestral al suceso $B$. Si a todos los sucesos de un espacio muestral les añadimos la misma ``condición'' $B$ obtenemos un nuevo espacio de probabilidad, que cumple todas las propiedades estudiadas para las probabilidades. Así, por ejemplo, dados dos sucesos $A$ y $C$ cualesquiera se debe cumplir que $P(A \cup C\mid B) = P(A\mid B) + P(C\mid B) - P(A \cap C\mid B)$.
\end{remark}

\begin{remark}
  Siempre que escribamos una expresión del tipo $P(A\mid B)$ se supondrá implícitamente que $P(B)>0$.
\end{remark}

\begin{remark}
  En general, $P(A\mid B) \neq P(B\mid A)$.
\end{remark}

\begin{theorem}
  [Teorema del Producto]
  \[P(A_1 \cap A_2 \cap \hdots \cap A_n) = P(A_1)P(A_2\mid A_1)P(A_3\mid A_1 \cap A_2)\cdots P(A_n\mid A_1 \cap A_1 \cap \hdots \cap A_{n-1})\]
\end{theorem}

\begin{remark}
  El Teorema del Producto se aplica con mucha frecuencia en experimentos secuenciales, es decir, que se pueden separar en fases (aunque sea conceptualmente). Así, por ejemplo, el lanzamiento de dos monedas se puede considerar formado por dos lanzamientos consecutivos.
\end{remark}

\begin{remark}
  Una herramienta muy práctica para aplicar el Teorema del Producto son los \emph{árboles de probabilidad}. Se trata de una representación gráfica de experimentos compuestos por varias fases. Hay un nodo inicial a partir del cual se van desplegando los distintos ``caminos''  o \emph{ramas} que puede seguir el experimento hasta un resultado final. Cada \emph{nodo} del árbol representa un resultado de una fase. Junto a cada rama escribimos la probabilidad que hay de seguir esa rama. Las probabilidades de las ramas son siempre (salvo las que salen del nodo inicial) probabilidades condicionadas, ya que se refieren a la probabilidad de seguir esa rama suponiendo que se alcanzó anteriormente el nodo del que parte. Las probabilidades de todas las ramas que parten de un mismo nodo han de sumar siempre 1. Cada nodo final, también llamado \emph{hoja} del árbol, representa un resultado final, que es la intersección de todos los nodos recorridos para llegar a esa hoja. El Teorema del Producto nos dice que la probabilidad de una hoja es igual al producto de las probabilidades de todas las ramas por las que se ha de pasar hasta llegar a ella.

  Por ejemplo, consideremos que tenemos dos urnas. En la primera, $U_1$, hay 3 bolas blancas y 4 bolas negras. En la segunda, $U_2$, hay 5 bolas blancas y 2 bolas negras. Se considera el experimento que consiste en elegir una urna al azar, y extraer, también al azar, una bola de dicha urna, y anotar su color. El árbol de probabilidad correspondiente a este experimento sería el siguiente:

\begin{center}\includegraphics[width=10cm]{arbol1_cropped.pdf}\end{center}
\end{remark}

\begin{example}
  Si un avión está presente en una cierta región, un radar detecta correctamente su presencia con una probabilidad del 99\%. Si no hay ningún avión presente, el radar puede realizar una falsa detección con una probabilidad del 10\%. Supongamos que la probabilidad de que un avión pase por la región de detección del radar sea de un 5\%. ¿Cuál es la probabilidad de que se produzca una falsa alarma? ¿Cuál es la probabilidad de que pase un avión sin ser detectado?

  Llamamos $A$ al suceso ``un avión pasa por la región de detección del radar''. Sabemos que:
  \[P(A)=0,05; \; P(\overline{A})=1-P(A)=1-0,05=0,95\]

  Llamamos $D$ al suceso ``el radar realiza una detección (falsa o correcta)''. Sabemos que:
  \[P(D\mid A)=0,99; \; P(D\mid \overline{A})=0,10\]

  Una falsa alarma se producirá cuando efectivamente no pase ningún avión, es decir, ocurra $\overline{A}$, y además el radar realice una detección, es decir ocurra $D$. Por tanto, la probabilidad de que se produzca una falsa alarma es la probabilidad de $D \cap \overline{A}$. Aplicando el Teorema del Producto:
  \[P(D \cap \overline{A}) = P(\overline{A} \cap D) = P(\overline{A})P(D\mid \overline{A})=0,95\cdot0,10=0,095=9,5\%\]

  Obsérvese la diferencia entre $P(D\mid A)=10\%$ y $P(D \cap \overline{A})=9,5\%$. La primera, que es un dato del enunciado, nos dice que el $10\%$ de las detecciones que realiza el radar son falsas. La segunda nos dice que el $9,5\%$ del tiempo el radar realiza detecciones falsas. La diferencia es que en el primer caso estamos suponiendo que efectivamente no se ha producido el paso de ningún avión, mientras que en la segunda estamos contando todos los casos: cuando no pasan aviones y también cuando sí pasan.

  Un avión pasará sin ser detectado cuando se verifiquen simultáneamente los sucesos $A$, pasa un avión, y $\overline{D}$, el radar no realiza ninguna detección. Aplicaremos nuevamente el Teorema del Producto:
  \[P(A \cap \overline{D}) = P(A)P(\overline{D}\mid A)\]

  Recordemos que las probabilidades condicionadas cumplen todas las propiedades de las probabilidades. Por lo tanto:
  \[P(\overline{D}\mid A)=1-P(D\mid A)=1-0,99=0,01\]

  Sustituyendo en la fórmula anterior, obtenemos:
  \[P(A \cap \overline{D}) = P(A)P(\overline{D}\mid A) = 0,05 \cdot 0,01 = 0,0005 = 0,05\%\]

  Con un árbol de probabilidad, los cálculos anteriores resultan muy intuitivos:

  \begin{center}
    \includegraphics[width=10cm]{arbol2_cropped.pdf}
  \end{center}
\end{example}

\begin{theorem}
  [Teorema de la Probabilidad Total] Dada una partición $P=\{A_1,A_2,\hdots,A_n\}$ de un espacio muestral, y un suceso cualquiera $B$ del mismo, se verifica que:
  \begin{eqnarray*}
    P(B) & = & P(B \cap A_1) + P(B \cap A_2) + \cdots + P(B \cap A_n) \\
         & = & P(A_1)P(B\mid A_1) + P(A_2)P(B\mid A_2) + \cdots + P(A_n)P(B\mid A_n)
  \end{eqnarray*}
\end{theorem}

\begin{remark}
  Representación gráfica del Teorema de la Probabilidad Total:
  \begin{center}\includegraphics[width=6cm]{probabilidadtotal2_cropped.pdf}\end{center}
\end{remark}

\begin{remark}
  Para una partición formada por un suceso y su contrario, el teorema se reduce a:
  $$P(B) = P(B \cap A) + P(B \cap \overline{A}) = P(A)P(B \mid A) + P(\overline{A})P(B \mid \overline{A}).$$
\end{remark}

\begin{theorem}
  [Bayes] Dado un suceso no imposible $S$, y una partición, $\{A_1,A_2,\dots,A_n\}$, se verifica que:
  \begin{eqnarray*}
    P(A_i\mid S) & = & \dfrac{P(A_i)P(S\mid A_i)}{P(S)} \\
             & = & \dfrac{P(A_i)P(S\mid A_i)}{P(A_1)P(S\mid A_1)+P(A_2)P(S\mid A_2)+\cdots+P(A_n)P(S\mid A_n)}
  \end{eqnarray*}
\end{theorem}

\begin{remark}
  El teorema anterior se deduce del siguiente modo. A partir de la probabilidad de la intersección, deducimos:
\[P(A_i\cap S)=P(A_i)P(S\mid A_i)=P(S)P(A_i\mid S)\iff P(A_i\mid S)=\dfrac{P(A_i)P(S\mid A_i)}{P(S)}\]
Utilizando el teorema de la probabilidad total, sabemos que:
\[P(S)=P(A_1)P(S\mid A_1)+P(A_2)P(S\mid A_2)+\cdots+P(A_n)P(S\mid A_n)\]
Sustituyendo en la expresión anterior, obtenemos el Teorema de Bayes.
\end{remark}

\begin{remark}
  Con el teorema de Bayes se trata de dar respuesta al problema siguiente. Sabemos que los resultados de un experimento aleatorio se pueden dividir en ciertos casos mutuamente excluyentes, que llamaremos \emph{hipótesis}, y representaremos por $A_1,A_2,\cdots,A_n$. Conocemos la probabilidad de que se verifique cada una de esas hipótesis: $P(A_1),P(A_2),\cdots,P(A_n)$. A estas las llamaremos \emph{probabilidades a priori}. Supongamos que se realiza el experimento, y se observa la ocurrencia de un cierto suceso, $S$, al que llamaremos \emph{evidencia}, porque sabemos que se ha verificado. El problema consiste en decidir cuál de las hipótesis se ha verificado (recordemos que son mutuamente excluyentes). Para ello, el teorema de Bayes nos proporciona una fórmula que nos permite calcular la probabilidad de cada hipótesis condicionada al resultado obtenido: $P(A_i\mid S)$. A estas probabilidades se les llama \emph{probabilidades a posteriori}. Normalmente decidiremos que la hipótesis verificada es la de mayor probabilidad a posteriori.
\end{remark}

\begin{example}
  En una bolsa tenemos 65 monedas, de las cuales una tiene dos caras, siendo el resto normales. Se escoge una moneda al azar, y se lanza al aire 6 veces, obteniéndose 6 caras seguidas. ¿Cuál es la probabilidad de que la moneda escogida sea la trucada?

Tenemos dos \emph{hipótesis}:
\[H_1=\{\text{Moneda normal}\}\]
\[H_2=\{\text{Moneda trucada}\}\]

Las \emph{probabilidades a priori} de estas hipótesis, bajo el supuesto de que todas las monedas tengan la misma probabilidad de ser escogidas, se pueden calcular fácilmente utilizando la regla de Laplace:
\[P(H_1)=\dfrac{64}{65}\]
\[P(H_2)=\dfrac{1}{65}\]

La \emph{evidencia} obtenida es $S=\{CCCCCC\}$, es decir, que hemos obtenido 6 caras en los 6 lanzamientos.

La probabilidad de este suceso bajo la hipótesis de que se ha escogido una moneda normal es:
\[P(S\mid H_1)=\dfrac{1}{2^6}\]
Puesto que, si consideramos una moneda cualquiera, el número de resultados distintos que podemos obtener viene dado por $2^6$, ya que por cada lanzamiento tenemos 2 resultados posibles.

La probabilidad del suceso observado bajo la hipótesis de que se ha escogido la moneda trucada es 1, ya que con esa moneda solo pueden obtenerse caras:
\[P(S\mid H_2)=1\]

No sabemos si hemos obtenido 6 caras porque hemos escogido la moneda trucada, o porque hemos tenido mucha suerte con una moneda normal. Sin embargo, el teorema de Bayes nos permite calcular la probabilidad de cada una de esas dos hipótesis:

\[P(H_1\mid S)=\dfrac{P(H_1)P(S\mid H_1)}{P(H_1)P(S\mid H_1)+P(H_2)P(S\mid H_2)}=\dfrac{\dfrac{64}{65}\cdot\dfrac{1}{2^6}}{\dfrac{64}{65}\cdot\dfrac{1}{2^6}+\dfrac{1}{65}\cdot 1}=\dfrac{1}{2}\]

\[P(H_2\mid S)=\dfrac{P(H_2)P(S\mid H_2)}{P(H_1)P(S\mid H_1)+P(H_2)P(S\mid H_2)}=\dfrac{\dfrac{1}{65}\cdot 1}{\dfrac{64}{65}\cdot\dfrac{1}{2^6}+\dfrac{1}{65}\cdot 1}=\dfrac{1}{2}\]

En definitiva, es igual de probable que la moneda escogida sea la trucada que la normal. Aunque parece que debe ser más probable que un resultado así se obtenga con la moneda trucada, al haber muchas más monedas no trucadas, la probabilidad se equilibra. Piénsese de este modo: si repetimos el experimento muchas veces, pongamos 650, escogeremos la moneda trucada 10 veces, y una moneda normal 640 veces. De las 10 veces que escogemos la moneda trucada, las 10 veces obtendremos 6 caras, porque no es posible otro resultado. De las 640 veces que escogemos una moneda normal, solo obtendremos 6 caras en 10 ocasiones (porque es difícil tener 6 caras seguidas con una moneda normal). En total, habremos obtenido 6 caras en 20 ocasiones, 10 con la moneda trucada y 10 con la moneda normal. Hemos obtenido ese resultado el mismo número de veces con una moneda normal que con una trucada, pero porque hemos probado con una moneda normal 640 veces, mientras que con la moneda trucada solo 10 veces.
\end{example}

\begin{definition}
  [Sucesos independientes] Se dice que dos sucesos $A$ y $B$ son independientes si
  \[P(A \cap B)=P(A)P(B).\]
\end{definition}

\begin{remark}
  Intuitivamente, dos sucesos son independientes cuando el conocimiento de que ha ocurrido o no ha ocurrido uno de ellos no influye en la probabilidad que asignamos al otro. La relación entre este concepto intuitivo y la definición es la siguiente. En general,
  \[P(A \cap B) = P(A)P(B\mid A)\]

  Si $A$ y $B$ son independientes, entonces, según la definición:
  \[P(A \cap B) = P(A)P(B)\]

  Suponiendo que $P(A)>0$, igualando las dos expresiones anteriores podemos concluir que:
  \[P(A)P(B\mid A)=P(A)P(B) \Rightarrow P(B\mid A) = P(B)\]

  A la inversa, si $P(B)=P(B\mid A)$, entonces, $P(A \cap B)=P(A)P(B\mid A)=P(A)P(B)$, luego $A$ y $B$ son independientes.

  De modo similar podríamos deducir que si $P(B)\neq0$, $A$ y $B$ son independientes si y solo si $P(A)=P(A\mid B)$.

  En resumen, suponiendo que $P(A)>0$ y $P(B)>0$, las siguientes afirmaciones son equivalentes:
  \begin{itemize}
  \item $A$ y $B$ son independientes.
  \item $P(A \cap B) = P(A)P(B)$.
  \item $P(A) = P(A\mid B)$.
  \item $P(B) = P(B\mid A)$.
  \end{itemize}
\end{remark}

\begin{remark}
  Dos sucesos $A$ y $B$ son independientes si y solo si sus contrarios $\overline{A}$ y $\overline{B}$ son independientes. De igual modo $A$ y $B$ son independientes si y solo si $\overline{A}$ y $B$ lo son, si y solo si $A$ y $\overline{B}$ son independientes.
\end{remark}

\begin{remark}
  Cuidado con no confundir sucesos independientes con sucesos incompatibles. De hecho, dos sucesos incompatibles (salvo en el que caso de que uno de ellos sea imposible) son siempre dependientes: si no se pueden dar a la vez, sabiendo que ha sucedido uno ya podemos estar seguros de que el otro no ha sucedido. Algebraicamente, si son incompatibles:
  \[P(A \cap B) = P(\emptyset) = 0\]
  Pero, si $P(A)>0$ y $P(B)>0$, entonces:
  \[P(A)P(B) \neq 0\]
  Luego no son independientes.
\end{remark}

\begin{remark}
  Este concepto puede extenderse a más de dos sucesos del siguiente modo. Los sucesos, $A_1, \hdots, A_n$ son independientes si y solo si se verifica que, para todo $S \subset \{1,\hdots,n\}$:
  \[P\left(\bigcap_{i\in S}A_i\right) = \prod_{i \in S}P(A_i)\]

  Es decir, para que consideremos independientes a varios sucesos no basta con que sean independientes dos a dos. Tampoco basta con que la probabilidad de la intersección de todos ellos sea igual al producto de las probabilidades de todos ellos. Es necesario que tomando cualquier grupo de ellos, la probabilidad de su intersección sea igual al producto de sus probabilidades. 
\end{remark}

\begin{remark}
  También se define la \emph{independencia condicional}. Dos sucesos $A$ y $B$ son condicionalmente independientes dado otro suceso $C$ con $P(C)>0$, si $P(A \cap B\mid C)=P(A\mid C)P(B\mid C)$. Si, además, $P(B\cap C)>0$, entonces la independencia condicional de $A$ y $B$ dado $C$ es equivalente a la condición $P(A\mid B\cap C) = P(A\mid C)$. La independencia condicional no implica independencia, ni viceversa.
\end{remark}

\begin{example}
  Dados dos sucesos $A$ y $B$ asociados a un mismo experimento aleatorio, se conocen las probabilidades $P(B)=0,7$, $P(A\mid B)=0,8$ y $P(A\cap\bar{B})=0,24$.
  \begin{enumeratealpha}
    \item Calcule $P(A\cap B)$.

        $P(A\cap B)=P(B)P(A\mid B)=0,7\cdot0,8=0,56$

    \item Calcule $P(A)$.

      $P(A)=P(A\cap B)+P(A\cap \bar{B})=0,56+0,24=0,8$

    \item Determine si $A$ y $B$ son independientes.

      Podemos comprobar que son independientes de dos formas. Por un lado, vemos que la probabilidad de la intersección es igual al producto de las probabilidades, luego son independientes:
      \[P(A)P(B)=0,8\cdot 0,7=0,56=P(A\cap B)\]

      Por otro lado, vemos que la probabilidad de $A$ es igual a la probabilidad de $A$ condicionado a $B$:
      \[P(A)=0,8=P(A\mid B)\]

  \end{enumeratealpha}
\end{example}

\begin{definition}
  [Experimentos compuestos] Un experimento aleatorio compuesto es un experimento que consiste en la realización sucesiva de varios subexperimentos. Si los espacios muestrales de los subexperimentos son $E_1,E_2,\dots,E_n$, el espacio muestral del experimento compuesto, $E$, está formado por todas las posibles secuencias de resultados $(s_1,s_2,\dots,s_n)$, donde $s_1\in E_1,s_2\in E_2,\dots,s_n\in E_n$, es decir, $E=E_1\times E_2\times\dots\times E_n$. A la distribución de probabilidad de un experimento compuesto se le llama distribución de probabilidad compuesta.
\end{definition}

\begin{remark}
  Téngase en cuenta que un experimento compuesto puede estar formado por dos o más observaciones realizadas sobre una misma ``experiencia''. Podemos considerar un experimento simple como compuesto, pensando que los sucesos que queremos estudiar son observaciones distintas.

Por ejemplo, supongamos que queremos estudiar si hay alguna relación entre aprobar la Selectividad y la lateralidad (ser zurdo o diestro). Para ello realizamos la experiencia de escoger al azar un alumno de entre todos los que han realizado la PAU en Madrid en junio de 2013. A continuación anotamos si ha aprobado la Selectividad y también si es zurdo o diestro. Podemos modelar este experimento como un único experimento, cuyo espacio muestral es el conjunto de todos los alumnos que han realizado la PAU en Madrid en junio de 2013, en el que estudiamos dos sucesos, $A=\{\text{``Ha aprobado la PAU''}\}$ y $B=\{\text{``Es zurdo''}\}$. Pero también podemos modelarlo como un experimento compuesto por dos experimentos: escoger un alumno al azar y primero ver si ha aprobado o no la PAU, con espacio muestral $E_1=\{\text{aprueba},\text{no aprueba}\}$, y en segundo lugar ver si es zurdo o diestro, con espacio muestral $E_2=\{\text{Zurdo},\text{Diestro}\}$.
\end{remark}

\begin{definition}
  [Experimentos mutuamente independientes] Se dice de un conjunto de experimentos aleatorios, con espacios muestrales $E_1,E_2,\hdots,E_n$, que son mutuamente independientes si para cualesquiera resultados $s_1 \in E_1,s_2 \in E_2,\hdots,s_n \in E_n$, se verifica que:
  \[P(s_1,s_2,\hdots,s_n)=P(s_1)P(s_2)\cdots P(s_n)\]
\end{definition}

\begin{remark}
  Cuando dos experimentos son mutuamente independientes diremos simplemente que son independientes.
\end{remark}

\begin{remark}
  Nótese la diferencia entre sucesos independientes y experimentos independientes. Para que dos experimentos sean independientes tienen que ser independientes todas las parejas de sucesos de uno y otro experimentos.
\end{remark}

\begin{remark}
  Este concepto de experimento compuesto se aplica sobre todo a la repetición de un mismo experimento con independencia (se sobreentiende que se refiere a independencia mutua). Según se ha visto, en este tipo de experiencias compuestas con independencia mutua, la probabilidad de un resultado es el producto de las probabilidades de los resultados parciales. Así, por ejemplo, consideremos el caso de que se lanza un dado 6 veces con independencia. ¿Cuál es la probabilidad de obtener este resultado (en el orden indicado): 1,2,3,4,5,6? Puesto que los lanzamientos son independientes, la probabilidad compuesta es el producto de las probabilidades de cada resultado simple:
  \[P(123456)=P(1)P(2)P(3)P(4)P(5)P(6)=\left(\dfrac{1}{6}\right)^6\]
\end{remark}

\begin{remark}
  Hay dos herramientas útiles para trabajar con experimentos compuestos: los \emph{árboles de probabilidad}, ya vistos anteriormente, y las \emph{tablas de contingencia}.

  Las \emph{tablas de contingencia} son útiles para estudiar experimentos compuestos de dos fases, o experimentos en los que consideramos dos particiones distintas del espacio muestral (cada fase, en un experimento secuencial, es, en realidad, una partición del espacio muestral). Se trata de tablas de doble entrada, en las que en las filas se sitúan los sucesos de una partición, y en las columnas los sucesos de la otra. Las celdas representan las probabilidades de las intersecciones de los sucesos correspondientes a la fila y columna en que se encuentran. El total de una fila o columna es la probabilidad del suceso correspondiente a dicha fila o columna, y se suele llamar \emph{probabilidad marginal}, por hallarse en el margen de la tabla.
\end{remark}

\begin{example}
  En una empresa hay 200 empleados, de los que 85 utiliza transporte público para llegar a su puesto de trabajo. Se sabe que 120 empleados son varones, y que de las mujeres hay 50 que utilizan transporte público. Se escoge al azar un empleado de dicha empresa. Se pide:
  \begin{enumeratealpha}
    \item Calcular la probabilidad de que sea hombre y utilice el transporte público.
    \item El empleado escogido ha resultado ser un hombre. Calcular la probabilidad de que utilice el transporte público.
    \item El empleado escogido utiliza un medio de transporte privado. Hallar la probabilidad de que sea una mujer.
    \item ¿Son independientes los sucesos ``ser hombre'' y ``utilizar transporte público''?
  \end{enumeratealpha}

Utilizaremos una tabla de contingencia para organizar los datos del enunciado:
\begin{center}
\begin{tabular}{|l|r|r|r|} \hline
                     & Hombre & Mujer & Total \\ \hline
  Transporte público &        &    50 &    85 \\ \hline
  Transporte privado &        &       &       \\ \hline
  Total              &    120 &       &   200 \\ \hline
\end{tabular}
\end{center}

Los números que faltan en la tabla de contingencia podemos calcularlos por simples sumas y restas:
\begin{center}
\begin{tabular}{|l|r|r|r|} \hline
                     & Hombre      & Mujer       & Total             \\ \hline
  Transporte público & \textbf{35} &         50  &          85       \\ \hline
  Transporte privado & \textbf{85} & \textbf{30} & \textbf{115}      \\ \hline
  Total              &        120  & \textbf{80} &         200       \\ \hline
\end{tabular}
\end{center}

Una vez completada la tabla es sencillo calcular las probabilidades pedidas utilizando la regla de Laplace (suponemos que todos los empleados tienen la misma probabilidad de ser escogidos). Llamaremos $H$ al suceso ``ser hombre'', $M$ al suceso ``ser mujer'', $P$ al suceso ``utilizar transporte público'' y $\overline{P}$ al suceso ``utilizar transporte privado''.
\begin{enumeratealpha}
  \item La probabilidad de que el empleado sea hombre y utilice transporte público es:
    \[P(H \cap P) = \dfrac{35}{200} = 0,175 = 17,5 \%\]
  \item Si el empleado escogido ha sido un hombre, la probabilidad de que utilice el transporte público es:
    \[P(P \mid H) = \dfrac{P(P \cap H)}{P(H)} = \dfrac{P(H \cap P)}{P(H)} = \dfrac{35/200}{120/200} = \dfrac{35}{120} = 0,2917 = 29,17 \%\]
  \item Si el empleado escogido utiliza un medio de transporte privado, la probabilidad de que sea una mujer es:
    \[P(M \mid \overline{P}) = \dfrac{P(M \cap \overline{P})}{P(\overline{P})} = \dfrac{30/200}{115/200} = \dfrac{30}{115} = 0,2609 = 26,09 \%\]
  \item Podemos analizar la independiencia de los sucesos $H$ y $P$ de dos formas. En primer lugar, compararemos $P(H \cap P)$ con $P(H)P(P)$:
    \[P(H \cap P) = 17,5\%\]
    \[P(H)P(P) = \dfrac{120}{200}\cdot\dfrac{85}{200} = 0,255 = 25,5\%\]
    Son distintos, por lo que los sucesos $H$ y $P$ son dependientes.

    Otra manera de comprobarlo es comparando $P(P)$ con $P(P \mid H)$ (esta probabilidad se calculó en el apartado b):
    \[P(P) = \dfrac{85}{200} = 0,425 = 42,5\%\]
    \[P(P \mid H) = 29,17\%\]
    Son distintas, luego son dependientes. En concreto, podemos afirmar que los hombres utilizan menos el transporte público que las mujeres.
\end{enumeratealpha}
\end{example}



\phantomsection
\addcontentsline{toc}{part}{Apéndices}



\part*{Apéndices}

\appendix

\chapter{Métodos de demostración}

\section{Concepto de demostración matemática}

\begin{remark}
  En Matemáticas, demostrar una afirmación es realizar una secuencia de razonamientos que evidencian que dicha afirmación es una consecuencia lógica de otras afirmaciones establecidas anteriormente como verdaderas.
\end{remark}

\begin{remark}
  La exposición siguiente no pretende un excesivo rigor lógico. Pretende ser solo una toma de contacto con la demostración matemática. Hay una parte de la Lógica (la Lógica Matemática), que estudia de manera precisa las demostraciones matemáticas.
\end{remark}

\begin{remark}
  Las afirmaciones matemáticas reciben distintos nombres según hayan sido o no demostradas, y según su importancia.

  Las afirmaciones demostradas se clasifican, según su importancia, en teoremas, lemas (o proposiciones) y corolarios.
  \begin{itemize}
  \item Teoremas: son resultados importantes. Por ejemplo, el Teorema Fundamental del Álgebra: \emph{un polinomio de grado $n$ tiene como máximo $n$ raíces}.
  \item Lemas o proposiciones: son resultados poco importantes. Por ejemplo, el Lema de Gauss: \emph{el producto de dos polinomios primitivos es también un polinomio primitivo} (un polinomio primitivo es un polinomio con todos los coeficientes enteros y primos entre sí).
  \item Corolarios: son consecuencias inmediatas de teoremas.
  \end{itemize}
 
  La distinción entre ellas es algo arbitraria. Normalmente, los lemas se llaman así, porque su principal importancia es que permiten demostrar algún teorema (son algo así como pasos intermedios en la demostración de un teorema).

  Las afirmaciones no demostradas se llaman conjeturas o hipótesis. Por ejemplo, una conjetura famosa es la Conjetura de Goldbach (1742): \emph{Todo número par mayor que 2 puede escribirse como suma de dos números primos.} Nadie ha sido capaz de demostrar que es verdad, pero tampoco se ha encontrado ningún número que no la cumpla.

  Hay otro tipo de afirmaciones matemáticas sin demostración, que se llaman \emph{axiomas} (o postulados). Son afirmaciones básicas, que se admiten como verdaderas sin demostración, y se toman como punto de partida para los demás razonamientos y definiciones. Así, por ejemplo, en Aritmética se admite como axioma que todo número natural $n$ tiene un sucesor ($n+1$); en Geometría euclídea, se toma como axioma que dos puntos determinan una recta; en Probabilidad, se toma como axioma que si $A$ y $B$ son sucesos incompatibles, la probabilidad de su unión es igual a la suma de sus probabilidades. La diferencia entre una conjetura y un axioma, ambos sin demostración, es que las conjeturas no son evidentes y necesitan demostración, mientras que los axiomas son evidentes y no necesitan demostración.
\end{remark}

\begin{remark}
  Las afirmaciones matemáticas se pueden clasificar en tres tipos según su alcance: \emph{universales} (todos los $x$ cumplen $p$), \emph{de existencia} (existe algún $x$ que cumple $p$), \emph{de unicidad} (existe un único $x$ que cumple $p$). La mayoría de las afirmaciones matemáticas son de tipo \emph{universal}. Por ejemplo, el Teorema de Pitágoras es \emph{universal}: \emph{Todos los triángulos rectángulos cumplen que el cuadrado de su hipotenusa es igual a la suma de los cuadrados de sus catetos}. El teorema lo cumplen todos los triángulos rectángulos que podamos imaginar.

Para demostrar una afirmación \emph{universal}, no basta con comprobar que se cumple en algunos casos, ni siquiera en muchos casos; es necesario demostrar que se cumple en todos. Una afirmación falsa puede cumplirse en algunos casos (entonces diríamos que es falsa porque la afirmación pretende ser válida en \emph{todos} los casos). Por ejemplo: \emph{Para todo número natural $n$, el número $n^2-n+41$ es un número primo.} Si probamos algunos casos, parece que la afirmación es verdadera:
  \begin{eqnarray*}
    n=1 & \Rightarrow & n^2-n+41=1-1+41=41\ \text{(es primo)} \\
    n=2 & \Rightarrow & n^2-n+41=4-2+41=43\ \text{(es primo)} \\
    n=3 & \Rightarrow & n^2-n+41=9-3+41=47\ \text{(es primo)} \\
    \vdots & \vdots & \vdots \\
    n=20 & \Rightarrow & n^2-n+41=400-20+41=421\ \text{(es primo)} \\
    \vdots & \vdots & \vdots
  \end{eqnarray*}
  Sin embargo, es falsa, porque no se cumple \emph{para todo número natural $n$}:
  \begin{eqnarray*}
    n=41 & \Rightarrow & n^2-n+41=41^2-41+41=41^2\ \text{(no es primo)} \\
    n=42 & \Rightarrow & n^2-n+41=42^2-42+41=47\cdot 53\ \text{(no es primo)}
  \end{eqnarray*}
 
La dificultad de las demostraciones de afirmaciones \emph{universales} es que, normalmente, los casos son infinitos: es imposible comprobarlos uno a uno. Es necesario, por eso, realizar unos razonamientos que nos convenzan de que la afirmación se cumplirá en todos los casos, aunque no la hayamos comprobado en todos ellos. Así, por ejemplo, la Conjetura de Goldbach (\emph{todo número par mayor que 2 se puede expresar como suma de dos números primos}), afirmación no demostrada, se ha comprobado (mediante ordenadores) que es verdadera para todos los números hasta $4\cdot10^{18}$. Sin embargo, no podemos asegurar que no haya un número par mayor que $4\cdot10^{18}$ que no la cumpla, hasta que no encontremos una demostración. Por eso sigue siendo una conjetura.
\end{remark}

\begin{remark}
  Las afirmaciones \emph{universales} equivalen (salvo por ciertos matices técnicos) a \emph{implicaciones}. Es lo mismo decir: \emph{todos los españoles son europeos}, que decir \emph{ser español implica ser europeo}, o bien, \emph{si $x$ es español, entonces $x$ es europeo}.
\end{remark}

\begin{example}
  Un ejemplo de demostración \emph{fácil} es la siguiente:

  Proposición:
  \begin{center}
    \emph{Existen números irracionales $x$ e $y$ tales que $x^y$ es racional}.    
  \end{center}

  Demostración:

  Tomemos $x=\sqrt{2}$ e $y=\sqrt{2}$, que son ambos irracionales, como nos pide la proposición. El número $\sqrt{2}^{\sqrt{2}}$ puede ser racional o irracional. Si es racional, ya hemos encontrado dos números que cumplen la proposición. Si es irracional, entonces tomamos $x=\sqrt{2}^{\sqrt{2}}$, e $y=\sqrt{2}$, que, en el caso que estamos considerando, son ambos irracionales. Ahora, $\left(\sqrt{2}^{\sqrt{2}}\right)^{\sqrt{2}}=\left(\sqrt{2}\right)^{\sqrt{2}\cdot\sqrt{2}}=\left(\sqrt{2}\right)^2=2$, que es racional. (Nota: en la actualidad sabemos que $\sqrt{2}^{\sqrt{2}}$ es en realidad irracional). 
\end{example}

\begin{example}
  Un ejemplo de demostración difícil es la del Teorema de Euclides.
  
  Teorema de Euclides:
  \begin{center}
    \emph{Hay infinitos números primos.}
  \end{center}

  Demostración:
  \begin{enumerate}
  \item Vamos a demostrar que dado cualquier conjunto finito de números primos, $P=\{p_1,p_2,\hdots,p_k\}$, siempre podemos encontrar un número primo que no está en dicho conjunto. Eso significa que no hay ningún conjunto finito que contenga a todos los números primos, luego el conjunto de todos los números primos es infinito.
  \item Llamaremos $p$ al producto de todos los números primos de $P$: $p=p_1p_2\cdots p_k$.
  \item Sea $n=p+1$. Claramente, $n$ es un número natural mayor que todos los números primos del conjunto $P$, ya que es mayor que el producto de todos ellos. Es decir, $n$ es un número distinto de todos los números primos de $P$.
  \item Si $n$ es primo, entonces hay un número primo que no estaba en $P$, como queríamos demostrar.
  \item Si $n$ es compuesto, entonces debe tener algún divisor primo (porque todos los números compuestos se pueden expresar como producto de números primos distintos de $1$ y de sí mismos). Sea $q$ un divisor primo de $n$, es decir, $n=qr$.
  \item Si $q$, además de ser divisor de $n$, fuese también divisor de $p$ ($p=qr'$), entonces sería divisor de $1$:
    \[n=qr,\ p=qr',\ n=p+1 \Rightarrow qr=qr'+1 \Rightarrow qr-qr'=1 \Rightarrow q(r-r')=1 \Rightarrow qr''=1\]
  \item Como $1$ no tiene divisores distintos de él mismo, $q$ no puede ser divisor de $p$. Si $q$ no es divisor de $p$, entonces no puede ser ninguno de los números primos $p_1$, $p_2$,..., $p_k$, cuyo producto es igual a $p$.
  \item Luego, $q$ sería un número primo que no está en $P$. Luego no todos los números primos están en $P$, como queríamos demostrar.
  \end{enumerate}
\end{example}

\begin{remark}
  En las siguientes secciones se expondrán, mediante ejemplos, algunas estrategias de demostración habituales.
\end{remark}

\section{Demostración por casos}

\begin{example}
  Teorema: para todo $x\in\mathbb{Z}$, $x(x+1)$ es un número par.

  \vspace{.3cm}

  \emph{Caso 1}. Supongamos que $x$ es par. En este caso, existe $k\in\mathbb{Z}$ tal que $x=2k$, de donde:
  \[x(x+1) = (2k)(2k+1)=2\left[k(2k+1)\right]=2y,\ \text{siendo }y=k(2k+1)\]
  Si $k$ es entero, entonces $k(2k+1)=y$ también es entero, y, sea cual sea el valor de $y$, $2y$ es siempre un número par. Luego $x(x+1)=2y$ es un número par.

  \vspace{.3cm}

  \emph{Caso 2}. Supongamos que $x$ es impar. En este caso, existe $k\in\mathbb{Z}$ tal que $x=2k+1$, de donde:
  \[x(x+1) = (2k+1)(2k+1+1) = (2k+1)(2k+2) = 2(2k+1)(k+1) = 2z,\ \text{siendo }z=(2k+1)(k+1)\]
  Si $k$ es entero, entonces $(2k+1)(k+1)=z$ también es entero, y, sea cual sea su valor, $2z$ es siempre un número par. Luego, $x(x+1)=2z$ es un número par.
\end{example}

\section{Demostración por inducción}

\begin{remark}
  Supongamos que queremos demostrar que determinada propiedad $p$ se cumple para todos los números naturales. El método de inducción, permite realizar este tipo de demostraciones, en dos pasos:
  \begin{enumerate}
  \item Se demuestra que el primer número (el $1$, el $2$, o el que interese) cumple la propiedad $p$.
  \item Se demuestra que si un número $n$ cumpliera $p$, entonces el siguiente, $n+1$ también la cumpliría.
  \end{enumerate}
  El segundo paso nos asegura que, a partir del primer número, todos van a cumplir $p$: si el $1$ cumple $p$, el siguiente, el $2$, también. Si el $2$ cumple $p$, el siguiente, el $3$, también, y así, sucesivamente.
\end{remark}

\begin{example}
  Demostrar que es posible dibujar un segmento de longitud $\sqrt{n}$, para cualquier $n$ natural, utilizando solo un segmento de longitud $1$, regla (no graduada) y compás.

  \vspace{.3cm}

  Demostración por inducción:
  \begin{enumerate}
  \item Es posible dibujar un segmento de longitud $\sqrt{2}$: tenemos un segmento de longitud $1$; trazamos una perpendicular a dicho segmento por su extremo (esto se puede hacer con la regla no graduada y el compás); sobre dicha perpendicular, desde el extremo del segmento de longitud $1$, determinamos otro segmento de longitud $1$ (con el compás). Hemos dibujado un triángulo rectángulo cuyos catetos miden $1$. La hipotenusa, según el Teorema de Pitágoras, mide $\sqrt{1^2+1^2}=\sqrt{2}$. Luego hemos dibujado un segmento de longitud $\sqrt{2}$.
  \item Si es posible dibujar un segmento de longitud $\sqrt{n}$, entonces también se puede construir uno de longitud $\sqrt{n+1}$. Suponiendo que se pueda dibujar un segmento de longitud $\sqrt{n}$, se podrá dibujar un triángulo rectángulo cuyos catetos sean $\sqrt{1}$ y $\sqrt{n}$ (por el mismo procedimiento anterior). La hipotenusa de dicho triángulo mide: $\sqrt{1^2+\left(\sqrt{n}\right)^2}=\sqrt{1+n}$.
  \end{enumerate}

\end{example}

\section{Demostración por reducción al absurdo}

\begin{example}
  Teorema: $\sqrt{2}$ es irracional.

  \vspace{.3cm}

  Antes de demostrar el teorema principal, demostraremos el siguiente \emph{lema}: el cuadrado de un número impar es también impar.
  Demostración: si $n$ es impar, entonces $n=2k+1$ para algún entero $k$. Luego, $n^2=(2k+1)^2=4k^2+4k+1=4k(k+1)+1$. Como $4k(k+1)$ es par, $4k(k+1)+1$, que es el número siguiente (consecutivo), ha de ser impar.

  Supongamos que $\sqrt{2}$ fuese racional. Un número racional es un número que se puede expresar como un cociente de dos números enteros (fracción). Toda fracción se puede simplificar hasta una fracción equivalente irreducible, en la que numerador y denominador no tienen factores comunes. Por lo tanto, si $\sqrt{2}$ fuese racional, existirían dos números enteros $a$ y $b$, primos entre sí (es decir, sin factores primos comunes), tales que $\sqrt{2}=\dfrac{a}{b}$.

  \[\sqrt{2}=\dfrac{a}{b} \iff 2=\left(\dfrac{a}{b}\right)^2 \iff \dfrac{a^2}{b^2}=2 \iff a^2=2b^2\]

  De la igualdad anterior deducimos que $a^2$ es par. Si $a^2$ es par, entonces $a$ también es par (según el lema demostrado al principio).

  Dado que $a$ y $b$ no pueden tener factores comunes, si $a$ es par (tiene factor $2$), $b$ ha de ser impar (no es divisible por $2$).

  Por otro lado, dado que $a$ es par, $a=2k$, para algún entero $k$. De la igualdad anterior, deducimos:

  \[a^2=2b^2 \iff (2k)^2=2b^2 \iff 4k^2=2b^2 \iff 2k^2=b^2\]

  Por lo tanto, $b^2$ es un número par. Si $b^2$ es par, según el lema demostrado al principio, $b$ también es par.

  De la afirmación de que existen $a$ y $b$ enteros primos entre sí tales que $\sqrt{2}=\dfrac{a}{b}$, hemos deducido dos afirmaciones contradictorias: que $b$ es impar y que $b$ es par. Luego la afirmación inicial ha de ser falsa: no existen $a$ y $b$ primos entre sí tales que $\sqrt{2}=\dfrac{a}{b}$. Es decir, $\sqrt{2}$ es irracional.
\end{example}

\section{Contraejemplos}

\begin{remark}
  Los contraejemplos se utilizan para demostrar que una afirmación es falsa. Un contraejemplo es un ejemplo contrario a lo que se afirma. No sirven, por tanto, para demostrar una afirmación, sino para refutarla.
\end{remark}

\begin{example}
  Di si la siguiente afirmación es verdadera o falsa: \emph{toda función continua es derivable}. En caso de que sea verdadera, demuéstrala. En caso de que sea falsa, demuestra que es falsa.

  \vspace{.3cm}

  La afirmación es falsa. Para demostrar que es falsa, nos basta dar un ejemplo de función que no verifica la afirmación. La función $f(x)=|x|$ es una función continua, sin embargo, no es derivable, ya que no es derivable en $x=0$: $f'(0^-)=-1\neq f'(0^+)=1$.
\end{example}

\begin{remark}
  Como se ve en este ejemplo, suele ser más fácil demostrar que una afirmación es falsa, que demostrar que es verdadera. Esto es así porque la mayoría de las afirmaciones son \emph{universales}. Para demostrar que es verdadera, tenemos que garantizar que se cumplirá en todos los casos. Para demostrar que es falsa, basta con encontrar un caso en que no se cumpla.
\end{remark}

\begin{remark}
  Para demostrar que una afirmación de tipo universal es falsa, basta con encontrar un contraejemplo. Sin embargo, habitualmente, ese ejemplo no será el único. Si así fuera, bastaría con incluirlo como excepción en el enunciado de la afirmación para convertirla en verdadera. Por ejemplo, si la única función continua pero no derivable fuera $f(x)=|x|$, la afirmación \emph{toda función continua, excepto $f(x)=|x|$, es derivable}, sería verdadera. Pero como hay muchos más contraejemplos, esta afirmación también es falsa.
\end{remark}


\chapter{Espacios vectoriales}

\newpage\section{Espacios vectoriales}

\begin{definition}[Espacio vectorial]Sea un conjunto $V$, a cuyos elementos
llamaremos {\tmstrong{vectores}}, y sea un cuerpo $K$, a cuyos elementos
llamaremos escalares. Se dice que $V$ es un {\tmstrong{espacio vectorial}}
sobre $K$ si existen dos operaciones, llamadas ``suma'' y ``producto por
escalar'', tales que:
\begin{enumeratealpha}
  \item La ``suma de vectores'' es una operación interna ($+ : V \times V
  \rightarrow V$) que cumple:
  
  \begin{itemize}
    \item Propiedad asociativa: $\forall \vec{u}, \vec{v}, \vec{w} \in V,
    \vec{u} + ( \vec{v} + \vec{w} ) = ( \vec{u} + \vec{v} ) + \vec{w}$
    
    \item Propiedad conmutativa: $\forall \vec{u}, \vec{v} \in V, \vec{u} +
    \vec{v} = \vec{v} + \vec{u}$
    
    \item Elemento neutro (vector nulo): $\exists \overrightarrow{o} \in V /
    \forall \overrightarrow{u} \in V, \vec{u} + \vec{o} = \vec{u}$
    
    \item Elemento simétrico (opuesto): $\forall \vec{u} \in V, \exists -
    \vec{u} / \vec{u} + ( - \vec{u} ) = \vec{o}$
  \end{itemize}
  
  \item El ``producto por escalar'' es una operación externa ($\cdot : V \times
  K \rightarrow V$) que cumple:
  
  \begin{itemize}
    \item Propiedad distributiva: $\forall \vec{u}, \vec{v} \in V, \lambda,
    \mu \in K, \left\{\begin{array}{l}
      \lambda ( \vec{u} + \vec{v} ) = \lambda \vec{u} + \lambda \vec{v}\\
      ( \lambda + \mu ) \vec{u} = \lambda \vec{u} + \mu \vec{u}
    \end{array}\right.$
    
    \item Propiedad asociativa: $\forall \vec{u} \in V, \lambda, \mu \in K,
    \lambda ( \mu \vec{u} ) = ( \lambda \mu ) \vec{u}$
    
    \item Elemento neutro: $\forall \vec{u} \in V, 1 \vec{u} = \vec{u}$
  \end{itemize}
\end{enumeratealpha}
\end{definition}

\begin{remark}Recuérdese que el único cuerpo que conocemos es $\mathbb{R}$, así que,
para nosotros, $K \equiv \mathbb{R}$. El conjunto de los números complejos
$\mathbb{C}$ también es un cuerpo.\end{remark}

\begin{remark}El símbolo utilizado para representar la ``suma de vectores'' ($+$) es el
mismo que hemos utilizado siempre para la ``suma de escalares''. Sin embargo, se
trata de dos operaciones de distinta naturaleza, que en la mayoría de los
casos se efectúan de maneras muy distintas. Siempre debemos prestar atención a
los objetos que sumamos (si son vectores o escalares). Una expresión como
$\vec{v} + \lambda$ no tiene sentido, porque en ningún momento hemos definido
una operación ``suma de vector y escalar''.\end{remark}

\begin{theorem}
  [Propiedades básicas]En un espacio vectorial $V$ sobre un cuerpo
  $K$, para cualesquiera que sean $\vec{u}, \vec{v} \in V$ y $\lambda, \mu \in
  K$, se verifica que:
  \begin{enumeratealpha}
    \item $\lambda \vec{o} = \vec{o}$
    
    \item $0 \vec{u} = \vec{o}$
    
    \item $\lambda \vec{u} = \vec{o} \Rightarrow ( \lambda = 0 ó \vec{u} =
    \vec{o} )$
    
    \item $( \lambda \vec{u} = \mu \vec{u}$ y $\vec{u} \neq \vec{o} )
    \Rightarrow \lambda = \mu$
    
    \item $( \lambda \vec{u} = \lambda \vec{v}$ y $\lambda \neq 0 )
    \Rightarrow \vec{u} = \vec{v}$
    
    \item $( - \lambda ) \vec{u} = \lambda ( - \vec{u} ) = - \lambda \vec{u}$
  \end{enumeratealpha}
\end{theorem}

\begin{remark}Estas propiedades son consecuencias directas de las propiedades de las
operaciones que constituyen el espacio vectorial y se cumplen por tanto para
todo espacio vectorial, pudiéndose demostrar (es un buen ejercicio) en
general, sin necesidad de definir qué significan (o cómo se efectúan) las
operaciones + (suma) y $\cdot$ (producto por un escalar).\end{remark}

\begin{example}
  El conjunto $\mathbb{R} \times \mathbb{R}=\mathbb{R}^2 = \{ ( a, b ) / a,
  b \in \mathbb{R} \}$ es un espacio vectorial sobre $\mathbb{R}$, si en él
  definimos la operación suma (+) como $( a, b ) + ( c, d ) = ( a + b, c + d
  )$, y la operación producto por escalar como $k ( a, b ) = ( ka, kb )$, ya
  que estas operaciones cumplen las propiedades de la definición.
\end{example}

\begin{example}
El conjunto de todas las matrices reales de dimensión $m \times n$ (que
se representa por $\mathcal{M}_{m \times n}$) es un espacio vectorial, ya que
las operaciones suma y producto por escalar cumplen las propiedades de la
definición.
\end{example}

\begin{example}
  El conjunto de todos los polinomios $P ( x )$ es un espacio vectorial sobre
  $\mathbb{R}$ respecto de las operaciones usuales de suma de polinomios y
  producto de un número por un polinomio.
\end{example}

\newpage\section{Dependencia lineal}

\begin{definition}
  [Combinación lineal]Se dice que un vector $\vec{w}$ es una
  combinación lineal de un conjunto de vectores $\{ \vec{v}_1, \ldots,
  \vec{v}_k \}$ si existe un conjunto de escalares $\{ \lambda_1, \ldots,
  \lambda_k \}$ tales que:
  \begin{center}
    $\vec{w} = \lambda_1 \vec{v}_1 + \ldots + \lambda_k \vec{v}_k =
    \overset{k}{\underset{i = 1}{\sum}} \lambda_i \vec{v}_i$
  \end{center}
  Si un vector es una combinación lineal de un conjunto de vectores, también
  se dice que depende linealmente de ellos. A los escalares $\lambda_1, \ldots, \lambda_k$ se les llama coeficientes de
  la combinación lineal.
\end{definition}

\begin{example}
  El vector $( - 6, 1 )$ de $\mathbb{R}^2$ es una combinación lineal de los
  vectores de $\mathbb{R}^2$ $\{ ( 1, - 1 ), ( 2, 0 ), ( - 2, 1 ) \}$, ya que
  \begin{center}
    $2 ( 1, - 1 ) - ( 2, 0 ) + 3 ( - 2, 1 ) = ( - 6, 1 )$
  \end{center}
Los coeficientes de la combinación lineal anterior serían: $2,
  - 1, 3$.
\end{example}

\begin{definition}
  [Dependencia lineal]Se dice que un conjunto de vectores es
  linealmente dependiente (o ligado) si al menos uno de ellos es una
  combinación lineal de los demás. En caso contrario, se dice que el conjunto
  de vectores es linealmente independiente (o libre).
\end{definition}

\begin{remark}Se puede demostrar que un conjunto de vectores $\{ \vec{v}_1, \ldots,
\vec{v}_k \}$ es linealmente independiente si y solo si
$\overset{k}{\underset{i = 1}{\sum}} \lambda_i \vec{v}_i = \vec{o} \Rightarrow
\lambda_i = 0, \forall i \in \{ 1, \ldots, k \}$, es decir, si la única
combinación lineal que da como resultado el vector nulo es la que tiene todos
los coeficientes nulos.\end{remark}

\begin{remark}Un conjunto de vectores que incluya al vector nulo siempre es ligado (ya
que el vector nulo siempre se puede obtener como combinación lineal de los
demás).\end{remark}

\begin{remark}Un conjunto de un único vector se considera siempre libre, salvo que
dicho vector sea $\vec{o}$.\end{remark}

\begin{remark}Un conjunto de dos vectores no nulos $\{ \vec{u}, \vec{w} \}$ es ligado
si y solo si los dos vectores son proporcionales, ya que si uno de los dos se
puede obtener como combinación lineal del otro, es que existe algún escalar
$\lambda$ tal que $\vec{u} = \lambda \vec{w}$ (esto es lo mismo que decir que
$\vec{u}$ y $\vec{w}$ son proporcionales).\end{remark}

\begin{remark}Se puede demostrar que si un conjunto de vectores $\{ \vec{v}_1, \ldots,
\vec{v}_k \}$ es linealmente independiente, entonces no existen dos
combinaciones lineales distintas de dichos vectores que den el mismo
resultado. La demostración (por reducción al absurdo) se deja como
ejercicio.\end{remark}

\begin{example}
  El conjunto de vectores de $\mathbb{R}^2$, $\{ ( 1, - 1 ), ( - 1, 1 ), ( 2,
  - 2 ) \}$, es linealmente dependiente porque al menos uno de ellos se puede
  obtener como combinación lineal de los otros dos, puesto que se tiene
  \begin{center}
    $( 2, - 2 ) = 2 ( 1, - 1 ) - ( - 1, 1 )$
  \end{center}
En este caso, cualquiera de los tres vectores se puede obtener
  como combinación lineal de los otros dos. Pero, basta con uno de ellos para
  que el conjunto sea ligado. ¿Hay casos en los que alguno se pueda expresar
  como combinación lineal de los demás, pero solo ese pueda expresarse así? La
  respuesta es afirmativa. Buscar un ejemplo de esto se deja como ejercicio.
\end{example}

\begin{example}
  El conjunto de vectores de $\mathbb{R}^2$, $\{ ( 2, - 1 ), ( - 10, 5 ) \}$,
  es ligado porque los dos vectores son proporcionales: $( - 10, 5 ) = - 5 (
  2, - 1 )$.
\end{example}

\begin{example}
  El conjunto de polinomios de 2º grado $\{ x^2 + 1, x + 1, x^2 -
  1, x^2 - 2 x + 1 \}$, es linealmente dependiente, ya que: \begin{center}
    $2 ( x^2 + 1 ) - 2 ( x + 1 ) - ( x^2 - 1 ) = 2 x^2 + 2 - 2 x - 2 - x^2 + 1
    = x^2 - 2 x + 1$
  \end{center}
El cuarto polinomio se puede obtener como combinación lineal
  de los tres primeros con coeficientes: $2, - 2, - 1$.
\end{example}

\begin{definition}
  [Rango]El rango de un conjunto de vectores $S$ es $n$ si y solo si
  se cumplen las dos condiciones siguientes:
  
  \begin{enumeratealpha}
    \item existe al menos un subconjunto de $n$ vectores de $S$ linealmente
    independiente;
    
    \item cualquier subconjunto de $S$ con más de $n$ vectores es linealmente
    dependiente.
  \end{enumeratealpha}
\end{definition}

\begin{remark}El rango de un conjunto de vectores es el mayor número de vectores
linealmente independientes que se pueden tomar de dicho conjunto.\end{remark}

\begin{remark}Un conjunto de vectores es libre si y solo si su rango es igual a su
número de vectores.\end{remark}

\begin{example}
  El rango de $S = \{ ( 1, - 1 ), ( - 1, 1 ), ( 2, - 2 ) \}$ es 2, ya que $S$
  es un conjunto ligado (según se vio en un ejemplo anterior), pero $\{ ( 1, -
  1 ), ( - 1, 1 ) \}$ es un conjunto linealmente independiente.
\end{example}

\newpage\section{Bases}

\begin{definition}
  [Conjunto generador]Dado un espacio vectorial $V$, se dice que un
  conjunto de vectores $S = \{ \vec{v}_1, \ldots, \vec{v}_k \}$ es un conjunto
  generador de $V$ si cualquier vector de $V$ se puede obtener como
  combinación lineal de los vectores de $S$.
\end{definition}

\begin{example}
  El conjunto $S_1 = \{ ( 1, 1 ), ( 1, - 1 ), ( - 1, 1 ), ( - 1, - 1 ) \}$ es
  un sistema generador de $\mathbb{R}^2$, porque cualquier vector de
  $\mathbb{R}^2$ se puede obtener como combinación lineal de los vectores de
  $S_1$. Otra cuestión sería demostrar esto que acabamos de afirmar (se
  propone como ejercicio).
\end{example}

\begin{definition}
  [Base]Dado un espacio vectorial $V$, se dice que un conjunto de
  vectores $S = \{ \vec{v}_1, \ldots, \vec{v}_k \}$ es una base de $V$ si $S$
  es un conjunto libre y generador de $V$.
\end{definition}

\begin{example}
  El conjunto $S_2 = \{ ( 1, 1 ), ( 1, - 1 ) \}$ es una base de
  $\mathbb{R}^2$ porque es un conjunto generador (cualquier vector de
  $\mathbb{R}^2$ se puede obtener como combinación lineal de esos dos), y
  además es linealmente independiente (solo son dos vectores, no nulos, y no
  son proporcionales). Sin embargo, el conjunto $S_1$ del ejemplo anterior no
  es una base, aunque sea generador, porque es linealmente dependiente (claro,
  si $S_2$ es generador, también $( - 1, 1 )$ y $( - 1, - 1 )$ se pueden
  obtener como combinación lineal de ellos).
\end{example}

\begin{example}
  El conjunto $B = \{ 1, x, x^2 \}$ es una base del espacio vectorial
  $\mathcal{P}_3$ de los polinomios de segundo grado. Demostración trivial.
\end{example}

\begin{theorem}
  [Teorema de la dimensión]Todas las bases de un mismo espacio
  vectorial tienen el mismo número de vectores.
\end{theorem}

\begin{definition}
  [Dimensión]Se llama dimensión de un espacio vectorial al número de
  vectores de sus bases.
\end{definition}

\begin{remark}Aunque no vamos a considerarlos en este curso, debemos anotar que
existen espacios vectoriales cuyas bases tienen infinitos vectores. De dichos
espacios se dice que tienen dimensión infinita. Por ejemplo, el conjunto de
todos los polinomios es un espacio vectorial de dimensión infinita. Una base
de dicho espacio sería el conjunto (infinito) de polinomios: $\{ 1, x, x^2,
x^3, \ldots, x^n, \ldots \}$.\end{remark}

\begin{remark}Es inmediato demostrar que si la dimensión de un espacio vectorial $V$
es $n$, cualquier conjunto de más de $n$ vectores de $V$ es linealmente
dependiente. Es decir, la dimensión de un espacio es el máximo rango que puede
tener cualquier conjunto de vectores del mismo.\end{remark}

\begin{remark}Si la dimensión de un espacio vectorial es $n$, entonces cualquier
conjunto generador de $V$ debe tener al menos $n$ vectores. Es decir, la
dimensión es el tamaño mínimo de los conjuntos generadores de $V$. Además, un
conjunto de $n$ vectores independientes siempre es una base.\end{remark}

\begin{example}
  El espacio $\mathbb{R}^2$, estudiado en cursos anteriores, tiene dimensión
  2. Esto significa que todas sus bases tienen 2 vectores. Por tanto, podemos
  estar seguros de que un conjunto de 3 vectores no es una base.
\end{example}

\newpage\section{Coordenadas}

\begin{definition}
  [Coordenadas]Sea $V$ un espacio vectorial sobre un cuerpo $K$ de
  dimensión $n$, y sea $B = \{ \vec{u}_1, \ldots, \vec{u}_n \}$ una base de
  $V$, y sea $\vec{w}$ un vector de $V$. Se dice que los escalares $\lambda_1,
  \ldots, \lambda_n$ son las coordenadas de $\vec{w}$ respecto de la base $B$
  si y solo si $\vec{w} = \lambda_1 \vec{u}_1 + \ldots + \lambda_n \vec{u}_n$.
  Para indicar que $\vec{w}$ es el vector cuyas coordenadas respecto de $B$
  son $\lambda_1, \ldots, \lambda_n$, se escribe: $\vec{w} ( \lambda_1,
  \ldots, \lambda_n )_B$.
\end{definition}

\begin{remark}Existencia y unicidad de las coordenadas. Todo vector de $V$ tiene
coordenadas respecto de cualquier base $B$, y, además, estas son únicas (es
decir, que cada vector tiene un único conjunto de coordenadas, y que no hay
dos vectores con las mismas coordenadas).\end{remark}

\begin{example}
  Sea $\mathcal{P}_3$ el espacio vectorial de todos los polinomios reales de
  2º grado (o menor). Sean las bases $B_1 = \{ x^2, x, 1 \}$, $B_2
  = \{ x^2 + x + 1, x - 1, x + 1 \}$ de $\mathcal{P}_3$. Sea $q ( x ) = x^2 -
  2 x + 2$ un ``vector'' de $\mathcal{P}_3$. Las coordenadas de $q ( x )$
  respecto de $B_1$ son, evidentemente, $( 1, - 2, 2 )$. Para hallar las
  coordenadas de $q ( x )$ respecto de $B_2$ procederíamos del siguiente modo:
  
  $\lambda_1 ( x^2 + x + 1 ) + \lambda_2 ( x - 1 ) + \lambda_3 ( x + 1 ) = x^2
  - 2 x + 2 \Leftrightarrow$
  
  $\Leftrightarrow \lambda_1 x^2 + \lambda_1 x + \lambda_1 + \lambda_2 x -
  \lambda_2 + \lambda_3 x + \lambda_3 = x^2 - 2 x + 2 \Leftrightarrow$
  
  $\Leftrightarrow \lambda_1 x^2 + ( \lambda_1 + \lambda_2 + \lambda_3 ) x + (
  \lambda_1 - \lambda_2 + \lambda_3 ) = x^2 - 2 x + 2 \Leftrightarrow$
  
  $\Leftrightarrow \left\{\begin{array}{l}
    \lambda_1 = 1\\
    \lambda_1 + \lambda_2 + \lambda_3 = - 2\\
    \lambda_1 - \lambda_2 + \lambda_3 = 2
  \end{array}\right. \Leftrightarrow \left\{\begin{array}{l}
    \lambda_1 = 1\\
    \lambda_2 + \lambda_3 = - 3\\
    - \lambda_2 + \lambda_3 = 1
  \end{array}\right. \Leftrightarrow \left\{\begin{array}{l}
    \lambda_1 = 1\\
    \lambda_2 + \lambda_3 = - 3\\
    2 \lambda_3 = - 2
  \end{array}\right. \Leftrightarrow \left\{\begin{array}{l}
    \lambda_1 = 1\\
    \lambda_2 + \lambda_3 = - 3\\
    \lambda_3 = - 1
  \end{array}\right. \Leftrightarrow \left\{\begin{array}{l}
    \lambda_1 = 1\\
    \lambda_2 = - 2\\
    \lambda_3 = - 1
  \end{array}\right.$
  
  Luego las coordenadas de $q ( x )$ respecto de $B_2$ son $( 1, - 2, - 1 )$.
\end{example}

\begin{theorem}
  [Cambio de coordenadas]Sean $B = \{ \vec{u}_1, \ldots, \vec{u}_n \}$
  y $B' = \{ \vec{u}_1', \ldots, \vec{u}_n' \}$ sendas bases de un espacio
  vectorial $V$. Sea $\vec{x}$ un vector cualquiera de $V$. Las coordenadas de
  $\vec{x}$ respecto de $B$ y respecto de $B'$ están relacionadas por la
  ecuación matricial:
  \begin{center}
    $X = M X' \Leftrightarrow \left(\begin{array}{c}
      x_1\\
      \ldots\\
      x_n
    \end{array}\right) = \left(\begin{array}{ccc}
      u_{11}' & \ldots & u_{1 n}'\\
      \ldots & \ldots & \ldots\\
      u_{n 1}' & \ldots & u_{n n}'
    \end{array}\right) \left(\begin{array}{c}
      x_1'\\
      \ldots\\
      x_n'
    \end{array}\right)$
  \end{center}
  siendo,
  
  $X$, una matriz columna formada por las coordenadas de $\vec{x}$ respecto de
  $B$,
  
  $X'$, una matriz columna formada por las coordenadas de $\vec{x}$ respecto
  de $B'$,
  
  $M$, una matriz cuadrada cuya columna $k$ contiene las coordenadas del
  vector $\vec{u}_k'$ de $B'$ respecto de la base $B$ ($\vec{u}_k' = u_{1 k}
  \vec{u}_1 + \ldots + u_{n k} \vec{u}_n$).
\end{theorem}

\begin{remark}La matriz $M$ se llama matriz de cambio de coordenadas, y es siempre
invertible, porque sus columnas son vectores de una base (linealmente
independientes). Cuando queremos hacer un cambio de coordenadas, normalmente
conocemos $X$ y $M$, y lo que queremos es hallar $X'$. Como $M$ es invertible,
en la ecuación anterior podemos despejar $X'$ así: $X' = M^{- 1} X$.\end{remark}

\begin{example}
  Sean las bases $B = \{ ( 1, 0 ), ( 0, 1 ) \}$ y $B' = \{ ( 1, 1 ), ( - 1, 1
  ) \}$ de $\mathbb{R}^2$. Hallar las coordenadas respecto de la base $B'$
  del vector $\vec{x} ( 4, 2 )_B$.
  
  Necesitamos las coordenadas de los vectores de $B'$ respecto de $B$. Es
  inmediato comprobar que sus coordenadas son sus mismas componentes. Por
  tanto, la matriz de cambio de coordenadas es:
  
  $M = \left(\begin{array}{cc}
    1 & - 1\\
    1 & 1
  \end{array}\right) \Rightarrow M^{- 1} = \dfrac{1}{\det ( M )} [ \tmop{Adj} (
  M ) ]^t = \dfrac{1}{2} \left(\begin{array}{cc}
    1 & - 1\\
    1 & 1
  \end{array}\right)^t = \dfrac{1}{2} \left(\begin{array}{cc}
    1 & 1\\
    - 1 & 1
  \end{array}\right)$
  
  Aplicando la ecuación anterior: $X = MX' \Leftrightarrow X' = M^{- 1} X
  \Leftrightarrow X' = \dfrac{1}{2} \left(\begin{array}{cc}
    1 & 1\\
    - 1 & 1
  \end{array}\right) \left(\begin{array}{c}
    4\\
    2
  \end{array}\right) = \left(\begin{array}{c}
    3\\
    - 1
  \end{array}\right)$
  
  Luego $\vec{x} ( 4, 2 )_B = \vec{x} ( 3, - 1 )_{B'}$. Efectivamente, $3 ( 1,
  1 ) - ( - 1, 1 ) = ( 3 + 1, 3 - 1 ) = ( 4, 2 ) = \vec{x}$
\end{example}

\newpage\section{Subespacios vectoriales}

\begin{definition}
  [Subespacio vectorial]Sea $V$ un espacio vectorial sobre $K$. Sea $S
  \subset V$ un subconjunto no vacío de $V$. Se dice que $S$ es un subespacio
  vectorial de $V$ si y solo si toda combinación lineal de vectores de $S$ da
  como resultado un vector de $S$.
\end{definition}

\begin{remark}Todos los subespacios vectoriales contienen al vector nulo $\vec{o}$, ya
que multiplicar por 0 un vector de $S$ es una combinación lineal de vectores
de $S$, el resultado es $\vec{o}$, y debe ser un vector de $S$.\end{remark}

\begin{remark}Un subespacio vectorial es un espacio vectorial (cumple todas las
propiedades).\end{remark}

\begin{definition}
  [Envolvente lineal]Sea $A$ un conjunto cualquiera de vectores de un
  espacio vectorial $V$. Al conjunto de todas las posibles combinaciones
  lineales de los vectores de $A$ se le llama envolvente lineal de $A$, y se
  representa por $\mathcal{L}( A )$.
\end{definition}

\begin{remark}La envolvente lineal de un conjunto cualquiera de vectores de un espacio
vectorial $V$ es un subespacio vectorial de $V$.\end{remark}

\begin{remark}$\mathcal{L}( A )$ es el subespacio vectorial ``más pequeño'' que contiene
a $A$ (es decir, cualquier otro subespacio que contenga a $A$ contiene también
a $\mathcal{L}( A )$).\end{remark}

\begin{remark}La dimensión del espacio vectorial $\mathcal{L}( A )$ es igual al rango
de $A$. De hecho también podíamos haber definido el rango de un conjunto de
vectores como la dimensión del subespacio generado por él.\end{remark}

\begin{example}
  El conjunto $A = \{ ( \lambda, 0 ) / \lambda \in \mathbb{R} \}$ es un
  subespacio vectorial de $\mathbb{R}^2$, tiene dimensión 1, y es la
  envolvente lineal de $B = \{ ( 1, 0 ) \}$: $\mathcal{L}( B ) = A$.
\end{example}

\begin{example}
  El conjunto de todos los polinomios de primer grado o menor es un subespacio
  vectorial del conjunto de todos los polinomios de segundo grado o menor. Es
  un subespacio de dimensión 2.
\end{example}

\begin{example}
  El subconjunto de $\mathbb{R}^2$, $A = \{ ( \lambda, 3 ) / \lambda \in
  \mathbb{R} \}$ no es un subespacio vectorial. El vector $\vec{u} = ( 1, 3
  )$ es un vector de $A$, sin embargo, el vector $\vec{w} = 2 \vec{u} = 2 ( 1,
  3 ) = ( 2, 6 )$ no es un vector de $A$, pese a ser combinación lineal de un
  vector de $A$. Nótese que $\vec{o} = ( 0, 0 ) \notin A$.
\end{example}

\chapter{Circunferencia y esfera}

\newpage\section{Circunferencia}

\begin{definition}[Circunferencia]Se llama circunferencia de centro $C$ y radio
$\rho$ al lugar geométrico del plano $E_2$ definido por:
\begin{center}
  $L = \{ P ( x, y ) \in E_2 / d ( P, C ) = \rho \}$
\end{center}
\end{definition}

\begin{theorem}
  [Ecuación de la circunferencia]La circunferencia de centro $C ( x_0,
  y_0 )$ y radio $\rho$ admite como ecuación:
  \begin{center}
    $( x - x_0 )^2 + ( y - y_0 )^2 = \rho^2$
  \end{center}
  O bien,
  \begin{center}
    $x^2 + y^2 + A x + B y + C = 0$
  \end{center}
  siendo,
  
  $A = - 2 x_0 ; B = - 2 y_0 ; C = x_0^2 + y_0^2 - \rho^2$
\end{theorem}

\begin{theorem}
  [Recta tangente a la circunferencia]La recta tangente a la
  circunferencia de centro $C ( x_0, y_0 )$ y radio $\rho$ en el punto $P (
  x_1, y_1 )$ de dicha circunferencia viene dada por:
  \begin{center}
    $t : ( x_0 - x_1 ) ( x - x_1 ) + ( y_0 - y_1 ) ( y - y_1 ) = 0$
  \end{center}
  
\end{theorem}



{}

\newpage\section{Esfera}

\begin{definition}[Esfera]Se llama esfera de centro $C$ y radio $\rho$ al lugar
geométrico del espacio definido por:
\begin{center}
  $L = \{ P \in E_3 / d ( P, C ) = \rho \}$
\end{center}
\end{definition}

\begin{theorem}
  [Ecuación de la esfera]La esfera de centro $C ( x_0, y_0, z_0 )$ y
  radio $\rho$ admite como ecuación:
  \begin{center}
    $( x - x_0 )^2 + ( y - y_0 )^2 + ( z - z_0 )^2 = \rho^2$
  \end{center}
  O bien,
  \begin{center}
    $x^2 + y^2 + z^2 + A x + B y + C z + D = 0$
  \end{center}
  siendo,
  
  $A = - 2 x_0 ; B = - 2 y_0 ; C = - 2 z_0 ; D = x_0^2 + y_0^2 + z_0^2 -
  \rho^2$
\end{theorem}

\begin{example}
  Determinar el centro y el radio de la superficie esférica de ecuación:
  
  $x^2 + y^2 + z^2 - 6 x - 6 y - 8 z + 9 = 0$.
  
  $A = - 2 x_0 = - 6 \Rightarrow x_0 = 3$
  
  $B = - 2 y_0 = - 6 \Rightarrow y_0 = 3$
  
  $C = - 2 z_0 = - 8 \Rightarrow z_0 = 4$
  
  El centro es el punto $C ( 3, 3, 4 )$.
  
  $D = x_0^2 + y_0^2 + z_0^2 - \rho^2 = 9 \Rightarrow \rho^2 = 3^2 + 3^2 + 4^2
  - 9 = 25 \Rightarrow \rho = 5$
  
  El radio es 5.
\end{example}

\begin{theorem}
  [Posición relativa de plano y esfera]Dados un plano $\pi$ y una
  esfera de centro $C$ y radio $\rho$, se tiene que:
  \begin{enumeratealpha}
    \item si $d ( C, \pi ) > \rho$, el plano y la esfera no tienen puntos en
    común, y se dice que el plano es exterior a la esfera;
    
    \item si $d ( C, \pi ) = \rho$, el plano y la esfera tienen un único punto
    en común, y se dice que el plano es tangente a la esfera;
    
    \item si $d ( C, \pi ) < \rho$, la intersección del plano y la esfera es
    una circunferencia, y se dice que el plano es secante a la esfera.
  \end{enumeratealpha}
\end{theorem}

{}



\begin{theorem}
  [Plano tangente a la esfera]El plano tangente a la esfera de centro
  $C ( x_0, y_0, z_0 )$ y radio $\rho$ en el punto $P ( x_1, y_1, z_1 )$ viene
  dado por:
  \begin{center}
    $\pi : ( x_0 - x_1 ) ( x - x_1 ) + ( y_0 - y_1 ) ( y - y_1 ) + ( z_0 - z_1
    ) ( z - z_1 ) = 0$
  \end{center}
\end{theorem}

\begin{example}
  Hallar la ecuación del plano tangente a la esfera $x^2 + y^2 + z^2 - 6 x - 6
  y - 8 z + 9 = 0$ en su punto del eje OX.
  
  Su punto del eje OX es $P ( x_1, 0, 0 )$, donde $x_1^2 + 0^2 + 0^2 - 6 x_1 -
  6 \cdot 0 - 8 \cdot 0 + 9 = 0 \Leftrightarrow x_1 = 3$ (comprobamos que la
  esfera toca al eje OX en un único punto): $P ( 3, 0, 0 )$.
  
  El centro de la esfera (calculado en un ejemplo anterior) es: $C ( 3, 3, 4
  )$.
  
  La ecuación del plano tangente en $P$ es:
  
  $\pi : ( 3 - 3 ) ( x - 3 ) + ( 3 - 0 ) ( y - 0 ) + ( 4 - 0 ) ( z - 0 ) = 0
  \Leftrightarrow 3 y + 4 z = 0$
  
  Como se ve, el plano tangente contiene al eje OX, porque dicho eje es
  tangente a la esfera en $P$.
\end{example}

\begin{theorem}
  [Intersección de plano y esfera]La intersección de un plano $\pi$
  secante a una esfera de centro $C$ y radio $\rho$ es una circunferencia
  contenida en el plano $\pi$, cuyo centro es la proyección ortogonal de $C$
  sobre $\pi$, y cuyo radio viene dado por $\sqrt{\rho^2 - d^2 ( C, \pi )}$.
\end{theorem}

\begin{example}
  Halla el centro y el radio de la circunferencia intersección del plano $\pi
  : 2 x + y + 2 x + 8 = 0$ con la esfera $x^2 + y^2 + z^2 + 2 x - 4 y + 8 z -
  4 = 0$.
  
  Calculamos en primer lugar el centro y el radio de la esfera dada:
  
  $C \left( \dfrac{2}{- 2}, \dfrac{- 4}{- 2}, \dfrac{8}{- 2} \right) = C ( - 1,
  2, - 4 )$; $\rho = \sqrt{( - 1 )^2 + 2^2 + ( - 4 )^2 - ( - 4 )} = \sqrt{25}
  = 5$
  
  La intersección de la esfera con el plano $\pi$ es una circunferencia cuyo
  centro es la proyección ortogonal de $C$ sobre $\pi$. Para calcular la
  proyección ortogonal utilizaremos la recta perpendicular a $\pi$ (vector
  director de la recta igual a vector normal del plano) que pasa por $C$:
  
  $r : \left\{\begin{array}{l}
    x = - 1 + 2 \lambda\\
    y = 2 + \lambda\\
    z = - 4 + 2 \lambda
  \end{array}\right.$
  
  La proyección ortogonal de $C$ sobre $\pi$ es la intersección de $r$ con
  $\pi$:
  
  $C_0 = r \cap \pi \equiv \left\{\begin{array}{l}
    x = - 1 + 2 \lambda\\
    y = 2 + \lambda\\
    z = - 4 + 2 \lambda\\
    2 x + y + 2 z + 8 = 0
  \end{array}\right. \Rightarrow 2 ( - 1 + 2 \lambda ) + 2 + \lambda + 2 ( - 4
  + 2 \lambda ) + 8 = 0 \Leftrightarrow \lambda = 1 \Rightarrow C_0 ( 1, 3, -
  2 )$
  
  El radio de la circunferencia intersección forma un triángulo rectángulo con
  el radio de la esfera y la distancia entre los dos centros:
  
  $\rho_0 = \sqrt{\rho^2 - d^2 ( C, C_0 )} = \sqrt{25 - ( ( 1 + 1 )^2 + ( 3 -
  2 )^2 + ( - 2 + 4 )^2 )} = \sqrt{16} = 4$
\end{example}

{}



\begin{theorem}
  [Posición relativa de recta y esfera]Dadas una recta $r$ y una
  esfera de centro $C$ y radio $\rho$, se tiene que:
  \begin{enumeratealpha}
    \item si $d ( C, r ) > \rho$, la recta y la esfera no tienen puntos en
    común, y se dice que la recta es exterior a la esfera;
    
    \item si $d ( C, r ) = \rho$, la recta y la esfera tienen un único punto
    en común, y se dice que la recta es tangente a la esfera;
    
    \item si $d ( C, r ) < \rho$, la recta y la esfera tienen dos puntos en
    común, y se dice que la recta es secante a la esfera.
  \end{enumeratealpha}
\end{theorem}

\begin{theorem}
  [Posición relativa de dos esferas]Dadas dos esferas de centros $C_1$
  y $C_2$ y radios $\rho_1$ y $\rho_2$, respectivamente, se tiene que:
  \begin{enumeratealpha}
    \item si $d ( C_1, C_2 ) > \rho_1 + \rho_2$, las esferas no tienen puntos
    en común y los puntos de cada una están todos en el exterior de la otra, y
    se dice que son exteriores;
    
    \item si $d ( C_1, C_2 ) = \rho_1 + \rho_2$, las esferas tienen un punto
    en común, estando los restantes puntos de cada una en la región exterior
    de la otra, y se dice que son tangentes exteriores;
    
    \item si $| \rho_1 - \rho_2 | < d ( C_1, C_2 ) < \rho_1 + \rho_2$, la
    intersección de las esferas es una circunferencia, y se dice que las
    esferas son secantes.
    
    \item si $d ( C_1, C_2 ) = | \rho_1 - \rho_2 |$, las esferas tienen un
    punto en común, y todos los demás puntos de una de ellas están en el
    interior de la otra, y se dice que son tangentes interiores.
    
    \item si $d ( C_1, C_2 ) < | \rho_1 - \rho_2 |$, las esferas no tienen
    puntos en común, y todos los puntos de una están en el interior de la
    otra, y se dice que son interiores.
  \end{enumeratealpha}
\end{theorem}



\chapter{Conjuntos y funciones}

\newpage\section{Concepto de conjunto}

\begin{definition}
  [Conjunto] Un \textbf{conjunto} es una colección de objetos bien definidos, distintiguibles y desordenados. A los objetos de un conjunto se les llama \textbf{elementos} del conjunto. Un conjunto queda determinado por sus elementos. Dos conjuntos son iguales cuando tienen los mismos elementos.
\end{definition}

\begin{definition}
  [Pertenencia] La relación entre un elemento y un conjunto al que pertenece se llama \textbf{pertenencia}. Se representa simbólicamente por $\in$. La relación $x \in A$ se expresa diciendo que $x$ pertenece a $A$ o que $x$ es un elemento de $A$.
\end{definition}

\begin{remark}
  Que $x$ no es un elemento de $A$, puede representarse simbólicamente así: $x \notin A$.
\end{remark}

\begin{remark}
  Las definiciones anteriores no son definiciones matemáticas. Son más bien descripciones de unas nociones que se toman del sentido común, y que son las bases con las que vamos a construir otros conceptos matemáticos.
\end{remark}

\begin{definition}
  Un conjunto se puede definir de dos maneras:
  \begin{enumeratealpha}
    \item Por \textbf{extensión}, enumerando los elementos que lo forman. Simbólicamente se escriben los elementos del conjunto entre llaves y separados por comas. Según la definición de conjunto, el orden en que se escriban los elementos es irrelevante, y todos los elementos deben ser distinguibles (no puede haber, por tanto, dos elementos representados por el mismo símbolo).
     \item Por \textbf{comprensión}, indicando una propiedad que posean todos los elementos del conjunto, y solamente ellos. Se expresa así:
\[\{x\mid x\text{ tiene la propiedad P}\}\]
Cuando se conoce previamente la pertenencia de todos los elementos a un conjunto definido previamente (llamado \emph{universo} o \emph{ambiente}) la definición por comprensión puede expresarse así:
\[\{x \in U \mid  x \text{ tiene la propiedad P}\}\]
  \end{enumeratealpha}
\end{definition}

\begin{remark}
  En lugar de $\mid $ se puede también utilizar $:$.
\end{remark}

\begin{example}
   Definición por extensión: la expresión
   \[\{1,2,3\}\]
   representa a un conjunto cuyos elementos son los números enteros $1$, $2$ y $3$. El mismo conjunto lo podíamos haber escrito así: $\{3,2,1\}$. Es decir,
   \[\{1,2,3\} = \{1,3,2\} = \{2,1,3\} = \{2,3,1\} = \{3,1,2\} = \{3,2,1\}\]

   Definición por comprensión: la expresión
   \[\{x\mid x \text{ es un número primo}\}\]
   representa al conjunto de todos los números primos.
\end{example}

\begin{remark}
  Para dar nombre a un conjunto se suele utilizar una expresión de igualdad entre el nombre y la expresión que define el conjunto. Así,
  \[A = \{n \in \mathbb{N} \mid   \exists k \in \mathbb{N}, \; n = 2k\}\]
  se lee ``A es/A se define como/Sea A el conjunto de los números naturales que son el doble de algún número natural'' (es decir, es el conjunto de los números pares).

  En contextos más técnicos o formales se distingue entre las igualdades y este tipo de expresiones que dan nombre a un objeto (es decir, que definen el significado de un símbolo nuevo, que es el nombre). Para ello, en lugar del signo $=$, se utiliza $:=$, o bien $\stackrel{def}{=}$, o bien $\stackrel{\nabla}{=}$. Nosotros no seremos tan formales.
\end{remark}

\begin{remark}
  Algunos conjuntos especialmente importantes tienen asignados nombres convenidos:
  \begin{itemize}
  \item El conjunto de los números naturales: $\mathbb{N}$.
  \item El conjunto de los números enteros: $\mathbb{Z}$.
  \item El conjunto de los números racionales: $\mathbb{Q}$.
  \item El conjunto de los números reales: $\mathbb{R}$.
  \item El conjunto de los números complejos: $\mathbb{C}$.
  \item El conjunto de los números racionales positivos: $\mathbb{Q}^+ = \{q \in \mathbb{Q} \mid  q > 0\}$.
  \item El conjunto de los números reales positivos: $\mathbb{R}^+ = \{x \in \mathbb{R} \mid  x > 0\}$.
  \item El conjunto de los números racionales no nulos: $\mathbb{Q}^* = \{q \in \mathbb{Q} \mid  q \neq 0\}$.
  \item El conjunto de los números reales no nulos: $\mathbb{R}^* = \{x \in \mathbb{R} \mid  x \neq 0\}$.
  \end{itemize}
\end{remark}

\begin{remark}
  La letra que se utiliza para representar a los elementos en la expresión que define un conjunto por comprensión ($x$, $n$, $\hdots$), puede ser cualquier letra. Las definiciones
\[\{x \in \mathbb{R} \mid  x \neq 0\},\hspace{1cm}\{y \in \mathbb{R} \mid  y \neq 0\}\]
son idénticas.

  Sin embargo, es frecuente utilizar las letras $x$, $y$, $z$, $r$, $s$, $t$, para representar números reales, y las letras $n$, $m$, $p$, $k$, para representar números enteros.
\end{remark}

\begin{remark}
  Cuando los elementos de un conjunto tienen una estructura fija, representable mediante alguna expresión simbólica con algunos parámetros variables, puede utilizarse dicha expresión en lugar de una única letra para representar a los elementos, simplificando así la definición. Por ejemplo, el conjunto (que es el conjunto de las fracciones positivas propias),
  \[\left\{q \in \mathbb{Q} \mid  q=\dfrac{n}{m}, n \in \mathbb{N}, m \in \mathbb{N}, n < m\right\}\]
podría definirse así:
  \[\left\{\dfrac{n}{m} \in \mathbb{Q}^+ \mid  |n| < |m|\right\}\]
\end{remark}

\begin{remark}
  Cuando un conjunto tiene muchos elementos, o infinitos, a veces se utiliza la definición por extensión incluyendo puntos suspensivos para representar a los elementos que no se escriben expresamente, pero cuya presencia se puede inducir a partir de los elementos escritos expresamente. Algunos ejemplos:
  \begin{itemize}
  \item El conjunto de los números naturales: $\mathbb{N} = \{1,2,3,\hdots\}$.
  \item El conjunto de los números enteros: $\mathbb{Z} = \{\hdots,-2,-1,0,1,2,\hdots\}$.
  \item El conjunto de los números naturales impares menores que 100: $\{1,3,5,7,\hdots,99\}$.
  \item El conjunto de las potencias de exponente natural de $\dfrac{1}{2}$: $\left\{\dfrac{1}{2},\dfrac{1}{4},\dfrac{1}{8},\hdots\right\}$.
  \item $\left\{\dfrac{1}{2},\dfrac{2}{5},\dfrac{3}{10},\hdots,\dfrac{n}{n^2+1},\hdots\right\}$.
  \end{itemize}
  Obsérvese cómo en el último ejemplo se ha incluido una expresión que permite calcular todos los elementos del conjunto, porque no resultaba fácil inducir cuáles debían ser estos. Podíamos haber definido más fácilmente el conjunto así: $\{n/(n^2+1) \mid  n \in \mathbb{N}\}$.
\end{remark}

\begin{remark}
  En las expresiones simbólicas se utilizan a veces símbolos especiales ($\forall,\exists,\wedge,\vee,\not,\Rightarrow,\iff$) para expresar relaciones lógicas. Algunos ejemplos de su uso para definir conjuntos son los siguientes:
  \begin{itemize}
  \item La expresión $\forall x P$ significa ``para todo $x$ se cumple $P$'' (es decir, la afirmación $P$ es verdadera al sustituir $x$ por cualquier valor). Ejemplo: $\{x \in \mathbb{R} \mid  \forall y \in \mathbb{R}, x+y=y\} = \{0\}$.
  \item La expresión $\exists x P$ significa ``existe algún $x$ que verifica $P$'' (en el sentido de que existe al menos uno, pero puede existir más de uno). Ejemplo: $\{n \in \mathbb{Z} \mid  \exists k \in \mathbb{Z}, n=k^2\}$.
  \item La expresión $P \wedge Q$ significa ``se verifica $P$ y se verifica $Q$'' (conjunción lógica). Ejemplo: $(1,5) = \{x \in \mathbb{R} \mid  (x>1) \wedge (x<5)\}$.
  \item La expresión $P \vee Q$ sigifica ``se verifica $P$ o se verifica $Q$ o se verifican ambas''. Ejemplo: $\left\{\dfrac{n}{m} \in \mathbb{Q} \mid  (n = 1) \vee (m=1)\right\}$.
  \item La expresión $\not P$ significa ``no se verifica $P$''. Ejemplo: $\{x \in \mathbb{R} \mid  \not (1<x<5)\}$.
  \item La expresión $P \Rightarrow Q$ significa ``$P$ implica $Q$'', es decir, ``si se verifica $P$, entonces también se verifica $Q$''. Ejemplo: $\{f \in \mathcal{F} \mid  \forall x,y \in \dom f, (x<y) \Rightarrow (f(x)<f(y))\}$.
  \item La expresión $P \iff Q$ significa ``$P$ si y solo si $Q$'', es decir, ``si se verifica $P$, entonces también se verifica $Q$, y si se verifica $Q$, entonces también se verifica $P$''. Ejemplo: $\{f \in \mathbb{F} \mid  \forall x \in \dom f, f(x)=0 \iff x=0\}$.
  \end{itemize}
  Estos símbolos deben utilizarse solo en expresiones simbólicas. Nunca deben utilizarse dentro de un texto normal como si fueran abreviaturas. Sería incorrecto, por ejemplo, escribir: ``si $A$ es un conjunto acotado de números reales, entonces $\exists$ algún número real $m$ tal que si $x$ pertenece a $A$, $\Rightarrow$ $x<m$''.
\end{remark}

\begin{remark}
  En realidad, las dos maneras de definir un conjunto mediante una propiedad que hemos presentado no son equivalentes. No todas las expresiones del primer tipo definen conjuntos. Así, por ejemplo, la expresión $\{x\mid x \notin x\}$ no define un conjunto (dicha expresión es la famosa paradoja de Russell). Esta expresión es la que llevó a modificar la manera de expresar la definición de un conjunto, introduciendo el concepto de \emph{universo} y la notación llamada de Zermelo. Sin embargo, nosotros usaremos muchas veces la primera forma de expresar para simplificar.
\end{remark}

\begin{definition}
  [Conjunto vacío] Es el conjunto que no tiene ningún elemento. Se representa por $\emptyset$ o por $\{\}$.
\end{definition}

\newpage\section{Subconjuntos}

\begin{definition}
  [Subconjunto] Un conjunto $B$ es subconjunto de un conjunto $A$ si todos los elementos de $B$ también pertenecen a $A$. Se representa por $A \subset B$. También se expresa diciendo que $B$ está contenido en $A$, o que $A$ incluye a $B$.
\end{definition}

\begin{remark}
  La inclusión se podría definir formalmente así:
  \[B \subset A \equiv x \in B \Rightarrow x \in A\]
\end{remark}

\begin{example}
  El conjunto $B=\{1,3,5\}$ es un subconjunto de $A=\{1,3,5,7,9\}$. Podríamos escribir: $B \subset A$.
\end{example}

\begin{definition}
  [Subconjuntos propios] Todo conjunto tiene al menos dos subconjuntos, que son él mismo y el conjunto vacío, a los que se llama \emph{subconjuntos triviales}. Todos los demás subconjuntos de un conjunto se llaman \emph{subconjuntos propios}.
\end{definition}

\begin{remark}
  Obsérvese la diferencia entre inclusión ($\subset$) y pertenencia ($\in$). La inclusión es una relación entre conjuntos. La pertenencia es una relación entre un elemento y un conjunto. Por ejemplo, $1$ pertenece a $\{1,2,3\}$, mientras que $\{1\}$ está incluido en $\{1,2,3\}$. Sería incorrecto decir que $1$ está incluido en $\{1,2,3\}$ y también que $\{1\}$ pertenece a $\{1,2,3\}$.

  Nada impide que los elementos de un conjunto sean a su vez conjuntos: se trataría de un conjunto de conjuntos. Sea, por ejemplo,
  \[A=\{\{1\},\{2\},\{1,2\}\}\]
  Ilustraremos la diferencia entre inclusión y pertenencia con algunas afirmaciones correctas e incorrectas:
  \begin{itemize}
  \item Es correcto que $\{1\} \in A$.
  \item Es correcto que $\{\{1\},\{2\}\} \subset A$.
  \item Es incorrecto que $\{1\} \subset A$.
  \item Es correcto que $\{\{1\}\} \subset A$.
  \item Es incorrecto que $\emptyset \in A$.
  \item Es correcto que $\emptyset \subset A$.
  \end{itemize}

  Otros ejemplos:
  \begin{itemize}
  \item Es incorrecto que $\emptyset \in \emptyset$.
  \item Es correcto que $\emptyset \subset \emptyset$.
  \item Es correcto que $\emptyset \in \{\emptyset\}$.
  \item Es correcto que $\emptyset \subset \{\emptyset\}$.
  \end{itemize}
\end{remark}

\begin{definition}
  [Conjunto potencia] Dado un conjunto $A$, se llama conjunto potencia de $A$, o conjunto de partes de $A$, y se representa por $\mathcal{P}(A)$, al conjunto formado por todos los subconjuntos de $A$.
\end{definition}

\begin{remark}
  Si un conjunto $A$ tiene $n$ elementos, entonces su conjunto potencia tiene $2^n$ elementos.
\end{remark}

\begin{example}
  Sea $A=\{1,2,3\}$. El conjunto potencia de $A$ es:
  \[\mathcal{P}(A) = \left\{ \emptyset, \{1\},\{2\},\{3\},\{1,2\},\{1,3\},\{2,3\},\{1,2,3\} \right\}\]
\end{example}

\begin{definition}
  [Cardinal] El número de elementos de un conjunto se llama \emph{cardinal}, y se representa por el símbolo $\#$.
\end{definition}

\begin{definition}
  [Conjuntos finitos e infinitos] Un conjunto es finito si su cardinal es finito, e infinito en caso contrario.
\end{definition}

\begin{remark}
  La definición de cardinal y la definición de conjunto infinito dadas no son ni mucho menos precisas. Dar una definición precisa de estos conceptos resultaría excesivamente largo para este apéndice, por lo que nos conformaremos con estas ``definiciones intuitivas''.
\end{remark}

\newpage\section{Operaciones con conjuntos}

\begin{definition}
  [Unión] Dados dos conjuntos $A$ y $B$ se llama unión de $A$ y $B$, y se representa por $A \cup B$, al conjunto definido por:
  \[A \cup B \equiv \{x \mid  x \in A \vee x \in B\}\]
\end{definition}

\begin{example}
  Sean
  \[A = \{1,3,5,7\}; \; B = \{1,2,3,4,5\}.\]
  Entonces,
  \[A \cup B =\{1,2,3,4,5,7\}\]
\end{example}

\begin{definition}
  [Intersección] Dados dos conjuntos $A$ y $B$, se llama intersección de $A$ y $B$, y se representa por $A \cap B$, al conjunto definido por:
  \[A \cap B \equiv \{x \mid  x \in A \wedge x \in B\}\]
\end{definition}

\begin{example}
  \[\{1,3,5,7\} \cap \{1,2,3,4,5\} = \{1,3,5\}\]
\end{example}

\begin{definition}
  [Conjuntos disjuntos] Dos conjuntos son disjuntos si su intersección es el conjunto vacío.
\end{definition}

\begin{example}
  Los conjuntos $A=\{1,3,5,7,\hdots\}$ y $B=\{2,4,6,8,\hdots\}$ son disjuntos porque $A \cap B =\emptyset$.
\end{example}

\begin{definition}
  [Diferencia] Dados dos conjuntos $A$ y $B$, se llama diferencia de $A$ y $B$, y se representa por $A-B$, al conjunto definido por:
  \[A - B \equiv \{x \mid  x \in A \wedge x \notin B\}\]
\end{definition}

\begin{remark}
  La diferencia $A-B$ puede representarse también mediante $A \setminus B$.
\end{remark}

\begin{example}
  Sean los conjuntos
  \[A = \{n \in \mathbb{N} \mid  \exists k \in \mathbb{N}, n = 2k\}; \hspace{.5cm} B = \{m \in \mathbb{N} \mid  \exists p \in \mathbb{N}, m = 3p\}.\]
  El conjunto $A-B$ sería:
  \[A - B = \{n \in \mathbb{N} \mid  (\exists k \in \mathbb{N}, n = 2k) \wedge (\nexists p \in \mathbb{N}, n = 3p)\}.\]
  El conjunto $A$ es el conjunto de los números naturales pares, y el conjunto $B$ es el de los múltiplos de 3. Así, pues, el conjunto $A-B$ es el conjunto de los números naturales pares que no son múltiplos de 3.
  Por otro lado, el conjunto $B-A$ sería el conjunto de los múltiplos de 3 que no son pares:
  \[B - A = \{n \in \mathbb{N} \mid  \exists k \in \mathbb{N}, (n=3k) \wedge (k \notin A)\}\]
\end{example}

\begin{theorem}
  [Propiedades de las operaciones con conjuntos] Dados tres conjuntos $A$, $B$ y $C$ cualesquiera, se verifican:
  \begin{itemize}
  \item $A \cup B = B \cup A$
  \item $A \cap B = B \cap A$
  \item $(A \cup B) \cup C = A \cup (B \cup C)$
  \item $(A \cap B) \cap C = A \cap (B \cap C)$
  \item $A \cap (B \cup C) = (A \cap B) \cup (A \cap C)$
  \item $A \cup (B \cap C) = (A \cup B) \cap (A \cup C)$
  \item $A \cup A = A$
  \item $A \cap A = A$
  \item $A \cup \emptyset = A$
  \item $A \cap \emptyset = \emptyset$
  \item $A \subset B \iff A = A \cap B \iff B = B \cup A$
  \end{itemize}
\end{theorem}

\begin{remark}
  Introduciendo el concepto de \emph{universo}, conjunto de todos los posibles elementos que se pueden considerar, que se define simbólicamente por $U := \{x \mid  x = x\}$, se puede definir otra operación, que es el \emph{conjunto complementario}. El conjunto complementario de un conjunto $A$, representado por $\overline{A}$, o también por $A^C$, o por $A'$, es el conjunto formado por todo lo que no pertenece a A:
  \[\overline{A} \equiv \{x \mid  x \notin A\}.\]

  El concepto de universo es necesario porque sin él, la definición anterior carece de sentido: no es concebible un conjunto que contenga todo, absolutamente todo, lo que no pertenece a $A$. Supongamos que $A = \{1,2,3\}$, entonces, ¿cuáles son los elementos de $\overline{A}$, según la definición anterior? Lo único que nos dice es cuáles no son sus elementos (los números 1, 2 y 3). Pero si tenemos que interpretar literalmente que cualquier cosa que no sea elemento de $A$ es elemento de $\overline{A}$, entonces la Segunda Guerra Mundial pertenece a $A$, y estos apuntes también. Un conjunto así no es concebible: ni siquiera merece el nombre de conjunto. Por eso, la definición ha de entenderse con referencia a un \emph{universo} del que se toman los elementos, así: $\{x \in U \mid  x \notin A\}$.

  El concepto es controvertido, porque dicho \emph{universo} no es admitido como conjunto (tampoco es concebible el conjunto de todo, sin más). En la práctica, lo que se utiliza es el \emph{complementario de $A$ dentro de $V$}, siendo $V$ un conjunto bien definido que constituye el ``contexto del discurso''.
\end{remark}

\newpage\section{Concepto de función}

\begin{definition}
  [Producto cartesiano] Dados dos conjuntos $A$ y $B$, se llama producto cartesiano $A \times B$ al conjunto de todos los pares ordenados $(a,b)$, donde $a$ es un elemento de $A$ y $b$ es un elemento de $B$. Es decir,
  \[A \times B = \{(a,b) \mid a \in A \wedge b \in B\}\]
\end{definition}

\begin{remark}
  Un par ordenado $(a,b)$ está formado por dos ``objetos'' $a$ y $b$ cualesquiera, de manera que dos pares son iguales cuando están formados por los mismos ``objetos'' y en el mismo orden: $(a,b)=(c,d) \iff (a=c) \wedge (b=d)$.

  A partir de los pares ordenados, se definen inductivamente las \emph{n-tuplas} $(a_1,a_2,\hdots,a_n) := (a_1,(a_2,\hdots,a_n))$.
\end{remark}

\begin{example}
  Sean $A=\{0,1\}$ y $B=\{1,2\}$. Tenemos:
  \[A \times B = \{(0,1),(0,2),(1,1),(1,2)\},\]
  \[B \times A = \{(1,0),(1,1),(2,0),(2,1)\}.\]
\end{example}

\begin{remark}
  También se define $A^2 \equiv A \times A$, y $A^{n+1} \equiv A \times (A^n)$, para todo $n$ natural mayor que 1.
\end{remark}

\begin{definition}
  [Correspondencia] Una correspondencia de un conjunto $A$ sobre otro conjunto $B$ es cualquier subconjunto del producto cartesiano $A \times B$. Al conjunto $A$ se le llama \emph{conjunto inicial} de la correspondencia, y al conjunto $B$ se le llama \emph{conjunto final}. Que $c$ es una correspondencia de $A$ sobre $B$, se expresa simbólicamente así: $c:A\rightarrow B$.

  Dado un par $(a,b)$ de una correspondencia $c$, a $b$ se dice que $b$ es una \emph{imagen} de $a$ en la correspondencia $c$, y que $a$ es una \emph{antiimagen} de $b$ en la correspondencia $c$.
\end{definition}

\begin{remark}
  Esta definición matemática es una formalización del concepto intuitivo que expresamos diciendo ``poner en relación o emparejar los elementos de un conjunto con los de otro''. Como el producto cartesiano es el conjunto de todas las posibles parejas, un subconjunto de dicho producto es un emparejamiento concreto. En principio, cualquier subconjunto del producto cartesiano es una correspondencia, pero normalmente nos interesarán aquellas correspondencias que siguen un criterio para seleccionar las parejas del producto cartesiano, criterio que será siempre algún tipo de relación entre los objetos que forman la pareja. Por ejemplo, consideremos los conjuntos $\mathbb{N}$ y $\mathbb{Q}$, y los siguientes subconjuntos de $\mathbb{N}\times\mathbb{Q}$:
  \[c = \left\{\left(1,\dfrac{1}{2}\right),\left(2,\dfrac{2}{3}\right),\hdots,\left(n,\dfrac{n}{n+1}\right),\hdots\right\}\]
  \[d = \left\{\left(1,3\right),\left(2,\dfrac{1}{10}\right),\left(3,\dfrac{7}{5}\right),\left(4,\dfrac{3}{8}\right),\left(5,1\right)\right\}\]
  \[e = \left\{(1,1),(1,2),(2,2),(1,3),(2,3),(3,3),(1,4),(2,4),(3,4),(4,4),\hdots\right\}\]
  Tanto $c$ como $d$ son correspondencias de $\mathbb{N}$ sobre $\mathbb{Q}$, ya que son subconjuntos de $\mathbb{N}\times\mathbb{Q}$. Sin embargo, rara vez tendremos que vérnoslas con una correspondencia como $d$, ya que los pares seleccionados parecen completamente arbitrarios, mientras que $c$ es una correspondencia que llamaremos \emph{sucesión} y para la que desarrollaremos bastantes herramientas de cálculo.
  La correspondencia $e:\mathbb{N}\rightarrow\mathbb{N}$ contiene todos los pares de números naturales tales que el primer número del par es menor o igal que el segundo. En esta correspondencia cada número natural tiene infinitas imágenes (todos los números naturales mayores o iguales que él), y cada número natural tiene tantas antiimágenes como indica su valor (los números naturales menores o iguales que él).
\end{remark}

\begin{remark}
  Una \emph{relación} $R$ en un conjunto $A$ es una correspondencia de $A$ sobre $A$, es decir, un subconjunto de $A^2$. Cuando el par $(x,y)$ pertenece a la relación $R$, se representa así: $xRy$. Hay dos tipos de relaciones especialmente importantes: las relaciones de equivalencia y las relaciones de orden. Una \emph{relación de equivalencia} es una relación que verifica las siguientes propiedades:
  \begin{itemize}
  \item Reflexiva: $\forall x \in A, x R x$.
  \item Simétrica: $\forall x,y \in A, xRy \Rightarrow yRx$.
  \item Transitiva: $\forall x,y,z \in A, (xRy \wedge yRz) \Rightarrow xRz$.
  \end{itemize}
  Por ejemplo, la igualdad es una relación de equivalencia. Otro ejemplo de relación de equivalencia en $\mathbb{N}$ es la que relaciona aquellos números naturales que al dividirlos entre 5 dan el mismo resto. En esta relación, tendríamos, por ejemplo, $7\,R\,12$, $43\,R\,18$, etc.
  Una \emph{relación de orden} es una relación que verifica las siguientes propiedades:
  \begin{itemize}
  \item Reflexiva.
  \item Antisimétrica: $\forall x,y \in A, (xRy \wedge x \neq y) \Rightarrow \not(yRx)$.
  \item Transitiva.
  \end{itemize}
  Un ejemplo de relación de orden es la inclusión de conjuntos.
\end{remark}

\begin{definition}
  [Correspondencias inyectivas, suprayectivas y biyectivas] Una correspondencia de $A$ sobre $B$ se llama
  \begin{itemize}
  \item inyectiva, si cada elemento de $B$ tiene como máximo una antiimagen;
  \item suprayectiva, si cada elemento de $B$ tiene como mínimo una antiimagen;
  \item biyectiva (o uno-uno), si es inyectiva y suprayectiva (cada elemento de $B$ tiene exactamente una antiimagen).
  \end{itemize}
\end{definition}

\begin{definition}
  [Función] Una función es una correspondencia entre dos conjuntos numéricos tal que cada elemento del conjunto inicial tiene como máximo una imagen. Es decir, $f = \{(a,b)\} \subset A \times B$ es una función si $((a,b) \in f \wedge (a,c) \in f) \Rightarrow b=c$.

  Dado un par $(a,b)$ de una función $a$, al número $b$ se le llama \emph{imagen} de $a$ en $f$ y se representa por $f(a)$.
\end{definition}

\begin{remark}
  Dado que, si $a$ tiene imagen, tiene solo una, la expresión $f(a)$ para un $a$ que tenga imagen está bien definida, y designa siempre un único número.
\end{remark}

\begin{remark}
  Una función es una correspondencia, es decir, un conjunto de pares ordenados. No es necesario que exista ninguna regla que determine qué pares forman parte de la función y cuáles no (a parte de la simple enumeración de los mismos). Por ejemplo,
  \[g = \{(1,1),(2,7),(15,\pi),(-4,0)\}\]
es una función, pero no hay ninguna regla que nos permita construirla. ¿Por qué la imagen de 1 es 1? ¿Por qué la imagen de 15 es $\pi$? No lo sabemos. Es así ``por definición'', pero no podemos expresar una regla general común a los cuatro pares que forman la función.

  El ejemplo anterior es una función, sin duda, pero es una función sin ningún interés. Las funciones interesantes son aquellas en las que existe alguna relación entre los números que forman el par, de modo que, conociendo esa relación, podemos anticipar qué pares formarán parte de la función y cuáles no, o decidir, a la vista de un par concreto, si está o no en la función. En particular, nos resultarán especialmente interesantes las funciones en que esa relación o regla pueda expresarse algebraicamente mediante una ecuación. A dicha ecuación la llamaremos entonces \emph{ecuación de la función}. La ecuación de una función, cuando existe, define casi completamente a la función (más adelante explicaremos por qué decimos ``casi''). Por ejemplo, la función $f:\\mathbb{R}\rightarrow\mathbb{R}$
  \[f = \{(1,0),(2,3),(3,8),(4,15),\hdots\}\]
sí está construida siguiendo una regla. Al no haber escrito la regla, y ni siquiera haber escrito todos los pares de la función, puede resultar difícil decidir qué otros pares forman parte de la función, o si el par $(5,24)$ pertenece a $f$, o cuál ha de ser el valor de $y$ para que el par $(6,y)$ pertenezca a $f$. Si ahora nos dijesen que $f$ es la función que a cada número le asocia su cuadrado menos 1, podríamos decir que $(5,24)$ sí es un par de la función, y que $y$ ha de valer $35$ para que $(6,y)$ pertenezca a $f$. Dicha ``regla'' de construcción puede expresarse mediante una ecuación que relaciona $a$ y $b$ en todos los pares $(a,b)$ de la función:
\[(a,b) \in f \iff b=a^2-1\]

Ya dijimos que si $(a,b)$ es un par de $f$, al número $b$ se le llama imagen de $a$ en $f$ y se representa por $f(a)$. Aprovechando este símbolo, podríamos escribir la ecuación de la función $f$ así:
\[f(a) = a^2-1\]

Si usamos $x$ en lugar de $a$, que es lo habitual, la ecuación anterior tiene la forma de una función de las que nos hemos encontrado a lo largo de toda la E.S.O.: $f(x)=x^2-1$.

También hay funciones (extrañas, la verdad) que se construyen mediante alguna regla, pero tales que dicha regla no puede expresarse algebraicamente (funciones sin ecuación). Por ejemplo, la función $h$ que a cada número real le asocia el número de veces que aparece el $7$ en su expresión decimal, o $\pi$ si dicho número de veces es infinito. Sabríamos calcular la mayoría de las imágenes de esta función:
\[h(7)=1;\;h(9)=0;\;h(77)=2;\;h(7/9)=\pi;\;h(1/7)=\pi;\;\hdots\]
pero no podemos expresar la relación entre $x$ y $h(x)$ mediante una ecuación.
\end{remark}

\begin{remark}
  Como es habitual en Matemáticas, muchas veces representaremos una función mediante un único símbolo (su ``nombre''). Por razones obvias, se usa con mucha frecuencia la letra $f$.

  A veces se leen en textos matemáticos expresiones como ``se considera la función $f(x)=x^2+1$''. Esta expresión es incorrecta. Propiamente hablando, $f(x)=x^2+1$ no es una función, sino una ecuación. Lo que tendríamos que decir para ser precisos es: ``se considera la función cuya ecuación es $f(x)=x^2+1$''. Cuando hablamos de ``la función $f(x)=x^2+1$'' estamos haciendo una especie de ``metonimia'': como ``la ecuación $f(x)=x^2+1$'' define a la función $f$, hablamos de esa ecuación como si fuese una función. Esta impropiedad se admite porque se entiende fácilmente su significado. Lo que tiene menos sentido es decir ``se considera la función $f(x)$'', porque de ninguna manera $f(x)$ define a la función. Como hemos repetido muchas veces, el símbolo $f(x)$ representa a la imagen de $x$ en $f$, es decir, a un número. Por tanto, $f(x)$ no es el nombre de la función. Lo correcto sería decir ``se considera la función $f$''.
\end{remark}

\begin{example}
  ¿Cuáles de las siguientes correspondencias son funciones?
  \begin{itemize}
  \item $\left\{(1,2),(2,-3),(3,4),(4,-1),(1,-5)\right\}$. No es una función porque hay dos pares distintos con el mismo primer elemento: $(1,2)$ y $(1,-5)$.
  \item $\left\{(0,1),(1,1),(2,1)\right\}$. Sí es una función porque no hay dos pares distintos con el mismo primer elemento.
  \item $\left\{(4,8),(4,2),(4,-16)\right\}$. No es función, porque todos los pares tienen el mismo primer elemento.
  \end{itemize}
\end{example}

\begin{example}
  ¿Cuáles de las siguientes correspondencias son funciones?
  \begin{itemize}
  \item $f = \left\{(x,y) \in [-1,2] \times \mathbb{R} \mid  y = 1-x^2\right\}$. Sí es una función, porque para cada valor de $x$ que se tome de $[-1,2]$ existirá un único valor de $y$ en $\mathbb{R}$ que verifique $y=1-x^2$.
  \item $g = \left\{(x,y) \in \mathbb{R}^2 \mid  y = \dfrac{1}{x^2+1}\right\}$. Sí es una función, porque para cualquier valor real de $x$ que se tome existirá un único valor real de $y$ que verifique $y = \dfrac{1}{x^2+1}$.
  \item $h = \left\{(x,y) \in \mathbb{N} \times \mathbb{R} \mid  y^2 = x\right\}$. No es una función, porque para cada valor natural de $x$ que se tome existirán dos valores de $y$ en $\mathbb{R}$ que verifiquen $y^2 = x$, a saber, $y = \sqrt{x}$ e $y = -\sqrt{x}$. Por ejemplo, $(4,2)$ es un par de $h$, ya que $2^2 = 4$, pero $(4,-2)$ también es un par de $h$, ya que $(-2)^2 = 4$. Así que $4$ tiene dos imágenes.
  \item $h_2 = \left\{(x,y) \in \mathbb{N} \times \mathbb{R}^+ \mid  y^2 = x\right\}$. Sí es una función, ya que para cada valor de $x$ que se considere existirá un único valor de $y$ en $\mathbb{R}^+$ que verifique $y^2 = x$, a saber, su raíz cuadrada positiva.
  \end{itemize}
\end{example}

\begin{example}
  Dada la función, $f:\mathbb{R}\rightarrow\mathbb{R}$ definida por $f(x)=\dfrac{4x^2-x}{3x-4}$, para cada una de las expresiones siguientes, escribir su valor, o una expresión equivalente:
  \begin{itemize}
  \item $f(2) = \dfrac{4\cdot 2^2-2}{3\cdot 2-4} = 7$.
  \item $f(0) = \dfrac{4\cdot 0^2 - 0}{3\cdot 0-4} = 0$.
  \item $f(x+1) = \dfrac{4(x+1)^2-(x+1)}{3(x+1)-4}$.
  \item ${x \mid  f(x)=7}$ (es decir, el conjunto de antiimágenes de 7):
    \[f(x) = 7 \iff \dfrac{4x^2-x}{3x-4}=7 \iff 2x^2-11x+14=0 \iff x \in \left\{2,\dfrac{7}{2}\right\}\]
  \end{itemize}
\end{example}

\begin{remark}
  Cuando una función se define mediante una ecuación que relacione el valor de una antiimagen con el de su imagen, tendremos que utilizar algún símbolo que represente al valor de la antiimagen. Normalmente utilizaremos una letra. Y la más frecuente es la $x$. A dicho símbolo, y también, por extensión, al conjunto de valores que toma, se le llama \emph{variable independiente} de la función. En una función de ecuación $f(x)=e^x$, diremos que $x$ es la variable independiente. Por supuesto que la elección de la letra es indiferente: la función definida por $f(x)=e^x$ es la misma que la definida por $f(t)=e^t$.

  A veces, en lugar de utilizar el símbolo $f(x)$ para representar a la imagen de $x$ en $f$, utilizaremos una única letra (frecuentemente, la $y$). A dicha letra, y, por extensión, al conjunto de valores que toma, se le llama \emph{variable dependiente} de la función. Así, la ecuación de la función anterior podría expresarse así: $y=e^x$.

  El sentido de estos nombres es claro. En principio, puedo darle a $x$ el valor que quiera (por eso esta variable es calificada de independiente). Pero, una vez elegido un valor de $x$, el valor de $y$ queda determinado: $y$ depende de $x$.

  Expresar una función mediante una ecuación de este estilo, $y=e^x$ tiene algunas ventajas y muchas desventajas. La manipulación algebraica resulta más simple. La interpretación geométrica es más inmediata. Sin embargo, en ese tipo de expresión no aparece el nombre de la función. Tampoco queda claramente expresado cuál es la variable independiente y cuál es la variable dependiente (sobre todo en el caso de que la ecuación fuera implícita, es decir, sin tener despejada la variable independiente, como en $x^2y=1$, o cuando aparecen más de dos letras). Por estas razones, preferiremos, en general, utilizar el símbolo $f(x)$ para representar a la variable independiente.

  Cuando decimos que ``$y$ varía en función de $x$, o es función de $x$'', matemáticamente hay que entenderlo en el sentido de que hay una función cuya variable independiente es $x$ y cuya variable dependiente es $y$. Estas expresiones se usan en contextos en que tanto $x$ como $y$ tienen significados dados con independencia de la función que las relaciona. Por ejemplo, en Física se puede decir que la energía cinética es función de la velocidad, significa que existe una función que relaciona los valores de ambas magnitudes en un móvil dado: $E_C(v)=\dfrac{1}{2}mv^2$.
\end{remark}

\newpage\section{Dominio de una función}

\begin{definition}
  [Dominio] Se llama dominio (o dominio de definición) de una función $f:A\rightarrow B$ al conjunto de todos los elementos de $A$ que tienen alguna imagen en $f$. Se representa por $\dom f$. Formalmente:
  \[\dom f = \{a \in A \mid  \exists b \in B, (a,b) \in f\}\]
\end{definition}

\begin{remark}
  El dominio de una función forma parte de su definición. Una función es un subconjunto del producto cartesiano de dos conjuntos. Al seleccionar los pares que formarán parte de la función ya estamos estableciendo el dominio.

  Imaginemos que nos dan la ecuación de una función, $f(x)=\dfrac{1}{x}$, por ejemplo. ¿Somos capaces de construir la función con esta información? La respuesta es no. Con esa ecuación podemos calcular la imagen de cualquier número que tenga imagen. El problema es cómo saber qué números tienen imagen y cuáles no. Los números que tienen imagen son los que forman el dominio de $f$. Si junto a la ecuación de $f$ nos dijeran su dominio, $\dom f = \mathbb{N}$, por ejemplo, entonces ya sí podríamos escribir todos los pares que quisiéramos de la función:
  \[f = \{(1,1),(2,1/2),(3,1/3),\hdots\}\]

  Sin embargo, es muy frecuente que se definan funciones sin especificar su dominio apoyándose en un convenio según el cual se ha de tomar como dominio de una función al conjunto de todos los números para los cuales la ecuación de la función tenga sentido. Según este convenio, si nos dan la función $g(x)=\dfrac{1}{x}$, sin especificar su dominio, deberíamos asumir que el dominio es $\mathbb{R}-\{0\}$, ya que la expresión $\dfrac{1}{x}$ está definida para cualquier valor real de $x$ excepto para $x=0$.

  Cuando se nos pide ``hallar el dominio'' de una función, lo que se nos está pidiendo es que apliquemos este convenio, examinando para qué valores de $x$ están definidas las expresiones que aparecen en la ecuación de la función.

  En todo caso, se debe suponer un ``contexto'' (un conjunto numérico dentro del cual se presupone al dominio), ya que una expresión puede tener un significado demasiado amplio. Por ejemplo, el dominio de $f(x)=x^{-1}$, podría ser el conjunto $\mathbb{R}-\{0\}$ (si suponemos que $x$ representa un número real), pero también podría ser el conjunto de todas las matrices invertibles (si suponemos que $x$ representa a una matriz), o $\mathbb{C}-\{0\}$ (suponiendo que $x$ representa un número complejo). Habitualmente, no es necesario especificar qué tipo de objeto matemático representa $x$, porque resulta evidente, pero a veces se aclara diciendo, por ejemplo, que $f$ es una función real de variable real definida por $f(x)=x^{-1}$.
\end{remark}

\begin{example}
  Hallar los dominios de las siguientes funciones reales de variable real:
  \begin{itemize}
  \item $f(x)=\dfrac{x}{x^2-x}$.
    El dominio de $f$ es
    \[\dom f = \mathbb{R}-\{0,1\}\]
    La explicación es la siguiente. La expresión $x^2-x$ está definida para cualquier valor real de $x$ (así ocurre con cualquier expresión polinómica, ya que sumas y productos están definidos para todos los números reales). Por otro lado, el cociente está definido para cualquier numerador y para cualquier denominador distinto de cero. En este caso el denominador es $x^2-x$. Como $x^2-x=0 \iff x \in \{0,1\}$, esos son los únicos dos valores reales para los que no está definida la función.
  \item $f(x) = \sqrt{1-x^2}$.
    El dominio de $f$ es
    \[\dom f =[-1,1]\]
    El radicando $1-x^2$ es polinómico, luego está definido para todo $x$ real. La raíz está definida siempre que el radicando sea positivo o nulo. Así pues el dominio de $f$ es el conjunto
    \[\dom f = \{x \in \mathbb{R} \mid  1-x^2 \geq 0\} = [-1,1].\]
  \item $f(x) = \dfrac{x}{\ln x}$.
    El dominio de $f$ es
    \[\dom f = (0,1) \cup (1,\infty).\]
    El logaritmo neperiano está definido siempre que su argumento sea positivo, en este caso, cuando $x>0$. Sin embargo, el cociente estará definido cuando lo estén su numerador y su denominador y esté último no sea nulo. Es obvio que el numerador está definido siempre, y ya hemos visto que el denominador está definido en $(0,\infty)$. ¿Hay algún valor de $x$ en que el denominador sea nulo? Sí: $\ln x = 0 \iff x = 1$. Por tanto, hay que excluir ese valor del dominio.
  \item $f(x) = \sqrt{-2 +|x|}$
    El dominio de $f$ viene dado por
    \[\dom f = \{x \in \mathbb{R} \mid  -2 + |x| \geq 0\}\]
    Tenemos que
    \[-2 + |x| \geq 0 \iff |x| \geq 2 \iff (x \geq 2) \vee (x \leq -2) \iff x \in (-\infty,-2] \cup [2,\infty)\]
    Por tanto,
    \[\dom f = (-\infty,-2] \cup [2,\infty)\]
  \end{itemize}
\end{example}

\begin{definition}
  [Recorrido] Se llama recorrido, rango o codominio de una función $f:A \rightarrow B$ al conjunto de todos los elementos de $B$ que son imagen en $f$ de algún elemento de $A$. Se representa por $\text{Rg}(f)$ o $Im(f)$. Formalmente:
  \[Im(f) = \{y \in B \mid  \exists x \in A, (x,y) \in f\}\]
\end{definition}

\begin{remark}
  En general, se llama \emph{imagen} de un subconjunto de $A$ en una función $f:A \rightarrow B$, y se representa por $f(A)$, al conjunto $\{y \in B \mid \exists x \in A, (x,y) \in f\}$. De modo, que podría definirse $Im(f) = f(\dom f)$.
\end{remark}

\begin{remark}
  Las funciones reales de variable real son subconjuntos de $\mathbb{R}^2$. Dicho conjunto (conjunto de pares ordenados de números reales) se puede conceptualizar como el conjunto de puntos del plano. Ya sabemos cómo: en cada par $(x,y)$, el primer número representa la coordenada horizontal del punto, y el segundo número representa su coordenada vertical (las coordenadas horizontal y vertical de un punto son las proyecciones sobre los ejes horizontal y vertical, respectivamente, del segmento que une el punto con el origen de coordenadas). Por tanto, una función real de variable real se puede interpretar como un conjunto de puntos del plano. A ese conjunto de puntos del plano, que ``representa gráficamente'' a la función se le llama \emph{gráfica de la función}.

En una función no puede haber dos pares distintos con el mismo primer elemento, $(x,y)$, $(x,z)$, siendo $y \neq z$. Gráficamente, esta característica de las funciones significa que en su gráfica no puede haber dos puntos con la misma coordenada horizontal y distinta coordenada vertical. Dicho de otra forma: una recta vertical solo puede cortar a la gráfica de una función una vez como máximo.
\end{remark}

\begin{example}
  Se consideran las funciones reales de variable real definidas por
  \[f(x) = \dfrac{x^2+1}{x+1}; \hspace{1cm} g(x) = e^{x^2-1}\]

  ¿Pasa la gráfica de $f$ por el punto $(1,1)$? Sí, porque $f(1) = \dfrac{1^2+1}{1+1} = 1$, luego $(1,1) \in f$.
 
  ¿Pasa la gráfica de $f$ por el origen? No, porque $f(0) = 1$, luego $(0,1) \in f$, luego $(0,1) \notin f$ (recuérdese que no puede haber dos pares distintos con el mismo primer elemento).

  ¿Pasa la gráfica de $g$ por el origen? No, porque $g(0) =e^{0^2-1} = e^{-1} = 1/e$, luego $(0,1/e) \in g$, luego $(0,0) \notin g$.

  ¿En qué punto corta el eje vertical a la gráfica de $g$? En el punto $(0,1/e)$. Los puntos del eje vertical tienen todos coordenada horizontal $0$ (la ecuación de dicho eje es $x=0$). Como $g(0)=1/e$, $(0,1) \in g$, luego $(0,1/e)$ es un punto de $g$, y está en el eje vertical, luego ese es el punto de corte.

  ¿En qué punto corta la recta vertical $x=1$ a la gráfica de $f$? En el punto $(1,f(1))$, es decir, el punto $(1,1)$.

  ¿En qué punto corta la recta vertical $x=-1$ a la gráfica de $f$? En ninguno, ya que no hay en $f$ ningún para cuyo primer elemento sea $-1$, puesto que $-1$ no está en el dominio de $f$. Obsérvese que para $x=-1$ el denominador de $f(x)$ resulta nulo.

  ¿Se cortan en algún punto las gráficas de $f$ y $g$? Siempre que para un determinado valor de $x$, las imágenes respectivas tengan los mismos valores, es decir, cuando
  \[f(x) = g(x) \iff \dfrac{x^2+1}{x+1} = e^{x^2-1}\]
  No es fácil resolver la ecuación anterior, pero según hemos visto anteriormente, $f(1) = 1$ y es fácil ver que $g(1) = 1$, luego $f(1) = g(1)$. Ambas gráficas pasan por el punto $(1,1)$, luego, por lo menos, se cortan en ese punto. Se puede demostrar que ese es el único punto de corte.

  ¿En qué punto o puntos corta la recta horizontal $y=1$ a la gráfica de $f$? Los puntos de la recta horizontal $y=2$ son todos aquellos cuya coordenada vertical es $1$. Los puntos de corte de $y=1$ con la gráfica de $f$ serán, pues, los puntos de dicha gráfica de la forma $(x,1)$. Para que estos puntos pertenezcan a la gráfica de $f$, ha de cumplirse que $f(x)=1$:
  \[f(x)=1 \iff \dfrac{x^2+1}{x+1}=1 \iff x^2-x=0 \iff x \in \{0,1\}.\]
  Por lo tanto, hay dos puntos de corte de la gráfica de $f$ con la recta $y=2$: $(0,f(0))$ y $(1,f(1))$, que son $(0,1)$ y $(1,1)$.
\end{example}

\begin{remark}
  Hay curvas que son gráficas de funciones y otras que no son gráficas de ninguna función. Así, por ejemplo, una circunferencia no es la gráfica de una función, porque una recta vertical puede cortarla dos veces. Por ejemplo, la circunferencia de centro $(0,0)$ y radio 1, pasa por los puntos $(0,1)$ y $(0,-1)$, lo que no podría hacer la gráfica de una función. Sin embargo, una parábola con vértice en $(0,0)$, cuyo eje sea el eje vertical, y con el foco en $(0,1/2)$, sí es la gráfica de una función, en concreto de $f(x)=x^2$.

  Hay curvas que se pueden representar mediante ecuaciones, y curvas que no se pueden representar mediante ecuaciones.

  Dentro del primer tipo están todas las gráficas de funciones definidas mediante una ecuación, lógicamente. Pero también hay curvas que no son gráficas de funciones y que sí se pueden representar mediante una ecuación. Cuando decimos que una ecuación representa una curva (o que una curva es la representación gráfica de una ecuación) lo que queremos decir es que el conjunto de puntos de la curva se corresponde biunívocamente con el conjunto de soluciones de la ecuación. Por ejemplo, la circunferencia de centro $(0,0)$ y radio 1, puede representarse algebraicamente por la ecuación:
  \[x^2+y^2 = 1\]
  Esto significa que dicha circunferencia es el conjunto de puntos cuyas coordenadas horizontal ($x$) y vertical ($y$) verifican la ecuación. Así, $(0,1)$, $(-1,0)$, $(0,-1)$ y $(1,0)$ son puntos de la circunferencia porque verifican su ecuación (compruébese). También $\left(\dfrac{1}{\sqrt{2}},\dfrac{1}{\sqrt{2}}\right)$ es un punto de la circunferencia porque $\left(\dfrac{1}{\sqrt{2}}\right)^2+\left(\dfrac{1}{\sqrt{2}}\right)^2=1$.

  Algunas se pueden representar mediante un sistema de ecuaciones, en lugar de una única ecuación. En estos casos, el conjunto de soluciones del sistema es el conjunto de puntos de la curva. Existe también un tipo de representación algebraica que se llama paramétrica, donde junto a las incógnitas que representan las coordenadas aparecen parámetros que no tienen una representación gráfica directa.

  El segundo tipo de curvas (no representables mediante ecuaciones) es inmenso. Si se quiere un ejemplo, déjesele a un niño de 3 años un lápiz y un papel en blanco, y se obtendrá uno.
\end{remark}

\begin{remark}
  Para concluir, repetiremos, una vez más, que el concepto de función como conjunto de pares ordenados es una formalización que ayuda a razonar rigurosamente con dicho concepto. Sin embargo, no debemos olvidar el concepto ``primitivo'' de función que es el que pretendemos formalizar: una función es una ``regla'' que a cada número de un conjunto $A$ le asigna un único número de cierto conjunto $B$. Se puede concebir una función, entonces, como una ``caja negra'', que al introducirle un número genera cierto número a la salida, de modo que el número generado para una determinada entrada es siempre el mismo. Por ejemplo, pensemos en la función $f$ que devuelve el inverso del número introducido: cuando introducimos un 2, siempre genera un 0'5. Esto lo expresamos diciendo que $f(2)$ vale $0'5$. Las funciones son, por tanto, previsibles.

Lo que ocurre es que una función no admite cualquier número de entrada. Dicho de otra forma, para ciertos números (los del dominio) se genera una salida, pero para otros números no se genera ninguna salida. Si en la función anterior introducimos un 0, la función no devuelve nada. Y para conocer exactamente el funcionamiento de la función, debemos conocer, además de la regla que utiliza para calcular la salida, qué números podemos introducir y cuáles no, es decir, el dominio de la función.

La manera más directa de definir completamente el comportamiento de una tal ``caja negra'' sería mediante una tabla de valores, que nos dijera para cada valor de entrada cuál es el valor de salida correspondiente. Claro que, como nos interesan funciones a las que se les pueden introducir infinitos números distintos, para describir la función mediante su tabla de valores necesitaríamos una tabla infinita. Es más práctico describir la función mediante su ecuación (la ``regla'' que utiliza para calcular la salida) y su dominio (qué números se pueden meter en la entrada).
\end{remark}

\begin{remark}
  No hay un acuerdo completo sobre la terminología empleada para nombrar los conceptos descritos hasta aquí. Algunos llaman aplicaciones a lo que nosotros hemos llamado funciones (en álgebra es más común utilizar el término aplicación, mientras que en cálculo es más frecuente el término función). Hay autores que distinguen entre aplicaciones y funciones: las aplicaciones se definen como correspondencias en que cada elemento tiene una única imagen, y las funciones como aplicaciones entre conjuntos numéricos. Para algunos, una aplicación debe cumplir, además, el requisito de que todos los elementos del conjunto inicial tengan una imagen. Hay autores que definen el conjunto inicial como nosotros hemos definido el dominio, de modo que en una expresión como $f:A\rightarrow B$ hay que entender que $A$ es el dominio de $f$, y, por tanto, que todos los elementos de $A$ tienen imagen.
\end{remark}

\newpage\section{Operaciones con funciones}

\begin{definition}
  [Suma de funciones] Dadas dos funciones $f$ y $g$ se llama suma de ambas, y se representa por $f+g$, a la función definida por
  \[(f+g)(x)=f(x)+g(x)\]
\end{definition}

\begin{definition}
  [Producto de funciones] Dadas dos funciones $f$ y $g$ se llama producto de ellas, y se representa por $fg$, a la función definida por
  \[(fg)(x)=f(x)g(x)\]
\end{definition}

\begin{definition}
  [Cociente de funciones] Dadas dos funciones $f$ y $f$ se llama cociente de $f$ entre $g$, y se representa por $\dfrac{f}{g}$, a la función definida por
  \[\left(\dfrac{f}{g}\right)(x)=\dfrac{f(x)}{g(x)},\;\forall x, g(x) \neq 0\]
\end{definition}

\begin{definition}
  [Composición de funciones] Dadas dos funciones $f$ y $g$ se llama función compuesta de $f$ y $g$, y se representa por $f \circ g$, a la función definida por
  \[(f \circ g)(x) = f\left(g(x)\right)\]
\end{definition}

\begin{remark}
  En las definiciones anteriores no se ha mencionado el dominio de la función definida con el fin de no complicar excesivamente la definición. Se supone siempre que la expresión que define la función suma, producto, cociente o compuesta ha de tener sentido. Solo se ha declarado explícitamente en $f/g$, ha de ser $g(x)\neq0$. Así, por ejemplo, el dominio de $f+g$ resulta ser, obviamente, $\dom f \cap \dom g$.
\end{remark}

\begin{example}
  Dadas las funciones $f(x)=x^2$, $g(x)=x+1$ y $h(x)=\ln x$, hallar la ecuación de cada una de las siguientes funciones:
  \begin{itemize}
  \item $f+g$: $(f+g)(x)=f(x)+g(x)=x^2+x+1$.
  \item $fg$: $(fg)(x) = f(x)g(x) = x^2(x+1)=x^3+x^2$.
  \item $\dfrac{f}{g}$: $\left(\dfrac{f}{g}\right)(x) = \dfrac{f(x)}{g(x)} = \dfrac{x^2}{x+1}$.
  \item $f \circ g$: $(f \circ g)(x) = f\left(g(x)\right) = f(x+1) = (x+1)^2 = x^2+2x+1$.
  \item $g \circ f$: $(g \circ f)(x) = g\left(f(x)\right) = g(x^2) = x^2+1$.
  \item $f \circ h$: $(f \circ h)(x) = f\left(h(x)\right) = \left(h(x)\right)^2 = \left(\ln x\right)^2 = \ln^2 x$.
  \item $h \circ f$: $(h \circ f)(x) = h\left(f(x)\right) = \ln f(x) = \ln x^2$.
  \item $f \circ (g \circ h)$: $(f \circ (g \circ h))(x) = f\left((g \circ h)(x)\right) = f\left(g\left(h(x)\right)\right) = f\left(g(\ln x)\right) = f(\ln x + 1) =(\ln x + 1)^2$.
  \end{itemize}
\end{example}

\begin{remark}
  Obsérvese que, en general, $f \circ g \neq g \circ f$. Por otro lado, $f \circ (g \circ h) =(f \circ g) \circ h$, por lo que suele abreviarse $f \circ g \circ h$.
\end{remark}

\begin{definition}
  [Función inyectiva] Una función es inyectiva si no tiene dos pares distintos con el mismo segundo elemento. 
\end{definition}

\begin{example}
  La función
  \[f(x) = \dfrac{x+1}{x+2}\]
  es inyectiva. Dado un valor cualquiera, $y$, la ecuación $\dfrac{x+1}{x+2} = y$ tendrá como máximo una solución.

  La gráfica de una función inyectiva puede ser cortada por cualquier recta horizontal como máximo una vez.

  La función
  \[g(x) = x^3 - x\]
  no es inyectiva, ya que hay valores distintos de $x$ que tienen la misma imagen. Así, por ejemplo,
  \[g(-1) = g(0) = g(1) = 0\]
\end{example}

\begin{definition}
  [Función inversa] Dada una función inyectiva, $f$, se llama función inversa o recíproca de $f$, y se representa por $f^{-1}$, a la función que verifica
  \[\left(f \circ f^{-1}\right)(x) = \left(f^{-1} \circ f\right)(x) = x, \; \forall x \in \Im f\]
\end{definition}

\begin{example}
  La función recíproca de $f(x)=e^x$ es $f^{-1}(x)=\ln x$.
\end{example}

\begin{remark}
  Un método para hallar la ecuación de la función inversa de una dada, que funciona en muchos casos, consiste en ``despejar'' $x$ en la ecuación de $f$, y luego intercambiar $x$ por $f(x)$ y viceversa. Por ejemplo, sea
  \[f(x)=\dfrac{x+1}{x+2}\]
  \begin{eqnarray*}f(x) = \dfrac{x+1}{x+2} & \iff & (x+2)f(x)=x+1 \\
    & \iff & xf(x)+2f(x)=x+1 \\
    & \iff & xf(x)-x=1-2f(x) \\
    & \iff & x(f(x)-1) =1-2f(x) \\
    & \iff & x = \dfrac{1-2f(x)}{f(x)-1}\end{eqnarray*}
  Por tanto,
  \[f^{-1}(x) = \dfrac{1-2x}{x-1}\]
\end{remark}

\begin{remark}
  Si una función es invertible, su rango es el dominio de su inversa. De modo que una manera de calcular el rango de una función es hayando su inversa y calculando el dominio de esta.
\end{remark}



\chapter{Sucesiones}

\begin{definition}
  Una {\tmstrong{sucesión infinita}} es una función cuyo dominio es
  $\mathbb{N}$ (o bien, un conjunto infinito de números
  ordenados). Se representa por $\{ a_n \}$.
\end{definition}

\begin{example}
  Las sucesiones no se suelen expresar utilizando la notación funcional, sino
  como un conjunto, indicando sólo el recorrido:
  
  $\{ a_n \} = \{ 1, \frac{4}{3}, \frac{3}{2}, \frac{8}{5}, \frac{5}{3}, \frac{12}{7}, \ldots \}$; $a_1 = 1 ; a_2 = \frac{4}{3} ; a_3 = \frac{3}{2} ; \ldots$
  
  Con notación funcional sería: $a ( 1 ) = 1 ; a ( 2 ) = \frac{4}{3} ; a ( 3  ) = \frac{3}{2} ; \ldots$
\end{example}

\begin{definition}
  Se llama {\tmstrong{término}} de una sucesión a cada uno de los elementos de
  su recorrido (o cada uno de sus elementos).
\end{definition}

\begin{definition}
  Se llama {\tmstrong{término general}} a la ecuación que relaciona cada
  número natural con su imagen (o cada término con la posición que ocupa en la
  sucesión).
\end{definition}

\begin{example}
  El término general de la sucesión anterior sería:
  
  $a_n = \frac{2 n}{n + 1}$
  
  Para calcular el término que ocupa una posición determinada en la sucesión,
  sólo hay que sustituir $n$ por dicha posición en el término general. Así,
  para calcular el término que ocupa la posición 10:
  
  $a_{10} = \frac{2 \cdot 10}{10 + 1} = \frac{20}{11}$
\end{example}

\begin{example}
  A veces la sucesión se define {\tmstrong{por recurrencia}}, mediante una
  expresión que relaciona el término n-ésimo con el término anterior, más el
  valor del primero. Así, por ejemplo, la sucesión:
  
  $1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, \ldots$ (cada término es la suma de
  los dos anteriores),
  
  se define así: $a_1 = 1 ; a_2 = 1 ; a_n = a_{n - 1} + a_{n - 2}, \tmop{para} n > 2$.
\end{example}

\begin{definition}
  Una sucesión $\{ a_n \}$ {\tmstrong{converge hacia L}} si para todo
  $\varepsilon > 0$ existe un número natural $N$ tal que $n > N \Rightarrow |a_n - L| < \varepsilon$. Se dice también que la sucesión {\tmstrong{tiende
  hacia L}}, o que su {\tmstrong{límite es L}}, y se representa por:
  {\tmstrong{$\underset{n \rightarrow \infty}{\lim} a_n = L$}}. Si una
  sucesión converge hacia algún número $L$, se dice que es
  {\tmstrong{convergente}}. En caso contrario, se dice que es
  {\tmstrong{divergente}}.
\end{definition}

\begin{example}
  La sucesión de los ejemplos anteriores es convergente, y su límite es 2:
  $\underset{n \rightarrow \infty}{\lim} \frac{2 n}{n + 1} = 2$
  
  Esto significa que aumentando $n$ podemos hacer que $a_n$ sea tan próximo a
  2 como queramos. En efecto:
  
  $2 - \frac{2 n}{n + 1} = \frac{2 n + 2 - 2 n}{n + 1} = \frac{2}{n + 1}$
  
  Para cualquier $\varepsilon > 0$, si tomamos $n > \frac{2}{\varepsilon} -  1$, tendremos:
  
  $n > \frac{2}{\varepsilon} - 1 \Rightarrow \frac{2}{n + 1} < \frac{2}{\left( \frac{2}{\varepsilon} - 1 \right) + 1} = \frac{2 \varepsilon}{2} = \varepsilon \Rightarrow 2 - \frac{2 n}{n + 1} < \varepsilon$
\end{example}

\begin{definition}
  Una sucesión es {\tmstrong{monótona creciente}} si para todo $n$, $a_{n + 1} \geqslant a_n$. Una sucesión es {\tmstrong{monótona decreciente}} si para
  todo $n$, $a_{n + 1} \leqslant a_n$. Una sucesión es {\tmstrong{monótona}}
  si es monótona creciente o monótona decreciente.
\end{definition}

\begin{definition}
  Una sucesión está {\tmstrong{acotada superiormente}} si existe algún número
  $C$ tal que $a_n \leqslant C$, para todo $n$. Una sucesión está
  {\tmstrong{acotada inferiormente}} si existe algún número $C$ tal que $a_n \geqslant C$ para todo $n$. Una sucesión está {\tmstrong{acotada}} si lo
  está superior e inferiormente.
\end{definition}

\begin{theorem}
  [Cálculo de límites de sucesiones] Todos los teoremas y
  procedimientos estudiados para los límites de funciones en el infinito son
  aplicables al cálculo de límites de sucesiones.
\end{theorem}

\begin{example}
  El límite anterior podíamos haberlo calculado así:
  
  $\underset{n \rightarrow \infty}{\lim} \frac{2 n}{n + 1} = \frac{2 \cdot \infty}{\infty + 1} = \frac{\infty}{\infty} = \underset{n \rightarrow \infty}{\lim} \frac{\frac{2 n}{n}}{\frac{n}{n} + \frac{1}{n}} = \underset{n \rightarrow \infty}{\lim} \frac{2}{1 + \frac{1}{n}} = \frac{2}{1 + \frac{1}{\infty}} = \frac{2}{1 + 0} = 2$
\end{example}

\begin{example}
  Calcular: $\underset{n \rightarrow \infty}{\lim} \left( \frac{3 n - 1}{3 n} \right)^{2 n}$
  
  $\underset{n \rightarrow \infty}{\lim} \left( \frac{3 n - 1}{3 n} \right)^{2n} = \left( \underset{n \rightarrow \infty}{\lim} \frac{3 n - 1}{3 n} \right)^{\underset{n \rightarrow \infty}{\lim} 2 n} = 1^{\infty} =  e^{\underset{n \rightarrow \infty}{\lim} 2 n \left( \frac{3 n - 1}{3 n} - 1\right)} = e^{\underset{n \rightarrow \infty}{\lim} 2 n \left( \frac{3 n - 1 - 3 n}{3 n} \right)} = e^{\underset{n \rightarrow \infty}{\lim} 2 n \frac{-1}{3 n}} = e^{\underset{n \rightarrow \infty}{\lim} \frac{- 2}{3}} = e^{-\frac{2}{3}}$
\end{example}

\begin{theorem}
  Una sucesión monótona converge si y sólo si está acotada.
\end{theorem}

\begin{theorem}
  Una sucesión converge si y sólo si $\underset{m, n \rightarrow \infty}{\lim} |a_m - a_n | = 0$.
\end{theorem}

\begin{example}
  Demostrar que la sucesión $a_n = \frac{2 n}{n + 1}$ es monótona creciente, y
  calcular $\underset{n \rightarrow \infty}{\lim} n^2 ( a_{n + 1} - a_{n )}$.
  
  
  
  $a_{n + 1} = \frac{2 ( n + 1 )}{( n + 1 ) + 1} 2 ( n + 1 ) ( n + 1 ) = 2 n^2 + 4 n + 2 > 2 n^2 + 4 n = 2 n [ ( n + 1 ) + 1 ] \Rightarrow \frac{2 ( n + 1 )}{( n + 1 ) + 1} > \frac{2 n}{n + 1} \Rightarrow a_{n + 1} > a_n, \forall n$
  
  Luego, la sucesión es monótona creciente.
  
  Además, la sucesión está acotada, ya que $\frac{2 n}{n + 1} = \frac{n + n}{n + 1} > 1, \forall n > 1$ y $\frac{2 n}{n + 1} = \frac{2 n + 2}{n + 1} - \frac{2}{n + 1} = \frac{2 ( n + 1 )}{n + 1} - \frac{2}{n + 1} = 2 - \frac{2}{n + 1} < 2, \forall n > 1$. Por tanto, según el teorema 2, es
  convergente.
  
  Por ser convergente, según el teorema 3, ha de ser $\underset{n \rightarrow \infty}{\lim} |a_{n + 1} - a_n | = 0$, luego:
  
  $\underset{n \rightarrow \infty}{\lim} n^2 ( a_{n + 1} - a_n ) = \infty \cdot 0$
  
  Para resolver la indeterminación, calculamos:
  
  $a_{n + 1} - a_n = \frac{2 ( n + 1 )}{n + 2} - \frac{2 n}{n + 1} = \frac{2 n^2 + 4 n + 2 - 2 n^2 - 4 n}{( n + 1 ) ( n + 2 )} = \frac{2}{n^2 + 3 n + 2}$
  
  $\underset{n \rightarrow \infty}{\lim} n^2 ( a_{n + 1} - a_n ) = \underset{n \rightarrow \infty}{\lim} n^2 \frac{2}{n^2 + 3 n + 2} = 2$
\end{example}

\begin{example}
  (Mod. 07-08, A.2, 2 ptos.) Calcular:
  \begin{enumeratealpha}
  \item $\underset{n \rightarrow \infty}{\lim} \left( \frac{2 + n}{1 + n} \right)^{1 - 5 n}$

    Es una indeterminación de tipo $1^\infty$:

    \begin{eqnarray*}\limite{n}{\infty}{\left(\dfrac{2+n}{1+n}\right)^{1-5n}} & = & 1^{-\infty} = e^{\limite{n}{\infty}{(1-5n)\left(\dfrac{2+n}{1+n}-1\right)}} = e^{\limite{n}{\infty}{(1-5n)\dfrac{2+n-(1+n)}{1+n}}} \\
      & = & e^{\limite{n}{\infty}{(1-5n)\dfrac{1}{1+n}}} = e^{\limite{n}{\infty}{\dfrac{1-5n}{1+n}}} = e^{-5}
    \end{eqnarray*}
    
  \item $\underset{n \rightarrow \infty}{\lim} \frac{\sqrt{n^4 + 2 n^3 - 3} - \sqrt{n^4 - n}}{n + 5}$

    Aparece en primer lugar una indeterminación de tipo $\infty-\infty$:

    \begin{eqnarray*}
      \limite{n}{\infty}{\dfrac{\sqrt{n^4+2n^3-3}-\sqrt{n^4-n}}{n+5}} & = & \dfrac{\infty-\infty}{\infty} \\
         & = & \limite{n}{\infty}{\dfrac{\left(\sqrt{n^4+2n^3-3}-\sqrt{n^4-n}\right)\left(\sqrt{n^4+2n^3-3}+\sqrt{n^4-n}\right)} {(n+5)\left(\sqrt{n^4+2n^3-3}+\sqrt{n^4-n}\right)}} \\
         & = & \limite{n}{\infty}{\dfrac{n^4+2n^3-3-(n^4-n)}{(n+5)\left(\sqrt{n^4+2n^3-3}+\sqrt{n^4-n}\right)}} \\
         & = & \limite{n}{\infty}{\dfrac{2n^3+n-3}{(n+5)\left(\sqrt{n^4+2n^3-3}+\sqrt{n^4-n}\right)}} = \dfrac{\infty}{\infty} \\
         & = & \limite{n}{\infty}{\dfrac{n^3\left(2+\frac{1}{n^2}-\frac{3}{n^3}\right)} {n\left(1+\frac{5}{n}\right)\left(\sqrt{n^4\left(1+\frac{2}{n}-\frac{3}{n^4}\right)}+\sqrt{n^4\left(1-\frac{1}{n^3}\right)}\right)}} \\
         & = & \limite{n}{\infty}{\dfrac{n^3\left(2+\frac{1}{n^2}-\frac{3}{n^3}\right)} {n^3\left(1+\frac{5}{n}\right)\left(\sqrt{1+\frac{2}{n}-\frac{3}{n^4}}+\sqrt{1-\frac{1}{n^3}}\right)}} \\
         & = & \limite{n}{\infty}{\dfrac{2+\frac{1}{n^2}-\frac{3}{n^3}} {\left(1+\frac{5}{n}\right)\left(\sqrt{1+\frac{2}{n}-\frac{3}{n^4}}+\sqrt{1-\frac{1}{n^3}}\right)}} \\
         & = & \dfrac{2}{2} = 1
    \end{eqnarray*}
  \end{enumeratealpha}
\end{example}

\begin{example}
  Calcular los límites siguientes:
  \begin{enumeratealpha}
  \item $\underset{x \rightarrow \infty}{\lim} \frac{n}{n + 1} - \frac{n + 1}{n}$
    \[\limite{n}{\infty}{\dfrac{n}{n+1}-\dfrac{n+1}{n}} = \limite{n}{\infty}{\dfrac{n}{n+1}} - \limite{n}{\infty}{\dfrac{n+1}{n}} = 1-1 = 0\]
  \item $\underset{n \rightarrow \infty}{\lim} \sqrt{n + 1} - \sqrt{n}$
    \[\limite{n}{\infty}{\left(\sqrt{n+1}-\sqrt{n}\right)} = \infty-\infty = \limite{n}{\infty}{\dfrac{\left(\sqrt{n+1}-\sqrt{n}\right)\left(\sqrt{n+1}+\sqrt{n}\right)}{\sqrt{n+1}+\sqrt{n}}} = \limite{n}{\infty}{\dfrac{n+1-n}{\sqrt{n+1}+\sqrt{n}}} = \dfrac{1}{\infty} = 0\]
  \end{enumeratealpha}
\end{example}

\begin{example}
  Calcular:
  \begin{enumeratealpha}
  \item $\underset{n \rightarrow \infty}{\lim} \sqrt[n]{a}, a > 0$
    \[\limite{n}{\infty}{\sqrt[n]{a}} = \limite{n}{\infty}{a^{1/n}} = a^{1/\infty} = a^0 = 1\]
  \item $\underset{n \rightarrow \infty}{\lim} \frac{n^2}{n + 1} -  \frac{n^2 + 1}{n}$
    \[\limite{n}{\infty}{\left(\dfrac{n^2}{n+1}-\dfrac{n^2+1}{n}\right)} = \limite{n}{\infty}{\dfrac{n^2\cdot n-(n+1)(n^2+1)}{n(n+1)}} = \limite{n}{\infty}{\dfrac{-n^2-n-1}{n^2+n}} = -1\]
  \end{enumeratealpha}
\end{example}

\begin{example}

  \begin{enumeratealpha}
  \item Demostrar que si $0 < a < 2$, entonces $a < \sqrt{2 a} < 2$.
    Sea $f(x)=\sqrt{x},\ x>0$. La función $f$ es estrictamente creciente en su dominio, ya que,
    \[f'(x)=\dfrac{1}{2\sqrt{x}}>0,\ \forall\;x>0\]

    Por lo tanto, 
    \[0<x<4 \Rightarrow \sqrt{x}<\sqrt{4}=2\]

    Dado que, obviamente, $0<a<2 \Rightarrow 0<2a<4$, tenemos que
    \[0<a<2 \Rightarrow \sqrt{2a}<2\]

    Aplicando de nuevo que $f(x)=\sqrt{x}$ es estrictamente creciente, tenemos que
    \[0<a<2 \Rightarrow \sqrt{a}<\sqrt{2} \Rightarrow \sqrt{a}\sqrt{a}<\sqrt{a}\sqrt{2} \Rightarrow \sqrt{a^2}<\sqrt{2a} \Rightarrow a<\sqrt{2a}\]

  \item Demostrar que la sucesión
    \begin{center}
      $\sqrt{2}, \sqrt{2 \sqrt{2}}, \sqrt{2 \sqrt{2 \sqrt{2}}}, \ldots$
    \end{center}
    es convergente.

    Demostraremos que la sucesión dada es monótona (creciente), y acotada. Llamaremos $a_n$ al término n-ésimo de la sucesión. Podríamos definir así la sucesión, por recurrencia:

    \[a_1=\sqrt{2};\ a_n=\sqrt{2a_{n-1}},\ n>1\]

    Veamos, en primer lugar, que está acotada, y que, concretamente, $a_n<2,\ \forall n$. Procederemos por inducción. Es claro que $a_1=\sqrt{2} \Rightarrow 0<a_1<2$. Por otro lado, según hemos demostrado en el apartado a),
    \[0<a_{n-1}<2 \Rightarrow a_n=\sqrt{2a_{n-1}}<2\]

    Queda demostrado que la sucesión está acotada.

    Puesto que la sucesión está acotada, sabemos que $0<a_{n-1}<2,\ \forall\ n$. Además, según hemos demostrado en a), $0<a_{n-1}<2 \Rightarrow a_{n-1}<\sqrt{2a_{n-1}}=a_n$. Luego la sucesión es creciente.
    
  \item Hallar el límite de la sucesión anterior.

    Aplicaremos un resultado bastante intuitivo que dice que toda subsucesión convergente de una sucesión convergente es convergente, y tiene el mismo límite que dicha sucesión.

    Sea $L=\limite{n}{\infty}{a_n}$. Obsérvese que,
    \[a_n=\sqrt{2}\sqrt{a_{n-1}},\ n>1\]

    Por lo tanto,
    \[L = \limite{n}{\infty}{a_n} = \limite{n}{\infty}{\sqrt{2}\sqrt{a_{n-1}}} = \sqrt{2}\sqrt{\limite{n}{\infty}{a_{n-1}}} =\sqrt{2}\sqrt{L}\]

    Es decir,
    \[L=\sqrt{2L}\]

    Resolviendo la ecuación anterior, considerando que ha de ser $L>0$, ya que $a_n>0,\ \forall n$, tenemos,
    \[L=\sqrt{2L} \iff L^2=2L \iff L=2\]

    Luego, el límite de la sucesión es $2$.
  \end{enumeratealpha}
\end{example}



\begin{example}
  Calcular, si existe:

  $$\underset{n \rightarrow \infty}{\lim} \frac{1 + ( - 1 )^n}{n}$$

  Sea $a_n$ el término general de la sucesión dada:

  \[a_n=\dfrac{1+(-1)^n}{n}\]

  Obsérvese que, para todo $n$,

  \[a_n=\twpwf{0}{\text{si }n\text{ es impar}}{\dfrac{2}{n}}{\text{si }n\text{ es par}}\]

  Luego, para todo $n$,

  \[0 \leq a_n \leq \dfrac{2}{n}\]

  Dado que $\limite{n}{\infty}{0}=0$ y $\limite{n}{\infty}{\dfrac{2}{n}}=0$, ha de ser

  \[\limite{n}{\infty}{a_n}=0\]
\end{example}





\end{document}
